{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7eaaec20b70143ac9f4e868c38f38868": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d71b086c9c084d41b84f7021cfaa2509",
              "IPY_MODEL_f826e2282aa1452ab047f599ab021bdd",
              "IPY_MODEL_6a36b47d00f94c7fb0e0c1916bff0ddd"
            ],
            "layout": "IPY_MODEL_945071247eb9401f89a86c1187674d2b"
          }
        },
        "d71b086c9c084d41b84f7021cfaa2509": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9af91d01919f4ed0959e78a611c48af9",
            "placeholder": "​",
            "style": "IPY_MODEL_c6813cedd2734aa49568f77b34a03390",
            "value": "Map: 100%"
          }
        },
        "f826e2282aa1452ab047f599ab021bdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c53405f4e37f48e6b8794a50c643b427",
            "max": 5872,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7236363ce5994eaeb7cc54910cf9291e",
            "value": 5872
          }
        },
        "6a36b47d00f94c7fb0e0c1916bff0ddd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b4591be3e7848fba83e82a98c6aa804",
            "placeholder": "​",
            "style": "IPY_MODEL_4bc8f1fcc5fd463b88bdfdd94d1224de",
            "value": " 5872/5872 [00:04&lt;00:00, 1453.28 examples/s]"
          }
        },
        "945071247eb9401f89a86c1187674d2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9af91d01919f4ed0959e78a611c48af9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6813cedd2734aa49568f77b34a03390": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c53405f4e37f48e6b8794a50c643b427": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7236363ce5994eaeb7cc54910cf9291e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b4591be3e7848fba83e82a98c6aa804": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bc8f1fcc5fd463b88bdfdd94d1224de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2263361c4ee24175bb5b358b499e02ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f8a0d29a07e24d819932cb052d6d6a30",
              "IPY_MODEL_85c7681bb5734c20bfcc9ebb04f9ed4b",
              "IPY_MODEL_bcc62de3996c463d8c8b1f2d3fcc2428"
            ],
            "layout": "IPY_MODEL_21118bd02d16497e9769198124c6f61e"
          }
        },
        "f8a0d29a07e24d819932cb052d6d6a30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d72af8623a747a6a4366dd042821573",
            "placeholder": "​",
            "style": "IPY_MODEL_4015b29276de4b2db4f620ca62fc028b",
            "value": "Map: 100%"
          }
        },
        "85c7681bb5734c20bfcc9ebb04f9ed4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_757efcf76053456a81034fa5253b8ebf",
            "max": 1468,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_227586f192df479a993bb806033bbd1d",
            "value": 1468
          }
        },
        "bcc62de3996c463d8c8b1f2d3fcc2428": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ac98116b5b44093ac733b0818c80eb9",
            "placeholder": "​",
            "style": "IPY_MODEL_0923bdc9f5c8459491c9e8275ddc3050",
            "value": " 1468/1468 [00:01&lt;00:00, 992.60 examples/s]"
          }
        },
        "21118bd02d16497e9769198124c6f61e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d72af8623a747a6a4366dd042821573": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4015b29276de4b2db4f620ca62fc028b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "757efcf76053456a81034fa5253b8ebf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "227586f192df479a993bb806033bbd1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ac98116b5b44093ac733b0818c80eb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0923bdc9f5c8459491c9e8275ddc3050": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> This notebook presents a complete workflow for tri-class sentiment classification on the FiReCS dataset of Taglish product reviews. The pipeline begins with data loading, cleaning, and a reproducible 80/20 stratified split that preserves class balance and writes split IDs to disk for consistent evaluation across runs. A simple baseline is then established using TF-IDF features with Logistic Regression to provide an interpretable reference score. The workflow proceeds to transformer fine-tuning with two backbones: a multilingual encoder (XLM-RoBERTa) and a Filipino-prior encoder (RoBERTa-Tagalog). Both models are adapted to three sentiment labels and trained using a shared evaluation function that reports macro-F1 and accuracy on the fixed validation split.\n",
        "\n",
        "> Each section of the notebook follows a consistent structure to aid replication. The preprocessing cell prepares tokenization with a fixed sequence length and converts the data into tensor-ready datasets. The training cell configures arguments, constructs the trainer, performs fine-tuning, evaluates on the validation set, and saves the best checkpoint together with its tokenizer. A brief inference cell verifies behavior on short sample texts, while an analysis cell produces a confusion matrix and a per-class report to explain common errors between negative, neutral, and positive. A final export cell aggregates all runs into a single log, writes spreadsheet summaries for grading and reporting, and highlights the strongest configuration per model.\n",
        "\n",
        "> The notebook supports both thorough runs and quick sweeps. A fast mode reduces training time by using a smaller training slice and an optional early-stopping callback, which is useful for exploring learning rate, batch size, and epoch count under limited time or hardware. Final headline scores are obtained from full runs that reuse the same split and metric function. Saved checkpoints, split ID files, and exported logs ensure that results can be reproduced and compared fairly across members and model choices.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "A9UbJzzYHqkh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Setup, imports, dataset load, and split**"
      ],
      "metadata": {
        "id": "pIiqkobxHKGk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`Purpose`**\n",
        "\n",
        "This block prepares the environment, ensures required libraries are available, and loads the FiReCS dataset into memory in a clean, consistent format. It also establishes a reproducible train–validation split so that all later experiments evaluate on the same examples. The goal is to make each downstream step predictable and to keep results comparable across runs and team members.\n",
        "\n",
        "**`Input`**\n",
        "\n",
        "The cell expects either a local copy of FiReCS.csv in the current working directory or, if absent, a file that will be provided through the upload dialog. The CSV must contain at least two columns named review and label, which represent the input text and its sentiment class. No other inputs are required at this stage, and any additional columns are ignored.\n",
        "\n",
        "**`Output`**\n",
        "\n",
        "The cell produces two pandas DataFrames, train_df and val_df, with stratified class proportions and a new id column to uniquely identify each row. It also writes two small files, train_ids.csv and val_ids.csv, which store the chosen row IDs for reuse. The printed device line indicates whether a GPU is available. Two proportion tables are printed as a quick check that label ratios are closely matched across splits.\n",
        "\n",
        "**`Details`**\n",
        "\n",
        "The cell installs the core NLP stack, imports common utilities, and detects the runtime device. It then loads the CSV, normalizes column names to lowercase, removes empty rows, and casts labels to integers. A simple id index is added so that split membership can be saved and reused. A stratified split holds label balance constant, which is printed to confirm the split is fair. Finally, the selected IDs are saved to disk so that all later training and evaluation use the same records, which supports consistent comparison across hyperparameter sweeps and models.\n",
        "\n",
        "**`Line-by-line Description.`**\n",
        "\n",
        "`!pip -q install transformers datasets accelerate scikit-learn openpyxl -U` installs or upgrades the libraries needed for tokenization, training, metrics, and spreadsheet export.\n",
        "\n",
        "`import os, numpy as np, pandas as pd, torch` pulls in filesystem helpers, numerical tools, data frames, and the deep learning backend.\n",
        "\n",
        "`from sklearn.model_selection import train_test_split` and `from sklearn.metrics import accuracy_score, f1_score` load utilities for splitting and scoring.\n",
        "`try: from google.colab import files ...` sets up an optional upload path that only activates when running in Colab.\n",
        "\n",
        "`device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')` detects whether a GPU is present and prints the choice so training expectations are clear.\n",
        "\n",
        "`if not os.path.exists('FiReCS.csv') and files is not None: files.upload()` requests an upload when the CSV is missing, which keeps the workflow flexible.\n",
        "\n",
        "`df = pd.read_csv('FiReCS.csv')` loads the data, and `df.columns = [c.lower() for c in df.columns]` enforces lowercase names so downstream code can assume consistent headers.\n",
        "\n",
        "`df = df.dropna(subset=['review','label']).copy()` removes incomplete rows to avoid errors and noisy training examples.\n",
        "`df['label'] = df['label'].astype(int)` fixes the label type so models receive proper integers.\n",
        "\n",
        "`df['id'] = np.arange(len(df))` assigns a stable identifier to each row so the split can be persisted.\n",
        "\n",
        "The branch that checks for `train_ids.csv` and `val_ids.csv` either reuses an existing split or creates a new stratified split with `train_test_split(... stratify=df['label'])`.\n",
        "\n",
        "`train_df[['id']].to_csv('train_ids.csv', index=False)` and the matching line for validation serialize the split for later reuse.\n",
        "\n",
        "The final `print(...)` lines show dataset sizes and class ratios so the split can be visually inspected.\n"
      ],
      "metadata": {
        "id": "pSZSQ3nPC3sL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install transformers datasets accelerate\n",
        "\n",
        "import os, numpy as np, pandas as pd, torch, json, inspect\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from google.colab import files\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "if not os.path.exists(\"FiReCS.csv\"):\n",
        "    uploaded = files.upload()\n",
        "df = pd.read_csv(\"FiReCS.csv\")\n",
        "\n",
        "df = df.rename(columns={c:c.lower() for c in df.columns})\n",
        "assert {'review','label'} <= set(df.columns), \"CSV must have 'review' and 'label' columns.\"\n",
        "\n",
        "df = df.dropna(subset=['review','label']).copy()\n",
        "df['label'] = df['label'].astype(int)\n",
        "df['id'] = np.arange(len(df))\n",
        "\n",
        "train_df, val_df = train_test_split(\n",
        "    df, test_size=0.2, random_state=42, stratify=df['label']\n",
        ")\n",
        "print(train_df['label'].value_counts(normalize=True).sort_index())\n",
        "print(val_df['label'].value_counts(normalize=True).sort_index())\n",
        "\n",
        "train_df[['id']].to_csv('train_ids.csv', index=False)\n",
        "val_df[['id']].to_csv('val_ids.csv', index=False)\n"
      ],
      "metadata": {
        "id": "7ej9srJoYd3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Baseline TF-IDF + Logistic Regression and log row**"
      ],
      "metadata": {
        "id": "V9q0q_b0HE_w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`Purpose`**\n",
        "\n",
        "This block builds a fast and transparent baseline that serves as a reference point for the later transformer models. It turns each review into a TF-IDF vector over single words and bigrams, trains a linear classifier, and records validation performance. The intent is to establish a clear bar that later fine-tuned models should exceed.\n",
        "\n",
        "**`Input`**\n",
        "\n",
        "The inputs are the train_df and val_df frames created earlier. Only the review and label columns are used. The TF-IDF vectorizer is configured with a vocabulary limit to cap memory and training time, and the labels are taken directly as integer classes.\n",
        "\n",
        "**`Output`**\n",
        "\n",
        "The block prints a compact dictionary that contains baseline accuracy and macro-F1. It also appends a structured row to runs_log.csv so that the baseline appears in the experiment ledger with model name, scores, and a note. These outputs provide both an on-screen summary and a durable record for later tables and charts.\n",
        "\n",
        "**`Details`**\n",
        "\n",
        "A TF-IDF vectorizer is fit on the training text and applied to the validation text, producing sparse matrices. A Logistic Regression model is trained with a high iteration cap to ensure convergence. Predictions for the validation set are compared against the gold labels to compute accuracy and macro-F1, where macro-F1 treats all classes equally. The metrics are printed and then written to the log file with consistent column names so that later export steps can merge and sort results without extra work.\n",
        "\n",
        "\n",
        "**`Line-by-line Description`**\n",
        "\n",
        "`from sklearn.feature_extraction.text import TfidfVectorizer` and `from sklearn.linear_model import LogisticRegression` import the tools for representation and classification.\n",
        "\n",
        "`tfidf = TfidfVectorizer(max_features=50000, ngram_range=(1,2), lowercase=True)` defines the vocabulary limit and includes single words and bigrams to capture short phrases.\n",
        "\n",
        "`X_tr = tfidf.fit_transform(train_df['review'])` learns the vocabulary and weights from training text and returns the training matrix.\n",
        "\n",
        "`y_tr = train_df['label'].values` extracts the training labels as a dense array.\n",
        "\n",
        "`X_va = tfidf.transform(val_df['review'])` applies the same mapping to validation text to ensure a consistent feature space.\n",
        "\n",
        "`y_va = val_df['label'].values` collects validation labels.\n",
        "\n",
        "`logreg = LogisticRegression(max_iter=2000)` raises the iteration cap to support convergence in high-dimensional space.\n",
        "\n",
        "`logreg.fit(X_tr, y_tr)` learns the linear classifier on the training features.\n",
        "\n",
        "`preds = logreg.predict(X_va)` generates predicted labels for validation examples.\n",
        "\n",
        "`acc_base = accuracy_score(y_va, preds)` and `f1_base = f1_score(..., average='macro')` compute the two main scores.\n",
        "\n",
        "The dictionary `{'model':..., 'accuracy':..., 'f1_macro':...}` is printed to show the baseline performance clearly.\n",
        "\n",
        "The `row = {...}` dictionary collects metadata and scores, and the `with open('runs_log.csv','a',...)` block appends it to the experiment ledger, writing headers when the file is new.\n",
        "\n"
      ],
      "metadata": {
        "id": "Kwe7KU5uDQzz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "tfidf = TfidfVectorizer(\n",
        "    max_features=50000,\n",
        "    ngram_range=(1,2),\n",
        "    lowercase=True\n",
        ")\n",
        "X_tr = tfidf.fit_transform(train_df['review'])\n",
        "y_tr = train_df['label'].values\n",
        "X_va = tfidf.transform(val_df['review'])\n",
        "y_va = val_df['label'].values\n",
        "\n",
        "logreg = LogisticRegression(max_iter=2000, n_jobs=None, class_weight=None)\n",
        "logreg.fit(X_tr, y_tr)\n",
        "\n",
        "preds = logreg.predict(X_va)\n",
        "acc_base = accuracy_score(y_va, preds)\n",
        "f1_base  = f1_score(y_va, preds, average='macro')\n",
        "print({\"model\":\"tfidf-logreg\", \"accuracy\":acc_base, \"f1_macro\":f1_base})\n",
        "\n",
        "row = {\n",
        "    \"member\":\"baseline\", \"model\":\"tfidf-logreg\",\n",
        "    \"num_train_epochs\":None, \"per_device_train_batch_size\":None,\n",
        "    \"learning_rate\":None, \"weight_decay\":None, \"warmup_steps\":None,\n",
        "    \"lr_scheduler_type\":None, \"gradient_accumulation_steps\":None,\n",
        "    \"max_seq_length\":None, \"seed\":42, \"fp16\":False,\n",
        "    \"accuracy\":acc_base, \"f1_macro\":f1_base, \"notes\":\"TF-IDF + LogReg baseline\"\n",
        "}\n",
        "pd.DataFrame([row]).to_csv(\"runs_log.csv\", mode=\"a\",\n",
        "                           index=False, header=not os.path.exists(\"runs_log.csv\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "mQkWVS7TYdm6",
        "outputId": "02b5b9c1-16d1-40f7-b4a0-dd35d8378ae8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'model': 'tfidf-logreg', 'accuracy': 0.803133514986376, 'f1_macro': 0.8057244174688569}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model switcher, tokenization, dataset tensors, and model init**"
      ],
      "metadata": {
        "id": "EANPmOOIHBX6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`Purpose`**\n",
        "\n",
        "This block activates the transformer route by choosing a backbone, preparing tokenization, converting data to the dataset format expected by the trainer, and constructing a sequence-classification head for three sentiment classes. It standardizes inputs so that training runs follow a single, repeatable path.\n",
        "\n",
        "**`Input`**\n",
        "\n",
        "The inputs are the training and validation DataFrames and a model key that selects either the multilingual encoder or the Tagalog-prior encoder. A maximum sequence length is specified to keep batch shapes uniform. The tokenizer is loaded to map raw text into token IDs and attention masks.\n",
        "\n",
        "**`Output`**\n",
        "\n",
        "The block prints the resolved model name to document which backbone is active. Two datasets.Dataset objects are produced with tensor columns input_ids, attention_mask, and label. A classification model with three output labels is created and moved to the detected device so that subsequent training calls can run immediately.\n",
        "\n",
        "**`Details`**\n",
        "\n",
        "A small dictionary maps human-readable keys to exact model identifiers. The tokenizer is loaded with the fast backend and wrapped in a function that applies truncation and padding to a fixed length. The pandas frames are converted into Dataset objects, tokenization is applied in batches for speed, and the dataset columns are formatted as PyTorch tensors. The model is loaded with a task-specific head sized to three classes and placed on CPU or GPU, depending on availability. These steps ensure that both backbones present the same interface to the training loop.\n",
        "\n",
        "**`Line-by-line Description`**\n",
        "\n",
        "`from datasets import Dataset` and `from transformers import AutoTokenizer, AutoModelForSequenceClassification` load dataset and model utilities.\n",
        "\n",
        "`MODEL_CHOICES = {...}` defines a readable switch between multilingual and Tagalog-prior encoders.\n",
        "\n",
        "`MODEL_CHOICE = 'xlmrb'` selects the active key, and `MODEL_NAME = MODEL_CHOICES[MODEL_CHOICE]` resolves it to a full identifier.\n",
        "\n",
        "`print('Using model:', MODEL_NAME)` documents the chosen model in the runtime log.\n",
        "\n",
        "`MAX_LEN = 128` sets a fixed sequence length to control memory and speed.\n",
        "\n",
        "`tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)` loads the matching fast tokenizer for efficient token handling.\n",
        "\n",
        "`def tok(batch): return tokenizer(batch['review'], truncation=True, padding='max_length', max_length=MAX_LEN)` defines a reusable tokenization function that enforces consistent length.\n",
        "\n",
        "`ds_train = Dataset.from_pandas(train_df[['review','label']].reset_index(drop=True))` and the similar line for validation convert pandas frames into Dataset objects with only the needed columns.\n",
        "\n",
        "`ds_train = ds_train.map(tok, batched=True)` applies tokenization in batches to speed up preprocessing.\n",
        "\n",
        "`ds_train = ds_train.with_format('torch', columns=['input_ids','attention_mask','label'])` and the matching line for validation expose tensors that the trainer consumes.\n",
        "\n",
        "`num_labels = 3` sets the number of sentiment classes.\n",
        "\n",
        "`model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=num_labels).to(device)` loads the encoder with a classification head and moves it to CPU or GPU.\n"
      ],
      "metadata": {
        "id": "AXiJwfJkDZ_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "MODEL_CHOICES = {\n",
        "    \"xlmrb\": \"xlm-roberta-base\",\n",
        "    \"roberta-tl\": \"jcblaise/roberta-tagalog-base\",\n",
        "}\n",
        "MODEL_CHOICE = \"xlmrb\"\n",
        "MODEL_NAME = MODEL_CHOICES[MODEL_CHOICE]\n",
        "print(\"Using model:\", MODEL_NAME)\n",
        "\n",
        "MAX_LEN = 128\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
        "\n",
        "def tokenize_fn(batch):\n",
        "    return tokenizer(batch[\"review\"], truncation=True, padding=\"max_length\", max_length=MAX_LEN)\n",
        "\n",
        "ds_train = Dataset.from_pandas(train_df[['review','label']].reset_index(drop=True))\n",
        "ds_val   = Dataset.from_pandas(val_df[['review','label']].reset_index(drop=True))\n",
        "\n",
        "ds_train = ds_train.map(tokenize_fn, batched=True)\n",
        "ds_val   = ds_val.map(tokenize_fn, batched=True)\n",
        "\n",
        "cols = ['input_ids','attention_mask','label']\n",
        "ds_train = ds_train.with_format(\"torch\", columns=cols)\n",
        "ds_val   = ds_val.with_format(\"torch\", columns=cols)\n",
        "\n",
        "num_labels = 3\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=num_labels).to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "7eaaec20b70143ac9f4e868c38f38868",
            "d71b086c9c084d41b84f7021cfaa2509",
            "f826e2282aa1452ab047f599ab021bdd",
            "6a36b47d00f94c7fb0e0c1916bff0ddd",
            "945071247eb9401f89a86c1187674d2b",
            "9af91d01919f4ed0959e78a611c48af9",
            "c6813cedd2734aa49568f77b34a03390",
            "c53405f4e37f48e6b8794a50c643b427",
            "7236363ce5994eaeb7cc54910cf9291e",
            "7b4591be3e7848fba83e82a98c6aa804",
            "4bc8f1fcc5fd463b88bdfdd94d1224de",
            "2263361c4ee24175bb5b358b499e02ba",
            "f8a0d29a07e24d819932cb052d6d6a30",
            "85c7681bb5734c20bfcc9ebb04f9ed4b",
            "bcc62de3996c463d8c8b1f2d3fcc2428",
            "21118bd02d16497e9769198124c6f61e",
            "6d72af8623a747a6a4366dd042821573",
            "4015b29276de4b2db4f620ca62fc028b",
            "757efcf76053456a81034fa5253b8ebf",
            "227586f192df479a993bb806033bbd1d",
            "7ac98116b5b44093ac733b0818c80eb9",
            "0923bdc9f5c8459491c9e8275ddc3050"
          ]
        },
        "id": "hZEoStUoYddB",
        "outputId": "ce32729d-7d53-4ecd-fe65-3579a82e1e5e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using model: xlm-roberta-base\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/5872 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7eaaec20b70143ac9f4e868c38f38868"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1468 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2263361c4ee24175bb5b358b499e02ba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training arguments, metric function, and Trainer construction**"
      ],
      "metadata": {
        "id": "JEsbkL2IG9kO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`Purpose`**\n",
        "\n",
        "This block defines how progress will be measured and how training will proceed. It establishes a metric function that reports macro-F1 and accuracy, builds a version-safe set of training arguments, and constructs a Trainer object that ties the model, data, tokenizer, arguments, and metrics into a single training interface.\n",
        "\n",
        "**`Input`**\n",
        "\n",
        "Inputs include the tokenized datasets, the initialized model and tokenizer, and hyperparameters such as number of epochs, batch sizes, learning rate, weight decay, and evaluation cadence. The argument builder reads the current library signature to set compatible fields for evaluation and saving strategies.\n",
        "\n",
        "**`Output`**\n",
        "\n",
        "The cell prints a confirmation that the trainer is ready and includes the active model name. Internally, it prepares all objects required for training and evaluation so that the next call can start optimization without additional setup.\n",
        "\n",
        "**`Details`**\n",
        "\n",
        "A compute function converts raw model outputs into predicted labels and compares them with gold labels to obtain macro-F1 and accuracy. A helper builds a dictionary of training arguments and adapts it to the current version of the library so that required keys are set correctly. Optional mixed-precision is enabled when a GPU is available. The finalized arguments, datasets, and tokenizer are passed into Trainer, which centralizes the fit loop, evaluation, and checkpointing steps under a consistent API.\n",
        "\n",
        "\n",
        "**`Line-by-line Description`**\n",
        "\n",
        "`import numpy as np, inspect` pulls in numerical tools and reflection utilities.\n",
        "\n",
        "`from transformers import TrainingArguments, Trainer` imports the high-level training API.\n",
        "\n",
        "`def compute_metrics(eval_pred): ...` defines the scoring routine that returns macro-F1 and accuracy for evaluation and model selection.\n",
        "\n",
        "`sig = inspect.signature(TrainingArguments.__init__)` captures the current constructor signature so keys can be set compatibly.\n",
        "\n",
        "`def make_training_args(**overrides):` creates a helper that merges sensible defaults with any overrides provided later. Inside the helper, the dictionary sets outputs, epochs, batch sizes, learning rate, weight decay, warmup, scheduler, accumulation steps, best-model selection, seed, logging interval, and reporting target.\n",
        "\n",
        "The following `if` blocks map evaluation and saving keys to whatever names the current library expects, and another branch sets `fp16` if a GPU is present.\n",
        "\n",
        "`training_args = make_training_args()` creates a baseline configuration, and `trainer = Trainer(...)` binds the model, arguments, datasets, tokenizer, and metric function together.\n",
        "\n",
        "`print('Trainer ready on', MODEL_NAME)` confirms that the training interface is assembled and names the backbone in use.\n"
      ],
      "metadata": {
        "id": "qBYE28ApDjp7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    preds = np.argmax(eval_pred.predictions, axis=1)\n",
        "    labels = eval_pred.label_ids\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    f1m = f1_score(labels, preds, average='macro')\n",
        "    return {'accuracy': acc, 'f1_macro': f1m}\n",
        "\n",
        "import inspect\n",
        "sig = inspect.signature(TrainingArguments.__init__)\n",
        "argnames = set(sig.parameters.keys())\n",
        "\n",
        "def make_training_args(**overrides):\n",
        "    cfg = dict(\n",
        "        output_dir=\"./results\",\n",
        "        num_train_epochs=3,                 # Candelaria\n",
        "        per_device_train_batch_size=16,     # Candelaria\n",
        "        per_device_eval_batch_size=32,\n",
        "        learning_rate=5e-5,                 # Candelaria\n",
        "        weight_decay=0.01,                  # Posadas\n",
        "        warmup_steps=500,                   # Posadas\n",
        "        lr_scheduler_type=\"linear\",         # Posadas\n",
        "        gradient_accumulation_steps=1,      # Tumulak\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"f1_macro\",   # Tumulak\n",
        "        seed=42,                            # Tumulak\n",
        "        logging_steps=100,\n",
        "        report_to=[]\n",
        "    )\n",
        "    cfg.update(overrides)\n",
        "\n",
        "    if \"evaluation_strategy\" in argnames:\n",
        "        cfg[\"evaluation_strategy\"] = cfg.get(\"evaluation_strategy\",\"epoch\")\n",
        "    elif \"eval_strategy\" in argnames:\n",
        "        cfg[\"eval_strategy\"] = cfg.get(\"eval_strategy\",\"epoch\")\n",
        "    else:\n",
        "        cfg[\"eval_steps\"] = cfg.get(\"eval_steps\", 500)\n",
        "\n",
        "    if \"save_strategy\" in argnames:\n",
        "        cfg[\"save_strategy\"] = cfg.get(\"save_strategy\",\"epoch\")\n",
        "    else:\n",
        "        cfg[\"save_steps\"] = cfg.get(\"save_steps\", 500)\n",
        "\n",
        "    if \"fp16\" in argnames:\n",
        "        cfg[\"fp16\"] = bool(torch.cuda.is_available()) if \"fp16\" not in cfg else cfg[\"fp16\"]\n",
        "\n",
        "    safe_cfg = {k:v for k,v in cfg.items() if k in argnames}\n",
        "    return TrainingArguments(**safe_cfg)\n",
        "\n",
        "training_args = make_training_args()\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=ds_train,\n",
        "    eval_dataset=ds_val,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "print(\"Trainer ready on:\", MODEL_NAME)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "TschWlUwZBIo",
        "outputId": "355111ad-b55c-4725-af52-00eba7636d3f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainer ready on: xlm-roberta-base\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-139214311.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Fast-mode bootstrap for quick sweeps**"
      ],
      "metadata": {
        "id": "EzQvyLLRG6KH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`Purpose`**\n",
        "\n",
        "This block prepares a quick sweep mode that reduces run time while preserving the validation set. It defines default values for epochs, batch size, and evaluation steps if they are missing, creates a smaller training subset, and optionally attaches early stopping. The intent is to identify promising settings rapidly before running a full configuration.\n",
        "\n",
        "**`Input`**\n",
        "\n",
        "Inputs are the full tokenized training and validation datasets along with optional global variables for the number of epochs, batch size, and evaluation interval. No changes are made to the validation set so that results remain comparable.\n",
        "\n",
        "**`Output`**\n",
        "\n",
        "The block prints a short summary line that shows the chosen values for epochs, batch size, evaluation steps, and the size of the reduced training subset. These values explain why later training progress appears shorter and help distinguish a sweep run from a full run.\n",
        "\n",
        "**`Details`**\n",
        "\n",
        "A fraction of the training set is selected to form a smaller dataset while leaving the validation set intact. A callback for early stopping is attached when available so the loop can halt once improvement stalls. The printed message confirms the configuration and the subset size so that log viewers can interpret run time and scores in context.\n",
        "\n",
        "\n",
        "**`Line-by-line Description`**\n",
        "\n",
        "`from transformers import EarlyStoppingCallback` is imported when available to stop training when validation does not improve.\n",
        "\n",
        "`FAST_TRAIN = False` sets the default to full training unless quick sweeps are desired.\n",
        "\n",
        "`TRAIN_FRACTION`, `NEW_MAX_LEN`, `EPOCHS`, `BATCH`, and `EVAL_STEPS` define compact settings that shorten training and evaluation cycles.\n",
        "\n",
        "The `if FAST_TRAIN:` branch selects a prefix of the training dataset with `ds_train.select(range(n))`, leaving the validation data untouched.\n",
        "\n",
        "`overrides = dict(...)` sets fewer epochs, a larger batch, zero warmup, evaluation every fixed number of steps, and a shorter logging interval so progress is visible without heavy overhead.\n",
        "\n",
        "`fast_args = make_training_args(**overrides)` rebuilds the training arguments specifically for fast mode.\n",
        "\n",
        "`callbacks = [EarlyStoppingCallback(...)] if HAVE_ES else None` attaches a simple stopping rule when supported.\n",
        "\n",
        "`trainer = Trainer(model=model, args=fast_args, train_dataset=ds_train_fast, ...)` re-instantiates the trainer to use the fast subsets.\n",
        "\n",
        "The final `print` statement reports the reduced training size so the reader knows this run is a sweep.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "thTkK_iBDqrM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "m-z3wCGgYW7k",
        "outputId": "22248020-95b7-48ec-ee7f-8834d6998bd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[BOOTSTRAP] EPOCHS=1, BATCH=32, EVAL_STEPS=200, train_fast=1174 / 5872\n"
          ]
        }
      ],
      "source": [
        "import math, numpy as np\n",
        "from transformers import Trainer\n",
        "\n",
        "EPOCHS = globals().get('EPOCHS', 1)\n",
        "BATCH = globals().get('BATCH', 32)\n",
        "EVAL_STEPS = globals().get('EVAL_STEPS', 200)\n",
        "TRAIN_FRACTION = globals().get('TRAIN_FRACTION', 0.20)\n",
        "\n",
        "if 'ds_train_fast' not in globals():\n",
        "    assert 'ds_train' in globals() and 'ds_val' in globals(), \"Need ds_train/ds_val first.\"\n",
        "    n_fast = max(8, int(len(ds_train) * TRAIN_FRACTION))\n",
        "    ds_train_fast = ds_train.select(range(n_fast))\n",
        "    ds_val_fast = ds_val\n",
        "\n",
        "callbacks = globals().get('callbacks', None)\n",
        "if callbacks is None:\n",
        "    try:\n",
        "        from transformers import EarlyStoppingCallback\n",
        "        callbacks = [EarlyStoppingCallback(early_stopping_patience=1)]\n",
        "    except Exception:\n",
        "        callbacks = None\n",
        "\n",
        "print(f\"[BOOTSTRAP] EPOCHS={EPOCHS}, BATCH={BATCH}, EVAL_STEPS={EVAL_STEPS}, \"\n",
        "      f\"train_fast={len(ds_train_fast)} / {len(ds_train)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train, evaluate, save, and append to the run log**"
      ],
      "metadata": {
        "id": "Dzl1-YjqG1Vs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`Purpose`**\n",
        "\n",
        "This block performs the actual fine-tuning, evaluates on the validation split, saves the trained checkpoint and tokenizer for later use, and writes a structured record of the run to the experiment log. It captures both on-screen feedback and durable artifacts needed for reporting and replication.\n",
        "\n",
        "**`Input`**\n",
        "\n",
        "Inputs include the Trainer instance, which encapsulates the model, datasets, and arguments. The training arguments determine the number of epochs, batch sizes, learning rate, and scheduling behavior. No additional inputs are required once the trainer has been built.\n",
        "\n",
        "**`Output`**\n",
        "\n",
        "The cell prints the evaluation dictionary containing accuracy and macro-F1, writes the model and tokenizer to a versioned folder named after the backbone, and appends a new row to runs_log.csv that contains the hyperparameters, scores, and a note string. These outputs provide both a human-readable summary and a machine-readable record.\n",
        "\n",
        "**`Details`**\n",
        "\n",
        "The call to train() runs the optimization loop and tracks progress according to the evaluation strategy. The call to evaluate() computes metrics on the fixed validation set using the same metric function defined earlier. The model and tokenizer are saved together so that future inference uses the exact same text processing. A dictionary is assembled with the run configuration and evaluation scores, then written as a new log row with consistent column names to support later aggregation and sorting.\n",
        "\n",
        "**`Line-by-line Description`**\n",
        "\n",
        "`train_out = trainer.train()` runs the optimization loop and shows progress updates and evaluation checkpoints as configured.\n",
        "\n",
        "`eval_results = trainer.evaluate()` computes macro-F1 and accuracy on the validation set using the shared metric function.\n",
        "\n",
        "`print('Eval:', eval_results)` surfaces the summary in the notebook output for quick inspection.\n",
        "\n",
        "`save_dir = f\\\"./finetuned_{MODEL_NAME.replace('/','_')}_best\\\"` constructs a folder name that is safe for filesystems.\n",
        "\n",
        "`trainer.save_model(save_dir)` and `tokenizer.save_pretrained(save_dir)` write the necessary artifacts for future use.\n",
        "\n",
        "The `row = {...}` dictionary collects hyperparameters and scores, and the `with open('runs_log.csv','a',...)` block appends the record, adding headers if the file is new.\n",
        "\n",
        "`print('Logged:', row['model'])` confirms that the run has been recorded.\n"
      ],
      "metadata": {
        "id": "TasFTWZhDwf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_out = trainer.train()\n",
        "eval_results = trainer.evaluate()\n",
        "print(\"Eval:\", eval_results)\n",
        "\n",
        "save_dir = f\"./finetuned_{MODEL_NAME.replace('/','_')}_best\"\n",
        "trainer.save_model(save_dir)\n",
        "tokenizer.save_pretrained(save_dir)\n",
        "\n",
        "row = {\n",
        "    \"member\":\"team\",\n",
        "    \"model\": MODEL_NAME,\n",
        "    \"num_train_epochs\": float(getattr(training_args, \"num_train_epochs\", np.nan)),\n",
        "    \"per_device_train_batch_size\": int(getattr(training_args, \"per_device_train_batch_size\", np.nan)),\n",
        "    \"learning_rate\": float(getattr(training_args, \"learning_rate\", np.nan)),\n",
        "    \"weight_decay\": float(getattr(training_args, \"weight_decay\", np.nan)),\n",
        "    \"warmup_steps\": int(getattr(training_args, \"warmup_steps\", np.nan)),\n",
        "    \"lr_scheduler_type\": str(getattr(training_args, \"lr_scheduler_type\", \"\")),\n",
        "    \"gradient_accumulation_steps\": int(getattr(training_args, \"gradient_accumulation_steps\", np.nan)),\n",
        "    \"max_seq_length\": MAX_LEN,\n",
        "    \"seed\": int(getattr(training_args, \"seed\", 42)),\n",
        "    \"fp16\": bool(getattr(training_args, \"fp16\", False)),\n",
        "    \"accuracy\": float(eval_results.get(\"eval_accuracy\", np.nan)),\n",
        "    \"f1_macro\": float(eval_results.get(\"eval_f1_macro\", np.nan)),\n",
        "    \"notes\":\"EF1 Transformers fine-tune\"\n",
        "}\n",
        "pd.DataFrame([row]).to_csv(\"runs_log.csv\", mode=\"a\",\n",
        "                           index=False, header=not os.path.exists(\"runs_log.csv\"))\n",
        "print(\"Logged run for:\", MODEL_NAME)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "id": "GvP-1u1sZMv1",
        "outputId": "2e12a26b-d493-4774-fd14-7f2857f8d467"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='368' max='1101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 368/1101 2:27:45 < 4:55:56, 0.04 it/s, Epoch 1/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='32' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [32/46 06:51 < 03:05, 0.08 it/s]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Inference sanity check with a small pipeline**"
      ],
      "metadata": {
        "id": "xOYlxuQqGxnp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`Purpose`**\n",
        "\n",
        "This block performs a quick, human-readable check that the saved model can process fresh text and return reasonable labels. It creates a simple text-classification pipeline and runs a few short sentences through it to confirm label behavior. This step helps validate that training produced a usable artifact.\n",
        "\n",
        "**`Input`**\n",
        "\n",
        "The inputs are the saved model and tokenizer from the previous step and a small list of short review sentences that represent common positive, neutral, and negative tones. The device is chosen automatically based on GPU availability to keep the call simple.\n",
        "\n",
        "**`Output`**\n",
        "\n",
        "The code prints each input sentence followed by the predicted label and a confidence score. These lines provide a quick visual confirmation that positive lines map to positive labels and complaint-style text maps to negative labels, with neutral sitting in between.\n",
        "\n",
        "**`Details`**\n",
        "\n",
        "A pipeline wrapper loads the classification head and tokenizer and applies them to each sample string. The outputs are dictionaries containing the predicted label index and score. The format is concise and easy to read, which makes it suitable for inclusion in a report as a small qualitative check beside the quantitative metrics.\n",
        "\n",
        "**`Line-by-line Description`**\n",
        "\n",
        "`from transformers import pipeline` imports the high-level inference interface.\n",
        "\n",
        "`clf = pipeline('text-classification', model=save_dir, tokenizer=tokenizer, device=0 if torch.cuda.is_available() else -1)` loads the saved classifier and sets the device index for GPU or CPU.\n",
        "\n",
        "`samples = [...]` prepares a short list of example sentences that cover different sentiments.\n",
        "\n",
        "`for t, p in zip(samples, clf(samples)):` iterates over inputs and predictions together to print a clean pairing.\n",
        "\n",
        "`print(t, '->', p)` produces human-readable lines that show the predicted label and score for each sample."
      ],
      "metadata": {
        "id": "rGmm4xUyD4oF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "sentiment_analyzer = pipeline(\n",
        "    \"text-classification\", model=model, tokenizer=tokenizer, device=0 if torch.cuda.is_available() else -1\n",
        ")\n",
        "\n",
        "samples = [\n",
        "    \"Ang bilis ng delivery, pero sira yung box.\",\n",
        "    \"solid yung quality, sakto ang size. sulit!\",\n",
        "    \"medyo pangit yung tela, tapos delay pa courier :(\"\n",
        "]\n",
        "preds = sentiment_analyzer(samples)\n",
        "for t, r in zip(samples, preds):\n",
        "    print(f\"{t}\\n -> {r}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ed6AdjXcilJO",
        "outputId": "b0d50c82-87c3-4393-90b3-80a473a5609a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ang bilis ng delivery, pero sira yung box.\n",
            " -> {'label': 'LABEL_0', 'score': 0.4898853600025177}\n",
            "\n",
            "solid yung quality, sakto ang size. sulit!\n",
            " -> {'label': 'LABEL_2', 'score': 0.7228704690933228}\n",
            "\n",
            "medyo pangit yung tela, tapos delay pa courier :(\n",
            " -> {'label': 'LABEL_0', 'score': 0.5115751624107361}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Confusion matrix and per-class report**"
      ],
      "metadata": {
        "id": "Xx7vWRVrGsDF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`Purpose`**\n",
        "\n",
        "This block explains where the model succeeds and where it struggles by producing a confusion matrix and a per-class table. It complements the single macro-F1 score with a breakdown across negative, neutral, and positive classes, which supports targeted analysis of errors.\n",
        "\n",
        "**`Input`**\n",
        "\n",
        "The inputs are the validation dataset and the trained model encapsulated by the trainer. Predictions are obtained as raw scores, which are converted to class labels before building the matrix and the report.\n",
        "\n",
        "**`Output`**\n",
        "\n",
        "The block displays a color-mapped confusion matrix with counts for each true–predicted pair and prints a classification report that includes precision, recall, and F1 per class, plus macro and weighted averages. These outputs make it easy to identify common confusions, such as neutral being mistaken for positive or negative.\n",
        "\n",
        "**`Details`**\n",
        "\n",
        "The trainer produces predictions and gold labels, which are turned into a confusion matrix using a fixed label order so the axes are stable across runs. The figure is annotated with counts for clarity. The classification report quantifies performance for each class, and the macro averages summarize balance across classes. The combination of figure and table supports discussion of error sources and improvements from hyperparameter changes.\n",
        "\n",
        "**`Line-by-line Description`**\n",
        "\n",
        "`import matplotlib.pyplot as plt` brings in plotting functions for the confusion matrix.\n",
        "\n",
        "`from sklearn.metrics import confusion_matrix, classification_report` imports evaluation tools for structured summaries.\n",
        "\n",
        "`pred = trainer.predict(ds_val)` gathers raw predictions and gold labels in one call.\n",
        "\n",
        "`y_true = pred.label_ids` extracts the ground truth, and `y_pred = np.argmax(pred.predictions, axis=1)` converts scores to label indices.\n",
        "\n",
        "`cm = confusion_matrix(y_true, y_pred, labels=[0,1,2])` builds the matrix with a stable label order.\n",
        "\n",
        "The next group of lines creates a figure, renders the matrix, sets axis titles and tick names, and writes counts into each cell for clarity.\n",
        "\n",
        "`report = classification_report(..., output_dict=True)` computes per-class precision, recall, and F1 plus macro and weighted averages.\n",
        "\n",
        "`pd.DataFrame(report).transpose()` presents the report as a table that can be sorted or exported if needed."
      ],
      "metadata": {
        "id": "8jSu0hb3D-6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "pred = trainer.predict(ds_val)\n",
        "y_true = pred.label_ids\n",
        "y_pred = np.argmax(pred.predictions, axis=1)\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred, labels=[0,1,2])\n",
        "plt.figure()\n",
        "plt.imshow(cm, interpolation='nearest')\n",
        "plt.title('Confusion Matrix (Val)')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.xticks([0,1,2], ['neg','neu','pos'])\n",
        "plt.yticks([0,1,2], ['neg','neu','pos'])\n",
        "for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        plt.text(j, i, cm[i, j], ha='center', va='center')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "report = classification_report(y_true, y_pred, labels=[0,1,2],\n",
        "                               target_names=['negative','neutral','positive'],\n",
        "                               output_dict=True)\n",
        "df_report = pd.DataFrame(report).transpose()\n",
        "df_report\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762
        },
        "id": "YndcMJ2Bio64",
        "outputId": "b05592a1-b82a-402e-fc4a-1f889f9eb88f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              precision    recall  f1-score      support\n",
              "negative       0.534884  0.724790  0.615522   476.000000\n",
              "neutral        0.485981  0.203922  0.287293   510.000000\n",
              "positive       0.658456  0.831950  0.735105   482.000000\n",
              "accuracy       0.579019  0.579019  0.579019     0.579019\n",
              "macro avg      0.559774  0.586887  0.545973  1468.000000\n",
              "weighted avg   0.558468  0.579019  0.540755  1468.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f34d6eb0-9c78-4fe7-bfaa-67d34ea39d6a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>support</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>negative</th>\n",
              "      <td>0.534884</td>\n",
              "      <td>0.724790</td>\n",
              "      <td>0.615522</td>\n",
              "      <td>476.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>0.485981</td>\n",
              "      <td>0.203922</td>\n",
              "      <td>0.287293</td>\n",
              "      <td>510.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>0.658456</td>\n",
              "      <td>0.831950</td>\n",
              "      <td>0.735105</td>\n",
              "      <td>482.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>accuracy</th>\n",
              "      <td>0.579019</td>\n",
              "      <td>0.579019</td>\n",
              "      <td>0.579019</td>\n",
              "      <td>0.579019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>macro avg</th>\n",
              "      <td>0.559774</td>\n",
              "      <td>0.586887</td>\n",
              "      <td>0.545973</td>\n",
              "      <td>1468.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weighted avg</th>\n",
              "      <td>0.558468</td>\n",
              "      <td>0.579019</td>\n",
              "      <td>0.540755</td>\n",
              "      <td>1468.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f34d6eb0-9c78-4fe7-bfaa-67d34ea39d6a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f34d6eb0-9c78-4fe7-bfaa-67d34ea39d6a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f34d6eb0-9c78-4fe7-bfaa-67d34ea39d6a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d2c3046f-9af6-4aac-868c-175f3ce36f54\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d2c3046f-9af6-4aac-868c-175f3ce36f54')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d2c3046f-9af6-4aac-868c-175f3ce36f54 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_d24ed1c1-eebd-468f-90e2-94334b82b883\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_report')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d24ed1c1-eebd-468f-90e2-94334b82b883 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_report');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_report",
              "summary": "{\n  \"name\": \"df_report\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05678303789950534,\n        \"min\": 0.48598130841121495,\n        \"max\": 0.6584564860426929,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.5348837209302325,\n          0.48598130841121495,\n          0.5584680822377985\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.21251741358066809,\n        \"min\": 0.20392156862745098,\n        \"max\": 0.8319502074688797,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.20392156862745098,\n          0.5868872306875724,\n          0.8319502074688797\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1-score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14731852235496515,\n        \"min\": 0.287292817679558,\n        \"max\": 0.7351054078826764,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.6155218554861731,\n          0.287292817679558,\n          0.5407551408906287\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"support\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 599.2766104873285,\n        \"min\": 0.5790190735694822,\n        \"max\": 1468.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          510.0,\n          1468.0,\n          482.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Export of consolidated logs and model summaries**"
      ],
      "metadata": {
        "id": "7hufxTwCGmOE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`Purpose`**\n",
        "\n",
        "This block consolidates the experiment ledger into export files that support grading and documentation. It merges local runs with any team template, sorts them by macro-F1, and writes CSV and spreadsheet versions, along with summary tables for “best by model,” “runs per model,” and the “top ten by macro-F1.”\n",
        "\n",
        "**`Input`**\n",
        "\n",
        "The inputs are runs_log.csv produced by previous training cells and an optional Experiment_Log_Template.xlsx if a group sheet is in use. The code aligns column names and merges tables so that both personal and team entries appear together.\n",
        "\n",
        "**`Output`**\n",
        "\n",
        "The block writes exports/Experiment_Runs_All.csv and .xlsx, as well as Best_by_Model, Runs_per_Model, and Top10_by_F1 files in both CSV and Excel formats when possible. A short message confirms export success. These files are suitable for inclusion as appendix tables and as sources for figures.\n",
        "\n",
        "**`Details`**\n",
        "\n",
        "The merged table is sorted by macro-F1 to surface the strongest runs first. A “best by model” table keeps only the top row per backbone to support quick comparisons in the Results section. A “runs per model” count shows coverage across backbones. A “top ten by F1” slice provides a quick list of leading configurations for screenshots. The exports follow stable column names so that downstream formatting or conditional coloring in spreadsheets is straightforward.\n",
        "\n",
        "**`Line-by-line Description`**\n",
        "\n",
        "`from pathlib import Path` prepares folder handling, and `outdir = Path('exports'); outdir.mkdir(exist_ok=True)` ensures the output directory exists.\n",
        "\n",
        "`df_runs = pd.read_csv('runs_log.csv') if os.path.exists('runs_log.csv') else pd.DataFrame()` loads the personal ledger or falls back to an empty table.\n",
        "\n",
        "The branch that checks `Experiment_Log_Template.xlsx` merges a team sheet when available, aligns columns, and creates a unified table.\n",
        "\n",
        "`if not df_all.empty:` guards the export steps so that the code only writes files when there is data to save.\n",
        "\n",
        "`df_all = df_all.sort_values('f1_macro', ascending=False)` places the highest macro-F1 at the top.\n",
        "\n",
        "`df_all.to_csv(...)` and `df_all.to_excel(...)` write consolidated logs for easy sharing.\n",
        "\n",
        "The next group builds `best_by_model` by keeping the top row per backbone, writes it out, and creates a `rpm` count of runs per model."
      ],
      "metadata": {
        "id": "SMIh-NzUEEdZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "outdir = Path('exports'); outdir.mkdir(exist_ok=True)\n",
        "\n",
        "df_runs = pd.read_csv('runs_log.csv') if os.path.exists('runs_log.csv') else pd.DataFrame()\n",
        "if os.path.exists('Experiment_Log_Template.xlsx'):\n",
        "    df_team = pd.read_excel('Experiment_Log_Template.xlsx')\n",
        "    for d in (df_runs, df_team):\n",
        "        d.columns = [str(c).strip().lower() for c in d.columns]\n",
        "    all_cols = sorted(set(df_runs.columns) | set(df_team.columns))\n",
        "    df_runs = df_runs.reindex(columns=all_cols)\n",
        "    df_team = df_team.reindex(columns=all_cols)\n",
        "    df_all = pd.concat([df_team, df_runs], ignore_index=True).drop_duplicates()\n",
        "else:\n",
        "    df_all = df_runs\n",
        "\n",
        "if not df_all.empty:\n",
        "    if 'f1_macro' in df_all.columns:\n",
        "        df_all = df_all.sort_values(by='f1_macro', ascending=False)\n",
        "    df_all.to_csv(outdir/'Experiment_Runs_All.csv', index=False)\n",
        "    try:\n",
        "        df_all.to_excel(outdir/'Experiment_Runs_All.xlsx', index=False)\n",
        "    except Exception as e:\n",
        "        print(\"Excel export error:\", e)\n",
        "\n",
        "    if 'model' in df_all.columns and 'f1_macro' in df_all.columns:\n",
        "        best_by_model = df_all.sort_values('f1_macro', ascending=False).drop_duplicates(subset=['model'])\n",
        "        best_by_model.to_csv(outdir/'Best_by_Model.csv', index=False)\n",
        "        best_by_model.to_excel(outdir/'Best_by_Model.xlsx', index=False)\n",
        "\n",
        "        rpm = df_all['model'].value_counts().rename_axis('model').reset_index(name='runs')\n",
        "        rpm.to_csv(outdir/'Runs_per_Model.csv', index=False)\n",
        "        rpm.to_excel(outdir/'Runs_per_Model.xlsx', index=False)\n",
        "\n",
        "    if 'f1_macro' in df_all.columns:\n",
        "        top10 = df_all.head(10)\n",
        "        top10.to_csv(outdir/'Top10_by_F1.csv', index=False)\n",
        "        top10.to_excel(outdir/'Top10_by_F1.xlsx', index=False)\n",
        "    print(\"Exported logs to exports/.\")\n",
        "else:\n",
        "    print(\"No logs found yet.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrk3KgeMiroD",
        "outputId": "043bd056-1e2b-4f25-fc8a-537d68367395"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported logs to exports/.\n"
          ]
        }
      ]
    }
  ]
}