{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIiqkobxHKGk"
      },
      "source": [
        "# **Setup, imports, dataset load, and split**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSZSQ3nPC3sL"
      },
      "source": [
        "**`Purpose`**\n",
        "\n",
        "This block prepares the environment and dataset so all later experiments are reproducible and fast to run. It first ensures required Python packages are available (PyTorch, Transformers, Datasets, Accelerate, Optuna, scikit-learn, pandas, numpy, matplotlib, openpyxl). It then loads your FiReCS dataset (expects review for text and label for the class), normalizes column names to lowercase, removes incomplete rows, enforces integer labels, and assigns each row a stable id. Finally, it performs a stratified train/validation split to preserve class balance between splits and writes the split IDs to disk so every subsequent run evaluates on the same examples. This guarantees your automated search (Grid vs Random) compares configurations on a fixed and fair validation set.\n",
        "\n",
        "The block also prints class-proportion checks for both splits. This is a quick sanity step to verify stratification worked (the class distribution in train and validation should be similar). By saving train_ids.csv and val_ids.csv, the notebook downstream can reload the exact splits even if the full dataset is reloaded or preprocessed again—keeping your F2 and F3 experiments consistent. members.\n",
        "\n",
        "**`Input`**\n",
        "\n",
        "- A CSV (e.g., `FiReCS.csv`) in the working directory with columns:\n",
        "  - `review` — the text\n",
        "  - `label` — class encoded as 0/1/2  \n",
        "- Permission to install any missing Python packages (the cell will only install if imports fail).\n",
        "\n",
        "**`Output`**\n",
        "\n",
        "- Imported libraries ready for use.\n",
        "- In-memory DataFrames:\n",
        "  - `df` → cleaned full dataset (integer `label`, added `id`)\n",
        "  - `train_df`, `val_df` → stratified 80/20 split\n",
        "- Printed normalized class distributions for train/val.\n",
        "- Reproducibility files:\n",
        "  - `train_ids.csv` (column: `id`)\n",
        "  - `val_ids.csv` (column: `id`)\n",
        "\n",
        "\n",
        "**`Line-by-line Description.`**\n",
        "- **Package bootstrap**\n",
        "  - `import subprocess, sys` — utilities to call `pip` if a package is missing.\n",
        "  - `packages_map = [(\"torch\",\"torch\"), ..., (\"openpyxl\",\"openpyxl\")]` — maps pip names to import names.\n",
        "  - Loop: try `__import__(import_name)`; on `ImportError`, run `pip install -q <package>` and warn if install fails.\n",
        "\n",
        "- **Core imports**\n",
        "  - `import os, numpy as np, pandas as pd, torch, json, inspect, optuna; from pathlib import Path` — general utilities, arrays, DataFrames, GPU support, JSON/reflection helpers, and Optuna for tuning.\n",
        "  - `from sklearn.model_selection import train_test_split` — stratified splitting utility.\n",
        "\n",
        "- **Load and normalize the dataset**\n",
        "  - `df = pd.read_csv(\"FiReCS.csv\")` — reads the dataset.\n",
        "  - `df = df.rename(columns={c: c.lower() for c in df.columns})` — lowercases column names to standardize on `review` and `label`.\n",
        "  - `assert {'review','label'} <= set(df.columns)` — hard check for expected schema.\n",
        "  - `df = df.dropna(subset=['review','label']).copy()` — removes rows with missing text/label; `copy()` avoids chained assignment issues.\n",
        "  - `df['label'] = df['label'].astype(int)` — ensures labels are 0/1/2 integers.\n",
        "  - `df['id'] = np.arange(len(df))` — adds a unique, stable row identifier for reproducible splits.\n",
        "\n",
        "- **Stratified train/validation split**\n",
        "  - `train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])` — creates an 80/20 split with fixed randomness and preserved class proportions.\n",
        "  - `print(train_df['label'].value_counts(normalize=True).sort_index())` — shows training class ratios.\n",
        "  - `print(val_df['label'].value_counts(normalize=True).sort_index())` — shows validation class ratios.\n",
        "\n",
        "- **Persist split IDs for reproducibility**\n",
        "  - `train_df[['id']].to_csv('train_ids.csv', index=False)` — saves training IDs.\n",
        "  - `val_df[['id']].to_csv('val_ids.csv', index=False)` — saves validation IDs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ej9srJoYd3o",
        "outputId": "5f9eddb7-8087-4706-896d-e4ce67f707b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ torch already installed\n",
            "✓ transformers already installed\n",
            "✓ datasets already installed\n",
            "✓ accelerate already installed\n",
            "✓ optuna already installed\n",
            "✓ scikit-learn already installed\n",
            "✓ pandas already installed\n",
            "✓ numpy already installed\n",
            "✓ matplotlib already installed\n",
            "✓ openpyxl already installed\n",
            "✓ optuna already installed\n",
            "Using device: cuda\n",
            "label\n",
            "0    0.324421\n",
            "1    0.347241\n",
            "2    0.328338\n",
            "Name: proportion, dtype: float64\n",
            "label\n",
            "0    0.324251\n",
            "1    0.347411\n",
            "2    0.328338\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "# Package mapping: (pip_name, import_name)\n",
        "packages_map = [\n",
        "    (\"torch\", \"torch\"),\n",
        "    (\"transformers\", \"transformers\"),\n",
        "    (\"datasets\", \"datasets\"),\n",
        "    (\"accelerate\", \"accelerate\"),\n",
        "    (\"optuna\", \"optuna\"),\n",
        "    (\"scikit-learn\", \"sklearn\"),\n",
        "    (\"pandas\", \"pandas\"),\n",
        "    (\"numpy\", \"numpy\"),\n",
        "    (\"matplotlib\", \"matplotlib\"),\n",
        "    (\"openpyxl\", \"openpyxl\"),\n",
        "    (\"optuna\", \"optuna\"),\n",
        "]\n",
        "\n",
        "for pip_name, import_name in packages_map:\n",
        "    try:\n",
        "        __import__(import_name)\n",
        "        print(f\"✓ {pip_name} already installed\")\n",
        "    except ImportError:\n",
        "        print(f\"Installing {pip_name}...\")\n",
        "        try:\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pip_name],\n",
        "                                stdout=subprocess.DEVNULL, stderr=subprocess.PIPE)\n",
        "            print(f\"✓ {pip_name} installed successfully\")\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"⚠ Warning: Could not install {pip_name}. You may need to install it manually.\")\n",
        "\n",
        "import os, numpy as np, pandas as pd, torch, json, inspect, optuna\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import optuna\n",
        "\n",
        "# Optional Colab support\n",
        "try:\n",
        "    from google.colab import files\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "    files = None\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "if not os.path.exists(\"FiReCS.csv\"):\n",
        "    if IN_COLAB and files is not None:\n",
        "        uploaded = files.upload()\n",
        "    else:\n",
        "        raise FileNotFoundError(\"FiReCS.csv not found. Please ensure the file is in the current directory.\")\n",
        "df = pd.read_csv(\"FiReCS.csv\")\n",
        "\n",
        "df = df.rename(columns={c:c.lower() for c in df.columns})\n",
        "assert {'review','label'} <= set(df.columns), \"CSV must have 'review' and 'label' columns.\"\n",
        "\n",
        "df = df.dropna(subset=['review','label']).copy()\n",
        "df['label'] = df['label'].astype(int)\n",
        "df['id'] = np.arange(len(df))\n",
        "\n",
        "train_df, val_df = train_test_split(\n",
        "    df, test_size=0.2, random_state=42, stratify=df['label']\n",
        ")\n",
        "print(train_df['label'].value_counts(normalize=True).sort_index())\n",
        "print(val_df['label'].value_counts(normalize=True).sort_index())\n",
        "\n",
        "train_df[['id']].to_csv('train_ids.csv', index=False)\n",
        "val_df[['id']].to_csv('val_ids.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--4_ssDysIuA"
      },
      "source": [
        "# Data cleaning and 80/10/10 split (reproducible)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjtuUqb_UEny"
      },
      "source": [
        "#### Purpose / Description\n",
        "This cell cleans the raw text, adds a simple **code-switch ratio** feature for exploratory analysis, and creates a **reproducible** 80/10/10 train–validation–test split. Cleaning removes HTML tags/entities, control characters, extra whitespace, and compresses long letter repeats (e.g., “goooood” → “goood”). It also drops empty texts and exact (text,label) duplicates to avoid leakage. For splits, it writes/loads `train_ids.csv`, `val_ids.csv`, and `test_ids.csv` so every run evaluates the same examples.\n",
        "\n",
        "#### Input\n",
        "- In-memory `df` from an earlier cell with columns: `review`, `label`, and `id`.\n",
        "- Libraries already imported earlier: `os`, `pandas as pd`, `numpy as np`.\n",
        "\n",
        "#### Output\n",
        "- Updated `df` with cleaned `review` and new `cs_ratio` column.\n",
        "- In-memory splits: `df_train`, `df_val`, `df_test`.\n",
        "- Reproducibility files (created if missing): `train_ids.csv`, `val_ids.csv`, `test_ids.csv`.\n",
        "- Printed diagnostics: kept rows after cleaning, split sizes, and label ratios per split.\n",
        "\n",
        "---\n",
        "\n",
        "#### Line-by-Line Explanation\n",
        "\n",
        "`import re, html`  \n",
        "Imports the regular-expression module and HTML utilities (for unescaping entities like `&amp;`).\n",
        "\n",
        "`from collections import Counter`  \n",
        "Brings in a counting helper (available for tallies; not strictly required later).\n",
        "\n",
        "`from sklearn.model_selection import train_test_split`  \n",
        "Imports the function used to make stratified splits of the dataset.\n",
        "\n",
        "`# --- Cleaning helpers ---`  \n",
        "Section comment to mark the start of text-cleaning utilities.\n",
        "\n",
        "`CTRL_RE = re.compile(r\"[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F]\")`  \n",
        "Precompiles a regex that matches non-printable control characters to remove from text.\n",
        "\n",
        "`REPEAT_RE = re.compile(r\"(\\w)\\1{2,}\")`  \n",
        "Precompiles a regex that detects any word character repeated 3+ times (e.g., “heyyy”).\n",
        "\n",
        "`def strip_html(text: str) -> str:`  \n",
        "Begins a helper that strips HTML and unescapes entities from a single text string.\n",
        "\n",
        "`    if not isinstance(text, str):`  \n",
        "Checks the input type to guard against non-string values.\n",
        "\n",
        "`        return \"\"`  \n",
        "Returns an empty string when the input is not a string.\n",
        "\n",
        "`    # unescape HTML entities then drop tags`  \n",
        "Comment describing the two-step HTML cleanup.\n",
        "\n",
        "`    t = html.unescape(text)`  \n",
        "Converts HTML entities to their characters (e.g., `&lt;` → `<`).\n",
        "\n",
        "`    t = re.sub(r\"<[^>]+>\", \" \", t)`  \n",
        "Removes any HTML tags by replacing them with a space.\n",
        "\n",
        "`    return t`  \n",
        "Returns the cleaned string.\n",
        "\n",
        "`def squash_repeats(text: str) -> str:`  \n",
        "Starts a helper that compresses excessive character repetitions.\n",
        "\n",
        "`    return REPEAT_RE.sub(r\"\\1\\1\", text)`  \n",
        "Replaces any 3+ repeats of a character with exactly 2 (keeps tone but reduces noise).\n",
        "\n",
        "`def basic_clean(text: str) -> str:`  \n",
        "Defines a higher-level cleaner that chains multiple cleaning steps.\n",
        "\n",
        "`    t = str(text)`  \n",
        "Casts the input to string to avoid errors with non-string inputs.\n",
        "\n",
        "`    t = strip_html(t)`  \n",
        "Applies HTML unescape and tag removal.\n",
        "\n",
        "`    t = CTRL_RE.sub(\" \", t)`  \n",
        "Removes control characters by replacing them with a space.\n",
        "\n",
        "`    t = re.sub(r\"\\s+\", \" \", t).strip()`  \n",
        "Collapses runs of whitespace to a single space and trims leading/trailing spaces.\n",
        "\n",
        "`    t = squash_repeats(t)`  \n",
        "Compresses long character repeats (e.g., “noooo” → “noo”).\n",
        "\n",
        "`    return t`  \n",
        "Outputs the fully cleaned text.\n",
        "\n",
        "`# Apply cleaning to the loaded df (from earlier cell)`  \n",
        "Comment indicating the cleaning is now applied to the dataset.\n",
        "\n",
        "`df = df.copy()`  \n",
        "Copies the DataFrame to avoid mutating the original reference.\n",
        "\n",
        "`df['review'] = df['review'].astype(str).map(basic_clean)`  \n",
        "Converts all reviews to strings and applies the `basic_clean` function to each one.\n",
        "\n",
        "`# drop empties and exact duplicates`  \n",
        "Comment describing the next pruning steps.\n",
        "\n",
        "`before = len(df)`  \n",
        "Stores the row count before pruning for reporting.\n",
        "\n",
        "`df = df[(df['review'].str.len() > 0)].drop_duplicates(subset=['review','label']).reset_index(drop=True)`  \n",
        "Drops rows with empty `review`, then removes exact duplicates based on (`review`,`label`), and resets the index.\n",
        "\n",
        "`after = len(df)`  \n",
        "Stores the row count after pruning.\n",
        "\n",
        "`print(f\"Cleaned dataset: kept {after}/{before} rows\")`  \n",
        "Logs how many rows remained after cleaning and deduplication.\n",
        "\n",
        "`# Optional: simple code-switch ratio (EDA only)`  \n",
        "Comment introducing a lightweight Taglish code-switching heuristic for exploration.\n",
        "\n",
        "`EN_RE = re.compile(r\"[A-Za-z]{3,}\")`  \n",
        "Regex that matches English-like tokens (alphabetic sequences with length ≥ 3).\n",
        "\n",
        "`TL_HINTS = set([\"po\",\"opo\",\"naman\",\"kuya\",\"ate\",\"nga\",\"na\",\"lang\",\"din\",\"rin\",\"daw\",\"ba\",\"yung\",\"yung\",\"ang\",\"sa\",\"si\",\"ni\",\"kay\",\"sana\",\"wala\",\"meron\",\"sobrang\",\"sobrang\",\"ganda\",\"pang\",\"bilis\",\"salamat\"])  # lightweight hints`  \n",
        "Defines a small set of common Tagalog hint words to approximate Tagalog presence.\n",
        "\n",
        "`def code_switch_ratio(text: str) -> float:`  \n",
        "Begins a helper that estimates English–Tagalog mix in a string.\n",
        "\n",
        "`    tokens = re.findall(r\"\\w+\", text.lower())`  \n",
        "Tokenizes the text into alphanumeric word tokens in lowercase.\n",
        "\n",
        "`    if not tokens:`  \n",
        "Checks for empty token lists.\n",
        "\n",
        "`        return 0.0`  \n",
        "Returns 0 if no tokens were found.\n",
        "\n",
        "`    en_like = sum(1 for tok in tokens if EN_RE.fullmatch(tok) is not None)`  \n",
        "Counts tokens that fully match the English-like regex.\n",
        "\n",
        "`    tl_like = sum(1 for tok in tokens if tok in TL_HINTS)`  \n",
        "Counts tokens that belong to the Tagalog hint set.\n",
        "\n",
        "`    return en_like / max(1, (en_like + tl_like))`  \n",
        "Returns the English proportion over the sum (guarding against division by zero).\n",
        "\n",
        "`df['cs_ratio'] = df['review'].map(code_switch_ratio)`  \n",
        "Creates a new EDA column with the code-switch ratio for each review.\n",
        "\n",
        "`# --- Reproducible 80/10/10 split ---`  \n",
        "Section comment to mark the start of the split logic.\n",
        "\n",
        "`RANDOM_SEED = 42`  \n",
        "Sets a fixed seed for reproducible splitting.\n",
        "\n",
        "`if not {'train_ids.csv','val_ids.csv','test_ids.csv'} <= set(os.listdir('.')):`  \n",
        "Checks if any of the three ID files are missing in the current directory.\n",
        "\n",
        "`    # stratified train vs temp (80/20)`  \n",
        "Comment: first split into 80% train and 20% temp with stratification.\n",
        "\n",
        "`    df_train, df_temp = train_test_split(`  \n",
        "Begins the first split call.\n",
        "\n",
        "`        df, test_size=0.2, random_state=RANDOM_SEED, stratify=df['label']`  \n",
        "Specifies 80/20 split, fixed seed, and stratification by label.\n",
        "\n",
        "`    )`  \n",
        "Closes the first split call.\n",
        "\n",
        "`    # split temp 50/50 -> 10/10`  \n",
        "Comment: split the 20% temp set into two equal 10% parts for val and test.\n",
        "\n",
        "`    df_val, df_test = train_test_split(`  \n",
        "Begins the second split call.\n",
        "\n",
        "`        df_temp, test_size=0.5, random_state=RANDOM_SEED, stratify=df_temp['label']`  \n",
        "Specifies 50/50 split of temp with the same seed and stratification by temp labels.\n",
        "\n",
        "`    )`  \n",
        "Closes the second split call.\n",
        "\n",
        "`    df_train[['id']].to_csv('train_ids.csv', index=False)`  \n",
        "Saves the training IDs for reproducibility.\n",
        "\n",
        "`    df_val[['id']].to_csv('val_ids.csv', index=False)`  \n",
        "Saves the validation IDs.\n",
        "\n",
        "`    df_test[['id']].to_csv('test_ids.csv', index=False)`  \n",
        "Saves the test IDs.\n",
        "\n",
        "`else:`  \n",
        "If all three ID files already exist, reuse them to reconstruct the exact same splits.\n",
        "\n",
        "`    ids_tr = set(pd.read_csv('train_ids.csv')['id'].tolist())`  \n",
        "Loads the training ID set from disk.\n",
        "\n",
        "`    ids_va = set(pd.read_csv('val_ids.csv')['id'].tolist())`  \n",
        "Loads the validation ID set from disk.\n",
        "\n",
        "`    ids_te = set(pd.read_csv('test_ids.csv')['id'].tolist())`  \n",
        "Loads the test ID set from disk.\n",
        "\n",
        "`    df_train = df[df['id'].isin(ids_tr)].copy()`  \n",
        "Rebuilds the training DataFrame by filtering on the saved IDs.\n",
        "\n",
        "`    df_val   = df[df['id'].isin(ids_va)].copy()`  \n",
        "Rebuilds the validation DataFrame by filtering on the saved IDs.\n",
        "\n",
        "`    df_test  = df[df['id'].isin(ids_te)].copy()`  \n",
        "Rebuilds the test DataFrame by filtering on the saved IDs.\n",
        "\n",
        "`print({`  \n",
        "Starts printing a small dictionary summarizing split sizes.\n",
        "\n",
        "`    'train': len(df_train), 'val': len(df_val), 'test': len(df_test)`  \n",
        "Computes the sizes of each split.\n",
        "\n",
        "`})`  \n",
        "Closes the dict printout.\n",
        "\n",
        "`print('Label ratios (train):', df_train['label'].value_counts(normalize=True).sort_index().to_dict())`  \n",
        "Prints the normalized label distribution for the training set.\n",
        "\n",
        "`print('Label ratios (val):  ', df_val['label'].value_counts(normalize=True).sort_index().to_dict())`  \n",
        "Prints the normalized label distribution for the validation set.\n",
        "\n",
        "`print('Label ratios (test): ', df_test['label'].value_counts(normalize=True).sort_index().to_dict())`  \n",
        "Prints the normalized label distribution for the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBDLlqdEsIuA",
        "outputId": "d36b5cd7-b266-4053-87cf-4b73246b1633"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned dataset: kept 7338/7340 rows\n",
            "{'train': 5870, 'val': 1468, 'test': 734}\n",
            "Label ratios (train): {0: 0.32453151618398635, 1: 0.3471890971039182, 2: 0.3282793867120954}\n",
            "Label ratios (val):   {0: 0.3242506811989101, 1: 0.3474114441416894, 2: 0.32833787465940056}\n",
            "Label ratios (test):  {0: 0.3242506811989101, 1: 0.3474114441416894, 2: 0.32833787465940056}\n"
          ]
        }
      ],
      "source": [
        "import re, html\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# --- Cleaning helpers ---\n",
        "CTRL_RE = re.compile(r\"[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F]\")\n",
        "REPEAT_RE = re.compile(r\"(\\w)\\1{2,}\")\n",
        "\n",
        "def strip_html(text: str) -> str:\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    # unescape HTML entities then drop tags\n",
        "    t = html.unescape(text)\n",
        "    t = re.sub(r\"<[^>]+>\", \" \", t)\n",
        "    return t\n",
        "\n",
        "def squash_repeats(text: str) -> str:\n",
        "    return REPEAT_RE.sub(r\"\\1\\1\", text)\n",
        "\n",
        "def basic_clean(text: str) -> str:\n",
        "    t = str(text)\n",
        "    t = strip_html(t)\n",
        "    t = CTRL_RE.sub(\" \", t)\n",
        "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
        "    t = squash_repeats(t)\n",
        "    return t\n",
        "\n",
        "# Apply cleaning to the loaded df (from earlier cell)\n",
        "df = df.copy()\n",
        "df['review'] = df['review'].astype(str).map(basic_clean)\n",
        "# drop empties and exact duplicates\n",
        "before = len(df)\n",
        "df = df[(df['review'].str.len() > 0)].drop_duplicates(subset=['review','label']).reset_index(drop=True)\n",
        "after = len(df)\n",
        "print(f\"Cleaned dataset: kept {after}/{before} rows\")\n",
        "\n",
        "# Optional: simple code-switch ratio (EDA only)\n",
        "EN_RE = re.compile(r\"[A-Za-z]{3,}\")\n",
        "TL_HINTS = set([\"po\",\"opo\",\"naman\",\"kuya\",\"ate\",\"nga\",\"na\",\"lang\",\"din\",\"rin\",\"daw\",\"ba\",\"yung\",\"yung\",\"ang\",\"sa\",\"si\",\"ni\",\"kay\",\"sana\",\"wala\",\"meron\",\"sobrang\",\"sobrang\",\"ganda\",\"pang\",\"bilis\",\"salamat\"])  # lightweight hints\n",
        "\n",
        "def code_switch_ratio(text: str) -> float:\n",
        "    tokens = re.findall(r\"\\w+\", text.lower())\n",
        "    if not tokens:\n",
        "        return 0.0\n",
        "    en_like = sum(1 for tok in tokens if EN_RE.fullmatch(tok) is not None)\n",
        "    tl_like = sum(1 for tok in tokens if tok in TL_HINTS)\n",
        "    return en_like / max(1, (en_like + tl_like))\n",
        "\n",
        "df['cs_ratio'] = df['review'].map(code_switch_ratio)\n",
        "\n",
        "# --- Reproducible 80/10/10 split ---\n",
        "RANDOM_SEED = 42\n",
        "if not {'train_ids.csv','val_ids.csv','test_ids.csv'} <= set(os.listdir('.')):\n",
        "    # stratified train vs temp (80/20)\n",
        "    df_train, df_temp = train_test_split(\n",
        "        df, test_size=0.2, random_state=RANDOM_SEED, stratify=df['label']\n",
        "    )\n",
        "    # split temp 50/50 -> 10/10\n",
        "    df_val, df_test = train_test_split(\n",
        "        df_temp, test_size=0.5, random_state=RANDOM_SEED, stratify=df_temp['label']\n",
        "    )\n",
        "    df_train[['id']].to_csv('train_ids.csv', index=False)\n",
        "    df_val[['id']].to_csv('val_ids.csv', index=False)\n",
        "    df_test[['id']].to_csv('test_ids.csv', index=False)\n",
        "else:\n",
        "    ids_tr = set(pd.read_csv('train_ids.csv')['id'].tolist())\n",
        "    ids_va = set(pd.read_csv('val_ids.csv')['id'].tolist())\n",
        "    ids_te = set(pd.read_csv('test_ids.csv')['id'].tolist())\n",
        "    df_train = df[df['id'].isin(ids_tr)].copy()\n",
        "    df_val   = df[df['id'].isin(ids_va)].copy()\n",
        "    df_test  = df[df['id'].isin(ids_te)].copy()\n",
        "\n",
        "print({\n",
        "    'train': len(df_train), 'val': len(df_val), 'test': len(df_test)\n",
        "})\n",
        "print('Label ratios (train):', df_train['label'].value_counts(normalize=True).sort_index().to_dict())\n",
        "print('Label ratios (val):  ', df_val['label'].value_counts(normalize=True).sort_index().to_dict())\n",
        "print('Label ratios (test): ', df_test['label'].value_counts(normalize=True).sort_index().to_dict())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lx0TZIOsIuB"
      },
      "source": [
        "# Fast mode toggle (optional)\n",
        "\n",
        "Set `FAST_MODE` to `True` to downsample the training split (40%) for quicker CPU experiments. Leave it `False` for full-run results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmAC-3F0sIuB",
        "outputId": "c3b0ab9a-d0ef-40ee-d8f3-3767ca569016"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FAST_MODE] train=4696 (~80%), val=1468, test=734)\n"
          ]
        }
      ],
      "source": [
        "FAST_MODE = True  # Set False for full runs\n",
        "TRAIN_FRACTION = 0.80 if FAST_MODE else 1.0\n",
        "VAL_FRACTION = 1.0  # Keep full validation/test by default\n",
        "\n",
        "if FAST_MODE and TRAIN_FRACTION < 1.0:\n",
        "    df_train = (df_train\n",
        "                .sample(frac=TRAIN_FRACTION, random_state=RANDOM_SEED)\n",
        "                .sort_values('id')\n",
        "                .reset_index(drop=True))\n",
        "    if VAL_FRACTION < 1.0:\n",
        "        df_val = (df_val\n",
        "                  .sample(frac=VAL_FRACTION, random_state=RANDOM_SEED)\n",
        "                  .sort_values('id')\n",
        "                  .reset_index(drop=True))\n",
        "        df_test = (df_test\n",
        "                   .sample(frac=VAL_FRACTION, random_state=RANDOM_SEED)\n",
        "                   .sort_values('id')\n",
        "                   .reset_index(drop=True))\n",
        "    print(f\"[FAST_MODE] train={len(df_train)} (~{TRAIN_FRACTION*100:.0f}%), val={len(df_val)}, test={len(df_test)})\")\n",
        "else:\n",
        "    print(\"FAST_MODE disabled: using full train/val/test splits\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBDjKQTtOp35"
      },
      "source": [
        "# Automated hyperparameter tuning configuration\n",
        "\n",
        "Toggle these settings to enable or customise the grid and random search experiments that will be executed later in the notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WtJ8_umOp35"
      },
      "outputs": [],
      "source": [
        "AUTO_TUNE_ENABLED = True  # Set to False to skip automated searches\n",
        "\n",
        "GRID_SEARCH_SPACE = {\n",
        "    \"learning_rate\": [5e-5, 3e-5, 2e-5],\n",
        "    \"per_device_train_batch_size\": [8, 16],\n",
        "    \"weight_decay\": [0.0, 0.05],\n",
        "    \"num_train_epochs\": [2, 3],\n",
        "}\n",
        "\n",
        "RANDOM_SEARCH_SPACE = {\n",
        "    # (mode, low, high, log_scale?) definitions, interpreted later\n",
        "    \"learning_rate\": (\"log_uniform\", 2e-5, 5e-5),\n",
        "    \"per_device_train_batch_size\": (\"choice\", [8, 12, 16, 24]),\n",
        "    \"weight_decay\": (\"uniform\", 0.0, 0.1),\n",
        "    \"num_train_epochs\": (\"int\", 2, 4),\n",
        "}\n",
        "\n",
        "RANDOM_TRIALS = 8  # adjust for more extensive exploration\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9q0q_b0HE_w"
      },
      "source": [
        "# **Baseline TF-IDF + Logistic Regression and log row**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kwe7KU5uDQzz"
      },
      "source": [
        "#### Purpose / Description\n",
        "This cell trains a fast **TF–IDF + Logistic Regression** baseline, evaluates it on the **validation** split, prints macro-F1 and accuracy, and appends a compact row to `runs_log.csv` so this baseline appears alongside later transformer runs and automated searches. It vectorizes text using 1–2-gram TF–IDF features (capped vocabulary), fits Logistic Regression with a generous iteration limit for convergence, and records a reproducible log row with key fields (metrics, seed, and a short note).\n",
        "\n",
        "#### Input\n",
        "- In-memory splits: `train_df` and `val_df` with columns `review` (text) and `label` (0/1/2).\n",
        "- `accuracy_score`, `f1_score` imported earlier (from `sklearn.metrics`), plus `pandas as pd` and `os`.\n",
        "\n",
        "#### Output\n",
        "- Printed dict with validation **accuracy** and **macro-F1** for this baseline.\n",
        "- Appended row in `runs_log.csv` describing this run (header auto-created if file doesn’t exist).\n",
        "\n",
        "---\n",
        "\n",
        "#### Line-by-Line Explanation\n",
        "\n",
        "`from sklearn.feature_extraction.text import TfidfVectorizer`  \n",
        "Imports the TF–IDF transformer to convert raw text into sparse n-gram features.\n",
        "\n",
        "`from sklearn.linear_model import LogisticRegression`  \n",
        "Imports the Logistic Regression classifier.\n",
        "\n",
        "`tfidf = TfidfVectorizer(`  \n",
        "Starts constructing the TF–IDF vectorizer object.\n",
        "\n",
        "`    max_features=50000,`  \n",
        "Caps the vocabulary at 50,000 features to keep runtime and memory reasonable.\n",
        "\n",
        "`    ngram_range=(1,2),`  \n",
        "Uses unigrams and bigrams to capture short phrases (better than unigrams alone).\n",
        "\n",
        "`    lowercase=True`  \n",
        "Normalizes case so “Good” and “good” map to the same feature.\n",
        "\n",
        "`X_tr = tfidf.fit_transform(train_df['review'])`  \n",
        "Learns the TF–IDF vocabulary/statistics **on training text only** and produces the sparse training matrix.\n",
        "\n",
        "`y_tr = train_df['label'].values`  \n",
        "Extracts the training labels as a NumPy array.\n",
        "\n",
        "`X_va = tfidf.transform(val_df['review'])`  \n",
        "Applies the **already-fit** vectorizer to the validation text (no leakage of val text into fitting).\n",
        "\n",
        "`y_va = val_df['label'].values`  \n",
        "Extracts the validation labels as a NumPy array.\n",
        "\n",
        "`logreg = LogisticRegression(max_iter=2000, n_jobs=None, class_weight=None)`  \n",
        "Configures Logistic Regression: up to 2000 iterations (to ensure convergence), default core usage, and no explicit class weighting.\n",
        "\n",
        "`logreg.fit(X_tr, y_tr)`  \n",
        "Fits the classifier on the TF–IDF training features and labels.\n",
        "\n",
        "`preds = logreg.predict(X_va)`  \n",
        "Generates predicted labels for the validation split.\n",
        "\n",
        "`acc_base = accuracy_score(y_va, preds)`  \n",
        "Computes **validation accuracy**.\n",
        "\n",
        "`f1_base  = f1_score(y_va, preds, average='macro')`  \n",
        "Computes **validation macro-F1** (each class contributes equally).\n",
        "\n",
        "`print({\"model\":\"tfidf-logreg\", \"accuracy\":acc_base, \"f1_macro\":f1_base})`  \n",
        "Prints a concise dictionary of the baseline metrics for quick inspection.\n",
        "\n",
        "`row = {`  \n",
        "Begins building a log entry compatible with the project’s experiment log schema.\n",
        "\n",
        "`    \"member\":\"baseline\", \"model\":\"tfidf-logreg\",`  \n",
        "Tags this run as a baseline and names the model.\n",
        "\n",
        "`    \"num_train_epochs\":None, \"per_device_train_batch_size\":None,`  \n",
        "Fills transformer-specific fields with `None` (not applicable to this baseline).\n",
        "\n",
        "`    \"learning_rate\":None, \"weight_decay\":None, \"warmup_steps\":None,`  \n",
        "More transformer-only fields set to `None`.\n",
        "\n",
        "`    \"lr_scheduler_type\":None, \"gradient_accumulation_steps\":None,`  \n",
        "Additional transformer fields set to `None`.\n",
        "\n",
        "`    \"max_seq_length\":None, \"seed\":42, \"fp16\":False,`  \n",
        "Records a seed for reproducibility; marks fp16 as False (not used here).\n",
        "\n",
        "`    \"accuracy\":acc_base, \"f1_macro\":f1_base, \"notes\":\"TF-IDF + LogReg baseline\"`  \n",
        "Stores the key validation metrics and a short note.\n",
        "\n",
        "\n",
        "`pd.DataFrame([row]).to_csv(\"runs_log.csv\", mode=\"a\",`  \n",
        "Creates a one-row DataFrame and opens the log file in **append** mode.\n",
        "\n",
        "`                           index=False, header=not os.path.exists(\"runs_log.csv\"))`  \n",
        "Writes without index; includes a header **only** if the file doesn’t exist yet (keeps a single header line across runs)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQkWVS7TYdm6",
        "outputId": "8b6c2662-6fdc-4364-dfb6-23a4a64360c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'model': 'tfidf-logreg', 'accuracy': 0.8024523160762943, 'f1_macro': 0.8050088305616837}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "tfidf = TfidfVectorizer(\n",
        "    max_features=50000,\n",
        "    ngram_range=(1,2),\n",
        "    lowercase=True\n",
        ")\n",
        "X_tr = tfidf.fit_transform(train_df['review'])\n",
        "y_tr = train_df['label'].values\n",
        "X_va = tfidf.transform(val_df['review'])\n",
        "y_va = val_df['label'].values\n",
        "\n",
        "logreg = LogisticRegression(max_iter=2000, n_jobs=None, class_weight=None)\n",
        "logreg.fit(X_tr, y_tr)\n",
        "\n",
        "preds = logreg.predict(X_va)\n",
        "acc_base = accuracy_score(y_va, preds)\n",
        "f1_base  = f1_score(y_va, preds, average='macro')\n",
        "print({\"model\":\"tfidf-logreg\", \"accuracy\":acc_base, \"f1_macro\":f1_base})\n",
        "\n",
        "row = {\n",
        "    \"member\":\"baseline\", \"model\":\"tfidf-logreg\",\n",
        "    \"num_train_epochs\":None, \"per_device_train_batch_size\":None,\n",
        "    \"learning_rate\":None, \"weight_decay\":None, \"warmup_steps\":None,\n",
        "    \"lr_scheduler_type\":None, \"gradient_accumulation_steps\":None,\n",
        "    \"max_seq_length\":None, \"seed\":42, \"fp16\":False,\n",
        "    \"accuracy\":acc_base, \"f1_macro\":f1_base, \"notes\":\"TF-IDF + LogReg baseline\"\n",
        "}\n",
        "pd.DataFrame([row]).to_csv(\"runs_log.csv\", mode=\"a\",\n",
        "                           index=False, header=not os.path.exists(\"runs_log.csv\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0neAE-lsIuD"
      },
      "source": [
        "# **Baseline ablations (TF‑IDF + Logistic Regression)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVRGtfPLUUzk"
      },
      "source": [
        "#### Purpose / Description\n",
        "This cell runs a **classical baseline search** using scikit-learn: it builds TF–IDF + Logistic Regression pipelines, performs a **5-fold Stratified** grid search over key classifier hyperparameters (`C`, `class_weight`), **compares two TF–IDF variants** (word 1–2 grams vs character-wb 3–5 grams), picks the best by cross-validated **macro-F1**, validates on the held-out **val** split, then **refits** on **train + val** and evaluates on **test**. It saves per-example test predictions and a confusion matrix image, and appends a structured row to `runs_log.csv` so these baseline results sit alongside transformer runs.\n",
        "\n",
        "#### Input\n",
        "- Clean, split dataframes: `df_train`, `df_val`, `df_test` with `review` and `label`.\n",
        "- Globals: `RANDOM_SEED` defined earlier.\n",
        "- Installed scikit-learn, matplotlib, numpy, pandas.\n",
        "\n",
        "#### Output\n",
        "- Console prints: best CV scores/params per variant; validation metrics; final test metrics.\n",
        "- Files:\n",
        "  - `baseline_predictions_test.csv` — per-example test predictions.\n",
        "  - `baseline_cm_test.png` — saved confusion matrix (test).\n",
        "  - `runs_log.csv` — appended row describing the run.\n",
        "\n",
        "---\n",
        "\n",
        "#### Line-by-Line Explanation\n",
        "\n",
        "`import numpy as np, matplotlib.pyplot as plt`  \n",
        "Imports NumPy for arrays/concatenation and Matplotlib for plotting the confusion matrix.\n",
        "\n",
        "`from sklearn.model_selection import StratifiedKFold, GridSearchCV`  \n",
        "Brings in stratified K-fold splitter and grid search for hyperparameter tuning.\n",
        "\n",
        "`from sklearn.pipeline import Pipeline`  \n",
        "Allows chaining vectorizer and classifier into a single estimator.\n",
        "\n",
        "`from sklearn.feature_extraction.text import TfidfVectorizer`  \n",
        "TF–IDF transformer for word/character n-gram features.\n",
        "\n",
        "`from sklearn.linear_model import LogisticRegression`  \n",
        "Linear classifier used in the baselines.\n",
        "\n",
        "`from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score, f1_score`  \n",
        "Evaluation utilities (macro-F1/accuracy) and tools to build/plot a confusion matrix.\n",
        "\n",
        "`X_tr = df_train['review'].tolist(); y_tr = df_train['label'].values`  \n",
        "Extracts training texts as a Python list and labels as a NumPy array.\n",
        "\n",
        "`X_va = df_val['review'].tolist();   y_va = df_val['label'].values`  \n",
        "Extracts validation texts/labels for later sanity-checking the picked model.\n",
        "\n",
        "`X_te = df_test['review'].tolist();  y_te = df_test['label'].values`  \n",
        "Extracts test texts/labels for final reporting after refit.\n",
        "\n",
        "`skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)`  \n",
        "Defines a **5-fold stratified** splitter with shuffling and fixed seed for reproducibility.\n",
        "\n",
        "`param_grid = {`  \n",
        "Starts the hyperparameter grid for Logistic Regression inside the pipeline.\n",
        "\n",
        "`    'clf__C': [0.5, 1.0, 2.0, 4.0],`  \n",
        "Regularization strength values to try (pipeline step name `clf`, param `C`).\n",
        "\n",
        "`    'clf__class_weight': [None, 'balanced']`  \n",
        "Either no weighting or automatic class weighting to combat imbalance.\n",
        "\n",
        "`variants = {`  \n",
        "Begins a dictionary of TF–IDF variants to compare.\n",
        "\n",
        "`    'word_1_2': TfidfVectorizer(max_features=50000, ngram_range=(1,2), lowercase=True),`  \n",
        "Variant A: word-level 1–2 grams, 50k vocab cap, lowercase normalization.\n",
        "\n",
        "`    'charwb_3_5': TfidfVectorizer(analyzer='char_wb', ngram_range=(3,5), max_features=100000, lowercase=True)`  \n",
        "Variant B: character n-grams within word boundaries (3–5), up to 100k features.\n",
        "\n",
        "\n",
        "`best = None`  \n",
        "Holds the best-performing variant after grid search (to be replaced once found).\n",
        "\n",
        "`for name, vec in variants.items():`  \n",
        "Iterates over each TF–IDF variant to run its own grid search.\n",
        "\n",
        "`    pipe = Pipeline([`  \n",
        "Starts a pipeline: vectorizer → classifier.\n",
        "\n",
        "`        ('vec', vec),`  \n",
        "Pipeline step `vec`: the current TF–IDF variant.\n",
        "\n",
        "`        ('clf', LogisticRegression(max_iter=2000))`  \n",
        "Pipeline step `clf`: Logistic Regression with a high iteration cap.\n",
        "\n",
        "`    ])`  \n",
        "Closes the pipeline definition.\n",
        "\n",
        "`    gs = GridSearchCV(`  \n",
        "Begins the grid search wrapper around the pipeline.\n",
        "\n",
        "`        pipe, param_grid=param_grid, scoring='f1_macro', cv=skf, n_jobs=-1, verbose=1`  \n",
        "Uses the pipeline, earlier grid, **macro-F1** as the objective, the 5-fold splitter, all CPU cores, and verbose progress.\n",
        "\n",
        "`    )`  \n",
        "Closes the grid search configuration.\n",
        "\n",
        "`    gs.fit(X_tr, y_tr)`  \n",
        "Runs cross-validated training across all param combinations for this variant.\n",
        "\n",
        "`    print(f\"Variant {name} best CV f1_macro: {gs.best_score_:.4f} with {gs.best_params_}\")`  \n",
        "Reports the top cross-validated macro-F1 and the corresponding hyperparameters for this variant.\n",
        "\n",
        "`    if best is None or gs.best_score_ > best['cv']:`  \n",
        "Checks if this variant beats the current best.\n",
        "\n",
        "`        best = {`  \n",
        "Stores details of the new best configuration/estimator.\n",
        "\n",
        "`            'name': name,`  \n",
        "The variant key (e.g., `word_1_2` or `charwb_3_5`).\n",
        "\n",
        "`            'cv': gs.best_score_,`  \n",
        "Best cross-validated macro-F1 for this variant.\n",
        "\n",
        "`            'best_params': gs.best_params_,`  \n",
        "The hyperparameters that achieved the best CV score.\n",
        "\n",
        "`            'estimator': gs.best_estimator_`  \n",
        "The pipeline fitted on the full training data under the best params.\n",
        "\n",
        "`# Validate picked model on val`  \n",
        "Section comment: evaluate the chosen variant/pipeline on the validation split.\n",
        "\n",
        "`val_preds = best['estimator'].predict(X_va)`  \n",
        "Generates predictions on validation texts with the best pipeline.\n",
        "\n",
        "`val_acc = accuracy_score(y_va, val_preds)`  \n",
        "Computes validation accuracy to sanity-check generalization.\n",
        "\n",
        "`val_f1m = f1_score(y_va, val_preds, average='macro')`  \n",
        "Computes validation macro-F1.\n",
        "\n",
        "`print({'pick': best['name'], 'val_acc': val_acc, 'val_f1_macro': val_f1m})`  \n",
        "Logs which variant was picked and its validation metrics.\n",
        "\n",
        "`# Refit on train+val`  \n",
        "Section comment: refit the **final** model on combined train and validation data.\n",
        "\n",
        "`X_trval = X_tr + X_va`  \n",
        "Concatenates training and validation texts (lists) for refit.\n",
        "\n",
        "`y_trval = np.concatenate([y_tr, y_va])`  \n",
        "Concatenates training and validation labels (arrays).\n",
        "\n",
        "`best_refit = Pipeline([`  \n",
        "Builds a fresh pipeline for the refit stage.\n",
        "\n",
        "`    ('vec', variants[best['name']]),`  \n",
        "Uses the **same** TF–IDF variant that won CV.\n",
        "\n",
        "`    ('clf', LogisticRegression(max_iter=2000, **{k.split('__')[1]:v for k,v in best['best_params'].items()}))`  \n",
        "Recreates Logistic Regression with `max_iter=2000` and injects the **best params** (e.g., `C`, `class_weight`) extracted from `best_params` by stripping the `clf__` prefix.\n",
        "\n",
        "`])`  \n",
        "Closes the refit pipeline.\n",
        "\n",
        "`best_refit.fit(X_trval, y_trval)`  \n",
        "Fits the final model on **train + val** to use all supervised data before testing.\n",
        "\n",
        "`y_pred = best_refit.predict(X_te)`  \n",
        "Predicts labels on the **test** split.\n",
        "\n",
        "`acc = accuracy_score(y_te, y_pred)`  \n",
        "Computes test accuracy.\n",
        "\n",
        "`f1m = f1_score(y_te, y_pred, average='macro')`  \n",
        "Computes test macro-F1.\n",
        "\n",
        "`print({'baseline_best_test_acc': acc, 'baseline_best_test_f1_macro': f1m, 'variant': best['name']})`  \n",
        "Prints final test metrics and the winning variant name.\n",
        "\n",
        "`# Save predictions and confusion matrix`  \n",
        "Section comment: create artifacts for the report/appendix.\n",
        "\n",
        "`import pandas as pd, os`  \n",
        "Imports pandas and os (used for saving files and logging).\n",
        "\n",
        "`pd.DataFrame({'review': X_te, 'gold': y_te, 'pred': y_pred}).to_csv('baseline_predictions_test.csv', index=False)`  \n",
        "Saves a CSV of per-example test predictions for error analysis.\n",
        "\n",
        "`cm = confusion_matrix(y_te, y_pred, labels=[0,1,2])`  \n",
        "Builds the raw confusion matrix with a fixed label order.\n",
        "\n",
        "`fig, ax = plt.subplots(figsize=(4,4))`  \n",
        "Creates a small Matplotlib figure/axes for the plot.\n",
        "\n",
        "`ConfusionMatrixDisplay(cm, display_labels=['neg','neu','pos']).plot(ax=ax, colorbar=False)`  \n",
        "Renders the confusion matrix with class labels and without a colorbar (cleaner for reports).\n",
        "\n",
        "`plt.tight_layout(); plt.savefig('baseline_cm_test.png', dpi=150); plt.close()`  \n",
        "Tightens layout, saves the figure as PNG (150 dpi), and closes the figure to free memory.\n",
        "\n",
        "`# Append to log`  \n",
        "Section comment: add a summary row to the global experiment log.\n",
        "\n",
        "`row = {`  \n",
        "Begins a dict describing this baseline search and final test results.\n",
        "\n",
        "`    'member': 'baseline-grid',`  \n",
        "Tags the row as a baseline grid-search entry.\n",
        "\n",
        "`    'model': f'tfidf-{best[\"name\"]}',`  \n",
        "Records which TF–IDF variant was used.\n",
        "\n",
        "`    'num_train_epochs': None,`  \n",
        "Transformer-specific fields (not applicable) are set to `None`.\n",
        "\n",
        "`    'per_device_train_batch_size': None,`  \n",
        "N/A for scikit-learn baseline.\n",
        "\n",
        "`    'learning_rate': None,`  \n",
        "N/A for scikit-learn baseline.\n",
        "\n",
        "`    'weight_decay': None,`  \n",
        "N/A for scikit-learn baseline.\n",
        "\n",
        "`    'warmup_steps': None,`  \n",
        "N/A for scikit-learn baseline.\n",
        "\n",
        "`    'lr_scheduler_type': None,`  \n",
        "N/A for scikit-learn baseline.\n",
        "\n",
        "`    'gradient_accumulation_steps': None,`  \n",
        "N/A for scikit-learn baseline.\n",
        "\n",
        "`    'max_seq_length': None,`  \n",
        "N/A for TF–IDF baseline.\n",
        "\n",
        "`    'seed': RANDOM_SEED,`  \n",
        "Records the seed used in CV splitting.\n",
        "\n",
        "`    'fp16': False,`  \n",
        "Half precision not applicable here.\n",
        "\n",
        "`    'accuracy': acc,`  \n",
        "Final **test** accuracy.\n",
        "\n",
        "`    'f1_macro': f1m,`  \n",
        "Final **test** macro-F1.\n",
        "\n",
        "`    'notes': f'GridSearchCV 5-fold; best_params={best[\"best_params\"]}'`  \n",
        "Free-form note including the best hyperparameters for traceability.\n",
        "\n",
        "`pd.DataFrame([row]).to_csv('runs_log.csv', mode='a', index=False, header=not os.path.exists('runs_log.csv'))`  \n",
        "Appends the row to `runs_log.csv`; writes a header only if the file didn’t exist yet to avoid duplicate headers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpr5r5uRsIuD",
        "outputId": "d2db341d-c153-4118-bd63-a50e1789a894"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
            "Variant word_1_2 best CV f1_macro: 0.8010 with {'clf__C': 4.0, 'clf__class_weight': None}\n",
            "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
            "Variant charwb_3_5 best CV f1_macro: 0.8061 with {'clf__C': 1.0, 'clf__class_weight': None}\n",
            "{'pick': 'charwb_3_5', 'val_acc': 0.8038147138964578, 'val_f1_macro': 0.8064406999307708}\n",
            "{'baseline_best_test_acc': 0.8937329700272479, 'baseline_best_test_f1_macro': 0.8944810164886371, 'variant': 'charwb_3_5'}\n"
          ]
        }
      ],
      "source": [
        "import numpy as np, matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score, f1_score\n",
        "\n",
        "X_tr = df_train['review'].tolist(); y_tr = df_train['label'].values\n",
        "X_va = df_val['review'].tolist();   y_va = df_val['label'].values\n",
        "X_te = df_test['review'].tolist();  y_te = df_test['label'].values\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
        "param_grid = {\n",
        "    'clf__C': [0.5, 1.0, 2.0, 4.0],\n",
        "    'clf__class_weight': [None, 'balanced']\n",
        "}\n",
        "\n",
        "variants = {\n",
        "    'word_1_2': TfidfVectorizer(max_features=50000, ngram_range=(1,2), lowercase=True),\n",
        "    'charwb_3_5': TfidfVectorizer(analyzer='char_wb', ngram_range=(3,5), max_features=100000, lowercase=True)\n",
        "}\n",
        "\n",
        "best = None\n",
        "for name, vec in variants.items():\n",
        "    pipe = Pipeline([\n",
        "        ('vec', vec),\n",
        "        ('clf', LogisticRegression(max_iter=2000))\n",
        "    ])\n",
        "    gs = GridSearchCV(\n",
        "        pipe, param_grid=param_grid, scoring='f1_macro', cv=skf, n_jobs=-1, verbose=1\n",
        "    )\n",
        "    gs.fit(X_tr, y_tr)\n",
        "    print(f\"Variant {name} best CV f1_macro: {gs.best_score_:.4f} with {gs.best_params_}\")\n",
        "    if best is None or gs.best_score_ > best['cv']:\n",
        "        best = {\n",
        "            'name': name,\n",
        "            'cv': gs.best_score_,\n",
        "            'best_params': gs.best_params_,\n",
        "            'estimator': gs.best_estimator_\n",
        "        }\n",
        "\n",
        "# Validate picked model on val\n",
        "val_preds = best['estimator'].predict(X_va)\n",
        "val_acc = accuracy_score(y_va, val_preds)\n",
        "val_f1m = f1_score(y_va, val_preds, average='macro')\n",
        "print({'pick': best['name'], 'val_acc': val_acc, 'val_f1_macro': val_f1m})\n",
        "\n",
        "# Refit on train+val\n",
        "X_trval = X_tr + X_va\n",
        "y_trval = np.concatenate([y_tr, y_va])\n",
        "best_refit = Pipeline([\n",
        "    ('vec', variants[best['name']]),\n",
        "    ('clf', LogisticRegression(max_iter=2000, **{k.split('__')[1]:v for k,v in best['best_params'].items()}))\n",
        "])\n",
        "best_refit.fit(X_trval, y_trval)\n",
        "\n",
        "y_pred = best_refit.predict(X_te)\n",
        "acc = accuracy_score(y_te, y_pred)\n",
        "f1m = f1_score(y_te, y_pred, average='macro')\n",
        "print({'baseline_best_test_acc': acc, 'baseline_best_test_f1_macro': f1m, 'variant': best['name']})\n",
        "\n",
        "# Save predictions and confusion matrix\n",
        "import pandas as pd, os\n",
        "pd.DataFrame({'review': X_te, 'gold': y_te, 'pred': y_pred}).to_csv('baseline_predictions_test.csv', index=False)\n",
        "cm = confusion_matrix(y_te, y_pred, labels=[0,1,2])\n",
        "fig, ax = plt.subplots(figsize=(4,4))\n",
        "ConfusionMatrixDisplay(cm, display_labels=['neg','neu','pos']).plot(ax=ax, colorbar=False)\n",
        "plt.tight_layout(); plt.savefig('baseline_cm_test.png', dpi=150); plt.close()\n",
        "\n",
        "# Append to log\n",
        "row = {\n",
        "    'member': 'baseline-grid',\n",
        "    'model': f'tfidf-{best[\"name\"]}',\n",
        "    'num_train_epochs': None,\n",
        "    'per_device_train_batch_size': None,\n",
        "    'learning_rate': None,\n",
        "    'weight_decay': None,\n",
        "    'warmup_steps': None,\n",
        "    'lr_scheduler_type': None,\n",
        "    'gradient_accumulation_steps': None,\n",
        "    'max_seq_length': None,\n",
        "    'seed': RANDOM_SEED,\n",
        "    'fp16': False,\n",
        "    'accuracy': acc,\n",
        "    'f1_macro': f1m,\n",
        "    'notes': f'GridSearchCV 5-fold; best_params={best[\"best_params\"]}'\n",
        "}\n",
        "pd.DataFrame([row]).to_csv('runs_log.csv', mode='a', index=False, header=not os.path.exists('runs_log.csv'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EANPmOOIHBX6"
      },
      "source": [
        "# **Model switcher, tokenization, dataset tensors, and model init**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXiJwfJkDZ_K"
      },
      "source": [
        "#### Purpose / Description\n",
        "This cell detects the available hardware (GPU/CPU) and sets OS-aware performance knobs, selects a pretrained backbone, builds a fast tokenizer, converts pandas splits into Hugging Face `Dataset` objects, **tokenizes with safe parallelism** (Windows vs Linux/Mac), sets PyTorch tensor formatting, and finally initializes the sequence classification model on the correct device. The result is a ready-to-train pipeline that honors platform constraints while keeping tokenization and batching efficient.\n",
        "\n",
        "#### Input\n",
        "- Split DataFrames: `df_train`, `df_val`, `df_test` with columns `review` and `label`.\n",
        "- Libraries already installed/imported earlier: `torch`, `pandas`, `datasets`, `transformers`, `platform`.\n",
        "\n",
        "#### Output\n",
        "- Hardware flags: `USE_GPU`, `device`, `NUM_WORKERS`, `PIN_MEMORY`.\n",
        "- Tokenization objects and datasets: `tokenizer`, `ds_train`, `ds_val`, `ds_test`.\n",
        "- Model: `model` (`AutoModelForSequenceClassification`) placed on the selected `device`.\n",
        "- Console prints summarizing GPU info, tokenization strategy, dataset sizes, and model status.\n",
        "\n",
        "---\n",
        "\n",
        "#### Line-by-Line Explanation\n",
        "\n",
        "`from datasets import Dataset`  \n",
        "Imports HF `Dataset` to convert pandas tables into datasets compatible with tokenization and PyTorch formatting.\n",
        "\n",
        "`from transformers import AutoTokenizer, AutoModelForSequenceClassification`  \n",
        "Imports factories for tokenizer and classification model tied to the chosen backbone.\n",
        "\n",
        "`import platform`  \n",
        "Allows detecting the operating system (Windows vs Linux/Mac) to adjust multiprocessing safely.\n",
        "\n",
        "`# GPU detection and optimization settings`  \n",
        "Comment: start hardware checks and performance flags.\n",
        "\n",
        "`USE_GPU = torch.cuda.is_available()`  \n",
        "Checks whether a CUDA-capable GPU is available.\n",
        "\n",
        "`if USE_GPU:`  \n",
        "Branches into the GPU path when CUDA is detected.\n",
        "\n",
        "`    print(f\"✓ GPU detected: {torch.cuda.get_device_name(0)}\")`  \n",
        "Prints the GPU model name for visibility.\n",
        "\n",
        "`    print(f\"  CUDA Version: {torch.version.cuda}\")`  \n",
        "Shows the CUDA toolkit version used by PyTorch.\n",
        "\n",
        "`    print(f\"  GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")`  \n",
        "Displays total GPU memory in gigabytes.\n",
        "\n",
        "`    device = torch.device(\"cuda:0\")`  \n",
        "Selects the first CUDA device for model tensors.\n",
        "\n",
        "`    # Windows needs num_workers=0, Linux can use more`  \n",
        "Comment: DataLoader workers guideline differs by OS.\n",
        "\n",
        "`    NUM_WORKERS = 0 if platform.system() == 'Windows' else 4`  \n",
        "Sets default DataLoader workers: 0 on Windows (multiprocessing caveats), 4 on Unix-like systems.\n",
        "\n",
        "`    PIN_MEMORY = True`  \n",
        "Enables pinned host memory to speed up GPU transfers.\n",
        "\n",
        "`else:`  \n",
        "CPU-only branch when no GPU is available.\n",
        "\n",
        "`    print(\"⚠ No GPU detected, using CPU (training will be slow)\")`  \n",
        "Warns that training on CPU will be slower.\n",
        "\n",
        "`    device = torch.device(\"cpu\")`  \n",
        "Selects CPU device.\n",
        "\n",
        "`    NUM_WORKERS = 0`  \n",
        "Disables multiprocessing workers for safety/perf consistency on CPU.\n",
        "\n",
        "`    PIN_MEMORY = False`  \n",
        "Pinned memory is unnecessary without CUDA.\n",
        "\n",
        "`MODEL_CHOICES = {`  \n",
        "Begins a dictionary mapping short keys to full model IDs.\n",
        "\n",
        "`    \"xlmrb\": \"xlm-roberta-base\",`  \n",
        "Option A: multilingual XLM-RoBERTa base.\n",
        "\n",
        "`    \"roberta-tl\": \"jcblaise/roberta-tagalog-base\",`  \n",
        "Option B: Tagalog-adapted RoBERTa (adjust if your exact ID differs).\n",
        "\n",
        "`MODEL_CHOICE = \"xlmrb\"`  \n",
        "Picks which key to use; change this to switch backbones centrally.\n",
        "\n",
        "`MODEL_NAME = MODEL_CHOICES[MODEL_CHOICE]`  \n",
        "Resolves the full model identifier from the chosen key.\n",
        "\n",
        "`print(f\"Using model: {MODEL_NAME}\")`  \n",
        "Logs which backbone will be loaded.\n",
        "\n",
        "`MAX_LEN = 128`  \n",
        "Sets the maximum tokenized sequence length (trade-off between speed and context).\n",
        "\n",
        "`tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)`  \n",
        "Loads the matching tokenizer; `use_fast=True` prefers the Rust implementation for speed.\n",
        "\n",
        "`def tokenize_fn(batch):`  \n",
        "Defines a batched tokenization function to be used with `Dataset.map`.\n",
        "\n",
        "`    return tokenizer(batch[\"review\"], truncation=True, padding=\"max_length\", max_length=MAX_LEN)`  \n",
        "Tokenizes a batch of reviews, truncating to `MAX_LEN` and padding to fixed length (stable tensor shapes).\n",
        "\n",
        "`print(\"Tokenizing datasets (this may take a moment)...\")`  \n",
        "User-facing message indicating that tokenization will start.\n",
        "\n",
        "`ds_train = Dataset.from_pandas(df_train[['review','label']].reset_index(drop=True))`  \n",
        "Converts the training split from pandas to a HF `Dataset` (keeps only needed columns).\n",
        "\n",
        "`ds_val   = Dataset.from_pandas(df_val[['review','label']].reset_index(drop=True))`  \n",
        "Converts the validation split.\n",
        "\n",
        "`ds_test  = Dataset.from_pandas(df_test[['review','label']].reset_index(drop=True))`  \n",
        "Converts the test split.\n",
        "\n",
        "`# Windows multiprocessing has issues with tokenizers, so disable parallel processing on Windows`  \n",
        "Comment: Tokenizers’ multiprocessing can be problematic on Windows.\n",
        "\n",
        "`# On Linux/Mac, we can use parallel processing if not on CPU`  \n",
        "Comment: safe to use multiple processes on Unix-like systems.\n",
        "\n",
        "`if platform.system() == 'Windows':`  \n",
        "Branch depending on operating system.\n",
        "\n",
        "`    NUM_PROC_TOKENIZE = None  # Disable parallel processing on Windows`  \n",
        "Disables multiprocessing for `Dataset.map` on Windows for stability.\n",
        "\n",
        "`    print(\"  Using single-process tokenization (Windows compatibility)\")`  \n",
        "Logs the decision to tokenize in a single process.\n",
        "\n",
        "`else:`  \n",
        "Unix-like OS branch (Linux/Mac).\n",
        "\n",
        "`    NUM_PROC_TOKENIZE = 4 if USE_GPU else 2  # Parallel processing on Unix systems`  \n",
        "Uses more processes when a GPU is present (to keep GPU fed), fewer on CPU.\n",
        "\n",
        "`    print(f\"  Using {NUM_PROC_TOKENIZE} processes for tokenization\")`  \n",
        "Logs the parallelism chosen for tokenization.\n",
        "\n",
        "`# Tokenize datasets (batched=True is faster than individual processing)`  \n",
        "Comment: batched mapping improves throughput.\n",
        "\n",
        "`# Only remove 'review' column, keep 'label' column`  \n",
        "Comment: keep labels intact.\n",
        "\n",
        "`ds_train = ds_train.map(tokenize_fn, batched=True, num_proc=NUM_PROC_TOKENIZE, remove_columns=['review'])`  \n",
        "Applies batched tokenization to train; drops raw text so only token IDs/masks + label remain.\n",
        "\n",
        "`ds_val   = ds_val.map(tokenize_fn, batched=True, num_proc=NUM_PROC_TOKENIZE, remove_columns=['review'])`  \n",
        "Tokenizes validation split similarly.\n",
        "\n",
        "`ds_test  = ds_test.map(tokenize_fn, batched=True, num_proc=NUM_PROC_TOKENIZE, remove_columns=['review'])`  \n",
        "Tokenizes test split similarly.\n",
        "\n",
        "`cols = ['input_ids','attention_mask','label']`  \n",
        "Declares which columns should be exposed as tensors to the Trainer.\n",
        "\n",
        "`ds_train = ds_train.with_format(\"torch\", columns=cols)`  \n",
        "Switches train dataset to PyTorch format for those columns.\n",
        "\n",
        "`ds_val   = ds_val.with_format(\"torch\", columns=cols)`  \n",
        "Switches validation dataset to PyTorch format.\n",
        "\n",
        "`ds_test  = ds_test.with_format(\"torch\", columns=cols)`  \n",
        "Switches test dataset to PyTorch format.\n",
        "\n",
        "`print(f\"✓ Datasets ready: train={len(ds_train)}, val={len(ds_val)}, test={len(ds_test)}\")`  \n",
        "Confirms that all three datasets are prepared and shows their sizes.\n",
        "\n",
        "`num_labels = 3`  \n",
        "Sets the number of classes for sequence classification.\n",
        "\n",
        "`model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=num_labels)`  \n",
        "Loads the pretrained backbone with a classification head sized for `num_labels`.\n",
        "\n",
        "`model = model.to(device)`  \n",
        "Moves the model to GPU (if available) or CPU to match earlier `device`.\n",
        "\n",
        "`print(f\"✓ Model loaded on {device}\")`  \n",
        "Confirms the model is allocated on the intended device."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343,
          "referenced_widgets": [
            "20b5c30221f84a4bbf8c0c914fee2283",
            "2e001fc5349440dc844303ec392175fd",
            "562c2754b7c64e4fbc5810137f6ce5a1",
            "bf71cc71efd44cfaa4039057bd506436",
            "492e6a72aaca481b99cc1fc4e6bbd496",
            "5df0a14fbdbb40ddb70c0c8fce84bc03",
            "2a6f98064fbb4e37ae0d723a7a4015f9",
            "c7076da07ea04da68ec4b3ca379af6a6",
            "769aad0925a747cb9ac2a1737ac58829",
            "e9117c674c6c4e9091b837788e5be018",
            "24b11bc396864aa5952c547fd80d70a4",
            "a210378d435541dca3e4173c9c8a3efc",
            "e3328a29eb8f4ddea44a87b2ddc1494e",
            "261cee5ccfcb40a1a9252a7243097b59",
            "c0466f5eb80f46c1aeff55b449a865ad",
            "f97706c753f3464790437ff7e68b99ba",
            "07cc40e0c23d461f8d7658adde481a81",
            "b056ef7c60c5490ebf467a5f560f3738",
            "a3d7f39435a54a8f8a7718cf3f10d025",
            "1c87ad0e0f55437f820d820704cc0773",
            "618e08f754d94c04bf272bcafebb2dd7",
            "cff2fc26f9cb480894eb6be0a05771ff",
            "99f62c615857417793a550e696fae6ae",
            "5936f3860586494baa89b52962085a34",
            "641d96b7ee584ccc97d656652b429a4c",
            "5e7acb56c9d748f28d588227878275da",
            "73538588f75848a2b692663ce13f44ba",
            "3c7e968dfc3d48ba9b89af0b6bac12da",
            "314b1a0af12c42929adaa6490ffd75eb",
            "81e86aba46b24884a62ef5cc8102ec49",
            "d55a8cdd68d74d1d931ea1ea5cdc4bbb",
            "1ccc86693fee4384935a1ba90b378324",
            "7ed0a02257094d709170b0a4cdecbfc3"
          ]
        },
        "id": "hZEoStUoYddB",
        "outputId": "b74e4c10-ede3-4450-bb3a-1878ea9ebf40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ GPU detected: NVIDIA L4\n",
            "  CUDA Version: 12.6\n",
            "  GPU Memory: 23.80 GB\n",
            "Using model: xlm-roberta-base\n",
            "Tokenizing datasets (this may take a moment)...\n",
            "  Using 4 processes for tokenization\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=4):   0%|          | 0/4696 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "20b5c30221f84a4bbf8c0c914fee2283"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=4):   0%|          | 0/1468 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a210378d435541dca3e4173c9c8a3efc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=4):   0%|          | 0/734 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "99f62c615857417793a550e696fae6ae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Datasets ready: train=4696, val=1468, test=734\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model loaded on cuda:0\n"
          ]
        }
      ],
      "source": [
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import platform\n",
        "\n",
        "# GPU detection and optimization settings\n",
        "USE_GPU = torch.cuda.is_available()\n",
        "if USE_GPU:\n",
        "    print(f\"✓ GPU detected: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"  CUDA Version: {torch.version.cuda}\")\n",
        "    print(f\"  GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    # Windows needs num_workers=0, Linux can use more\n",
        "    NUM_WORKERS = 0 if platform.system() == 'Windows' else 4\n",
        "    PIN_MEMORY = True\n",
        "else:\n",
        "    print(\"⚠ No GPU detected, using CPU (training will be slow)\")\n",
        "    device = torch.device(\"cpu\")\n",
        "    NUM_WORKERS = 0\n",
        "    PIN_MEMORY = False\n",
        "\n",
        "MODEL_CHOICES = {\n",
        "    \"xlmrb\": \"xlm-roberta-base\",\n",
        "    \"roberta-tl\": \"jcblaise/roberta-tagalog-base\",\n",
        "}\n",
        "MODEL_CHOICE = \"xlmrb\"\n",
        "MODEL_NAME = MODEL_CHOICES[MODEL_CHOICE]\n",
        "print(f\"Using model: {MODEL_NAME}\")\n",
        "\n",
        "MAX_LEN = 128\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
        "\n",
        "def tokenize_fn(batch):\n",
        "    return tokenizer(batch[\"review\"], truncation=True, padding=\"max_length\", max_length=MAX_LEN)\n",
        "\n",
        "print(\"Tokenizing datasets (this may take a moment)...\")\n",
        "ds_train = Dataset.from_pandas(df_train[['review','label']].reset_index(drop=True))\n",
        "ds_val   = Dataset.from_pandas(df_val[['review','label']].reset_index(drop=True))\n",
        "ds_test  = Dataset.from_pandas(df_test[['review','label']].reset_index(drop=True))\n",
        "\n",
        "if platform.system() == 'Windows':\n",
        "    NUM_PROC_TOKENIZE = None  # Disable parallel processing on Windows\n",
        "    print(\"  Using single-process tokenization (Windows compatibility)\")\n",
        "else:\n",
        "    NUM_PROC_TOKENIZE = 4 if USE_GPU else 2  # Parallel processing on Unix systems\n",
        "    print(f\"  Using {NUM_PROC_TOKENIZE} processes for tokenization\")\n",
        "\n",
        "ds_train = ds_train.map(tokenize_fn, batched=True, num_proc=NUM_PROC_TOKENIZE, remove_columns=['review'])\n",
        "ds_val   = ds_val.map(tokenize_fn, batched=True, num_proc=NUM_PROC_TOKENIZE, remove_columns=['review'])\n",
        "ds_test  = ds_test.map(tokenize_fn, batched=True, num_proc=NUM_PROC_TOKENIZE, remove_columns=['review'])\n",
        "\n",
        "cols = ['input_ids','attention_mask','label']\n",
        "ds_train = ds_train.with_format(\"torch\", columns=cols)\n",
        "ds_val   = ds_val.with_format(\"torch\", columns=cols)\n",
        "ds_test  = ds_test.with_format(\"torch\", columns=cols)\n",
        "\n",
        "print(f\"✓ Datasets ready: train={len(ds_train)}, val={len(ds_val)}, test={len(ds_test)}\")\n",
        "\n",
        "num_labels = 3\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=num_labels)\n",
        "model = model.to(device)\n",
        "print(f\"✓ Model loaded on {device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqaqVOkdWK3l"
      },
      "source": [
        "# **Training arguments, metric function, and Trainer construction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZGrsNThbRuB"
      },
      "source": [
        "#### Purpose / Description\n",
        "This cell defines evaluation metrics, configures **GPU-aware batch sizes** and precision, builds a **version-safe** `TrainingArguments` factory (so it works across different `transformers` versions), enables optional **gradient checkpointing**, attaches **early stopping**, and finally constructs a Hugging Face `Trainer`. With this, training and evaluation will use consistent metrics (accuracy, macro-F1), reproducible seeds, proper logging/saving cadence, and efficient dataloading based on the detected hardware.\n",
        "\n",
        "#### Input\n",
        "- Prepared datasets: `ds_train`, `ds_val`.\n",
        "- Runtime flags from earlier cells: `USE_GPU`, `FAST_MODE`, `NUM_WORKERS`, `PIN_MEMORY`, `MODEL_CHOICE`, `device`.\n",
        "- Objects: `model`, `tokenizer`.\n",
        "- Imports available: `numpy as np`, `accuracy_score`, `f1_score` (from `sklearn.metrics`), `torch`.\n",
        "\n",
        "#### Output\n",
        "- `training_args` — populated `TrainingArguments` instance.\n",
        "- `callbacks` — list containing `EarlyStoppingCallback`.\n",
        "- `trainer` — a fully configured `Trainer` ready for `.train()` / `.evaluate()`.\n",
        "- Console prints summarizing device, batch sizes, FP16, workers, pin memory, and early-stopping settings.\n",
        "\n",
        "---\n",
        "\n",
        "#### Line-by-Line Explanation\n",
        "\n",
        "`from transformers import TrainingArguments, Trainer, EarlyStoppingCallback`  \n",
        "Imports the configuration class for training, the high-level Trainer wrapper, and an early-stopping callback.\n",
        "\n",
        "`import inspect`  \n",
        "Provides reflection utilities to detect supported `TrainingArguments` parameters for version safety.\n",
        "\n",
        "`def compute_metrics(eval_pred):`  \n",
        "Starts a metric function that the Trainer will call during evaluation.\n",
        "\n",
        "`    preds = np.argmax(eval_pred.predictions, axis=1)`  \n",
        "Converts model logits to hard class predictions by argmax over the class dimension.\n",
        "\n",
        "`    labels = eval_pred.label_ids`  \n",
        "Fetches the ground-truth labels from the evaluation batch.\n",
        "\n",
        "`    acc = accuracy_score(labels, preds)`  \n",
        "Computes accuracy between predictions and labels.\n",
        "\n",
        "`    f1m = f1_score(labels, preds, average='macro')`  \n",
        "Computes macro-averaged F1 (each class contributes equally).\n",
        "\n",
        "`    return {'accuracy': acc, 'f1_macro': f1m}`  \n",
        "Returns a metrics dict that Trainer will record and use for “best model” selection.\n",
        "\n",
        "`# GPU-optimized batch sizes`  \n",
        "Comment: choose batch sizes/precision based on available hardware.\n",
        "\n",
        "`if USE_GPU:`  \n",
        "Checks if CUDA is available (set earlier).\n",
        "\n",
        "`    # Adjust batch size based on GPU memory (larger = faster training)`  \n",
        "Note: you may raise these if your GPU has more memory.\n",
        "\n",
        "`    TRAIN_BATCH_SIZE = 32  # Increase if you have more GPU memory`  \n",
        "Sets per-device train batch size for GPUs.\n",
        "\n",
        "`    EVAL_BATCH_SIZE = 64`  \n",
        "Sets per-device eval batch size (often can be larger than train).\n",
        "\n",
        "`    USE_FP16 = True`  \n",
        "Enables mixed-precision (float16) for faster GPU training.\n",
        "\n",
        "`    GRADIENT_CHECKPOINTING = False  # Set True if out of memory`  \n",
        "Option to trade compute for memory by checkpointing activations.\n",
        "\n",
        "`else:`  \n",
        "CPU fallback.\n",
        "\n",
        "`    TRAIN_BATCH_SIZE = 8   # Smaller for CPU`  \n",
        "Conservative per-device train batch size for CPU.\n",
        "\n",
        "`    EVAL_BATCH_SIZE = 16`  \n",
        "Eval batch size for CPU.\n",
        "\n",
        "`    USE_FP16 = False`  \n",
        "Mixed precision is disabled on CPU.\n",
        "\n",
        "`    GRADIENT_CHECKPOINTING = False`  \n",
        "No checkpointing by default on CPU.\n",
        "\n",
        "`sig = inspect.signature(TrainingArguments.__init__)`  \n",
        "Grabs the signature of the constructor to see what parameters are supported.\n",
        "\n",
        "`argnames = set(sig.parameters.keys())`  \n",
        "Builds a set of valid argument names for this installed `transformers` version.\n",
        "\n",
        "`def make_training_args(**overrides):`  \n",
        "Begins a small factory that produces a `TrainingArguments` object with sensible defaults and optional overrides.\n",
        "\n",
        "`    base_epochs = 2 if FAST_MODE else 3`  \n",
        "Chooses a short number of epochs for quick iteration vs full run.\n",
        "\n",
        "`    # Calculate warmup steps (10% of training steps)`  \n",
        "Comment: warmup helps schedule the LR.\n",
        "\n",
        "`    total_steps = max(1, (len(ds_train) // max(1, TRAIN_BATCH_SIZE)) * base_epochs)`  \n",
        "Approximates total steps to size warmup proportionally.\n",
        "\n",
        "`    warmup_steps = max(25, int(total_steps * 0.1))`  \n",
        "At least 25 steps or 10% of total steps, whichever is larger.\n",
        "\n",
        "`    cfg = dict(`  \n",
        "Starts the default configuration dictionary.\n",
        "\n",
        "`        output_dir=f\"./checkpoints/{MODEL_CHOICE}/run1\",`  \n",
        "Where to save checkpoints and logs.\n",
        "\n",
        "`        num_train_epochs=base_epochs,`  \n",
        "Number of training epochs.\n",
        "\n",
        "`        per_device_train_batch_size=TRAIN_BATCH_SIZE,`  \n",
        "Per-device batch size for training.\n",
        "\n",
        "`        per_device_eval_batch_size=EVAL_BATCH_SIZE,`  \n",
        "Per-device batch size for evaluation.\n",
        "\n",
        "`        learning_rate=3e-5,`  \n",
        "Base learning rate for AdamW.\n",
        "\n",
        "`        weight_decay=0.01,`  \n",
        "L2 weight decay for regularization.\n",
        "\n",
        "`        warmup_ratio=0.05,`  \n",
        "Warmup fraction (used if your version prefers ratio).\n",
        "\n",
        "`        lr_scheduler_type=\"linear\",`  \n",
        "Linear schedule with warmup.\n",
        "\n",
        "`        gradient_accumulation_steps=1,`  \n",
        "No gradient accumulation by default.\n",
        "\n",
        "`        load_best_model_at_end=True,`  \n",
        "Restores the best checkpoint after training.\n",
        "\n",
        "`        metric_for_best_model=\"f1_macro\",`  \n",
        "Chooses macro-F1 as the selection criterion.\n",
        "\n",
        "`        greater_is_better=True,`  \n",
        "Higher macro-F1 is better.\n",
        "\n",
        "`        seed=42,`  \n",
        "Reproducible seed.\n",
        "\n",
        "`        logging_steps=50,`  \n",
        "Log training loss/metrics every N steps.\n",
        "\n",
        "`        eval_steps=100,`  \n",
        "Run evaluation every N steps.\n",
        "\n",
        "`        save_steps=200,`  \n",
        "Save checkpoints every N steps.\n",
        "\n",
        "`        save_total_limit=2,`  \n",
        "Keep only the last/best few checkpoints.\n",
        "\n",
        "`        report_to=[],`  \n",
        "Disable external loggers (e.g., WandB) for clean notebooks.\n",
        "\n",
        "`        fp16=USE_FP16,`  \n",
        "Turn FP16 on/off based on hardware.\n",
        "\n",
        "`        dataloader_num_workers=NUM_WORKERS,`  \n",
        "Background workers for data loading.\n",
        "\n",
        "`        dataloader_pin_memory=PIN_MEMORY,`  \n",
        "Pin memory when using CUDA for faster transfers.\n",
        "\n",
        "`        remove_unused_columns=False,`  \n",
        "Preserve dataset columns needed by the model/tokenizer.\n",
        "\n",
        "`        gradient_checkpointing=GRADIENT_CHECKPOINTING,`  \n",
        "Optionally reduce memory usage at the cost of compute.\n",
        "\n",
        "`    )`  \n",
        "Closes the defaults.\n",
        "\n",
        "`    cfg.update(overrides)`  \n",
        "Allows callers to tweak any default via keyword arguments.\n",
        "\n",
        "`    # Handle different versions of transformers`  \n",
        "Comment: map strategy keys depending on version.\n",
        "\n",
        "`    if \"evaluation_strategy\" in argnames:`  \n",
        "If the current version expects `evaluation_strategy`…\n",
        "\n",
        "`        cfg[\"evaluation_strategy\"] = cfg.get(\"evaluation_strategy\", \"steps\")`  \n",
        "…set it to “steps” unless overridden.\n",
        "\n",
        "`    elif \"eval_strategy\" in argnames:`  \n",
        "Older/newer variants might use `eval_strategy`.\n",
        "\n",
        "`        cfg[\"eval_strategy\"] = cfg.get(\"eval_strategy\", \"steps\")`  \n",
        "Fallback to set `eval_strategy`.\n",
        "\n",
        "`    if \"save_strategy\" in argnames:`  \n",
        "If `save_strategy` is available…\n",
        "\n",
        "`        cfg[\"save_strategy\"] = cfg.get(\"save_strategy\", \"steps\")`  \n",
        "…ensure it matches the steps cadence.\n",
        "\n",
        "`    safe_cfg = {k:v for k,v in cfg.items() if k in argnames}`  \n",
        "Filter out any keys not supported by this version of `transformers`.\n",
        "\n",
        "`    return TrainingArguments(**safe_cfg)`  \n",
        "Instantiate and return the validated `TrainingArguments`.\n",
        "\n",
        "`training_args = make_training_args()`  \n",
        "Builds a concrete `TrainingArguments` with the defaults (or any overrides passed).\n",
        "\n",
        "`# Enable gradient checkpointing on model if needed`  \n",
        "Comment: some models support toggling this at runtime.\n",
        "\n",
        "`if GRADIENT_CHECKPOINTING and hasattr(model, 'gradient_checkpointing_enable'):`  \n",
        "Checks whether checkpointing is requested and implemented on the model.\n",
        "\n",
        "`    model.gradient_checkpointing_enable()`  \n",
        "Enables gradient checkpointing to reduce memory footprint.\n",
        "\n",
        "`    print(\"✓ Gradient checkpointing enabled (saves memory)\")`  \n",
        "Informs the user that the feature is active.\n",
        "\n",
        "`callbacks = [EarlyStoppingCallback(early_stopping_patience=2, early_stopping_threshold=0.001)]`  \n",
        "Configures early stopping: stop after 2 evaluations without at least 0.001 improvement in the monitored metric.\n",
        "\n",
        "`trainer = Trainer(`  \n",
        "Starts constructing the high-level Trainer.\n",
        "\n",
        "`    model=model,`  \n",
        "Passes the initialized classification model.\n",
        "\n",
        "`    args=training_args,`  \n",
        "Attaches the training/evaluation/saving configuration.\n",
        "\n",
        "`    train_dataset=ds_train,`  \n",
        "Training dataset.\n",
        "\n",
        "`    eval_dataset=ds_val,`  \n",
        "Validation dataset for periodic evals and model selection.\n",
        "\n",
        "`    compute_metrics=compute_metrics,`  \n",
        "Tells the Trainer how to compute accuracy and macro-F1 from logits.\n",
        "\n",
        "`    tokenizer=tokenizer,`  \n",
        "Provides the tokenizer for smart padding/decoding as needed.\n",
        "\n",
        "`    callbacks=callbacks,`  \n",
        "Registers early stopping (and any future callbacks you add).\n",
        "\n",
        "`)`  \n",
        "Closes the Trainer configuration.\n",
        "\n",
        "`print(f\"✓ Trainer ready on {device}\")`  \n",
        "Confirms the Trainer is initialized on the selected device.\n",
        "\n",
        "`print(f\"  Batch size: {TRAIN_BATCH_SIZE} (train), {EVAL_BATCH_SIZE} (eval)\")`  \n",
        "Echoes the effective per-device batch sizes.\n",
        "\n",
        "`print(f\"  FP16: {USE_FP16}, Workers: {NUM_WORKERS}, Pin Memory: {PIN_MEMORY}\")`  \n",
        "Summarizes precision and dataloader performance knobs.\n",
        "\n",
        "`print(f\"  Early stopping: patience=2\")`  \n",
        "Shows the early-stopping patience for quick reference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TschWlUwZBIo",
        "outputId": "08a10fc6-18a9-4f3f-d008-10e78a1bb5d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Trainer ready on cuda:0\n",
            "  Batch size: 32 (train), 64 (eval)\n",
            "  FP16: True, Workers: 4, Pin Memory: True\n",
            "  Early stopping: patience=2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1185774574.py:81: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ],
      "source": [
        "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback\n",
        "import inspect\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    preds = np.argmax(eval_pred.predictions, axis=1)\n",
        "    labels = eval_pred.label_ids\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    f1m = f1_score(labels, preds, average='macro')\n",
        "    return {'accuracy': acc, 'f1_macro': f1m}\n",
        "\n",
        "# GPU-optimized batch sizes\n",
        "if USE_GPU:\n",
        "    # Adjust batch size based on GPU memory (larger = faster training)\n",
        "    TRAIN_BATCH_SIZE = 32  # Increase if you have more GPU memory\n",
        "    EVAL_BATCH_SIZE = 64\n",
        "    USE_FP16 = True\n",
        "    GRADIENT_CHECKPOINTING = False  # Set True if out of memory\n",
        "else:\n",
        "    TRAIN_BATCH_SIZE = 8   # Smaller for CPU\n",
        "    EVAL_BATCH_SIZE = 16\n",
        "    USE_FP16 = False\n",
        "    GRADIENT_CHECKPOINTING = False\n",
        "\n",
        "sig = inspect.signature(TrainingArguments.__init__)\n",
        "argnames = set(sig.parameters.keys())\n",
        "\n",
        "def make_training_args(**overrides):\n",
        "    base_epochs = 2 if FAST_MODE else 3\n",
        "    # Calculate warmup steps (10% of training steps)\n",
        "    total_steps = max(1, (len(ds_train) // max(1, TRAIN_BATCH_SIZE)) * base_epochs)\n",
        "    warmup_steps = max(25, int(total_steps * 0.1))\n",
        "\n",
        "    cfg = dict(\n",
        "        output_dir=f\"./checkpoints/{MODEL_CHOICE}/run1\",\n",
        "        num_train_epochs=base_epochs,\n",
        "        per_device_train_batch_size=TRAIN_BATCH_SIZE,\n",
        "        per_device_eval_batch_size=EVAL_BATCH_SIZE,\n",
        "        learning_rate=3e-5,\n",
        "        weight_decay=0.01,\n",
        "        warmup_ratio=0.05,\n",
        "        lr_scheduler_type=\"linear\",\n",
        "        gradient_accumulation_steps=1,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"f1_macro\",\n",
        "        greater_is_better=True,\n",
        "        seed=42,\n",
        "        logging_steps=50,\n",
        "        eval_steps=100,\n",
        "        save_steps=200,\n",
        "        save_total_limit=2,\n",
        "        report_to=[],\n",
        "        fp16=USE_FP16,\n",
        "        dataloader_num_workers=NUM_WORKERS,\n",
        "        dataloader_pin_memory=PIN_MEMORY,\n",
        "        remove_unused_columns=False,\n",
        "        gradient_checkpointing=GRADIENT_CHECKPOINTING,\n",
        "    )\n",
        "    cfg.update(overrides)\n",
        "\n",
        "    # Handle different versions of transformers\n",
        "    if \"evaluation_strategy\" in argnames:\n",
        "        cfg[\"evaluation_strategy\"] = cfg.get(\"evaluation_strategy\", \"steps\")\n",
        "    elif \"eval_strategy\" in argnames:\n",
        "        cfg[\"eval_strategy\"] = cfg.get(\"eval_strategy\", \"steps\")\n",
        "\n",
        "    if \"save_strategy\" in argnames:\n",
        "        cfg[\"save_strategy\"] = cfg.get(\"save_strategy\", \"steps\")\n",
        "\n",
        "    safe_cfg = {k:v for k,v in cfg.items() if k in argnames}\n",
        "    return TrainingArguments(**safe_cfg)\n",
        "\n",
        "training_args = make_training_args()\n",
        "\n",
        "# Enable gradient checkpointing on model if needed\n",
        "if GRADIENT_CHECKPOINTING and hasattr(model, 'gradient_checkpointing_enable'):\n",
        "    model.gradient_checkpointing_enable()\n",
        "    print(\"✓ Gradient checkpointing enabled (saves memory)\")\n",
        "\n",
        "callbacks = [EarlyStoppingCallback(early_stopping_patience=2, early_stopping_threshold=0.001)]\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=ds_train,\n",
        "    eval_dataset=ds_val,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        "    callbacks=callbacks,\n",
        ")\n",
        "\n",
        "print(f\"✓ Trainer ready on {device}\")\n",
        "print(f\"  Batch size: {TRAIN_BATCH_SIZE} (train), {EVAL_BATCH_SIZE} (eval)\")\n",
        "print(f\"  FP16: {USE_FP16}, Workers: {NUM_WORKERS}, Pin Memory: {PIN_MEMORY}\")\n",
        "print(f\"  Early stopping: patience=2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eubP82RdScM"
      },
      "source": [
        "# **Automated Hyperparameter Search (Grid vs Random)**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDSlxnrfOp39"
      },
      "source": [
        "#### Purpose / Description\n",
        "This cell automates tuning for the Transformer model using **Optuna** with two strategies: **Grid** (exhaustive over a tiny discrete set) and **Random** (sampled from ranges). It defines a **class-weighted Trainer** (optional) for imbalance, builds a **lean per-trial Trainer** (fast, no mid-eval/checkpointing), runs trials to **maximize validation macro-F1**, writes detailed trial logs/summary CSVs, **refits the best trial per strategy**, evaluates on **validation and test**, saves test predictions, and appends compact best-run rows to `runs_log.csv`. Memory is freed between trials to keep the session stable.\n",
        "\n",
        "#### Input\n",
        "- From earlier cells: `Trainer`, `TrainingArguments`, `AutoModelForSequenceClassification`, `compute_metrics`, `ds_train`, `ds_val`, `ds_test`, `tokenizer`, `MODEL_NAME`, `num_labels`, `device`, `RANDOM_SEED`, `NUM_WORKERS`, `PIN_MEMORY`, `FAST_MODE`, `df_test`.\n",
        "- Libraries: `optuna`, `numpy as np`, `pandas as pd`, `json`, `torch`, `gc`, `time`, `Path` (`pathlib`), `os`, `inspect`.\n",
        "\n",
        "#### Output\n",
        "- In `tuning/`: `grid_trials.csv`, `random_trials.csv`, `all_trials.csv`, `strategy_summary.csv` (+ `.xlsx` variants if available), and `<strategy>_best_predictions.csv`.\n",
        "- Console prints: per-strategy best CV, validation/test metrics, timing.\n",
        "- Appended rows in `runs_log.csv` for best runs (both strategies).\n",
        "\n",
        "---\n",
        "\n",
        "#### Line-by-Line Explanation\n",
        "\n",
        "`import gc`  \n",
        "Use Python’s garbage collector to free memory between trials.\n",
        "\n",
        "`import time`  \n",
        "Measure wall-clock time per trial and best refit.\n",
        "\n",
        "`from optuna.samplers import GridSampler, RandomSampler`  \n",
        "Bring Optuna samplers for exhaustive grid and random sampling.\n",
        "\n",
        "`AUTO_TUNE_ENABLED = True`  \n",
        "Master switch to run/skip the entire auto-tune block.\n",
        "\n",
        "`SEARCH_STRATEGIES = [\"grid\", \"random\"]`  \n",
        "Run both strategies (order controls printing/logging order).\n",
        "\n",
        "`GRID_SEARCH_SPACE = {...}`  \n",
        "Tiny discrete grid over `learning_rate`, `per_device_train_batch_size`, `weight_decay` (keeps grid fast).\n",
        "\n",
        "`RANDOM_SEARCH_SPACE = {...}`  \n",
        "Random ranges: LR (log-uniform), batch size (choice), weight decay (uniform), epochs (int small range).\n",
        "\n",
        "`RANDOM_TRIALS = 6 if FAST_MODE else 10`  \n",
        "Limit random trials; fewer in fast/debug mode.\n",
        "\n",
        "`MAX_AUTOTUNE_EPOCHS = 2`  \n",
        "Hard cap on epochs **inside trials** to bound runtime.\n",
        "\n",
        "`AUTO_TUNE_USE_CLASS_WEIGHTS = True`  \n",
        "Enable weighted cross-entropy to mitigate label imbalance.\n",
        "\n",
        "`TUNING_DIR = Path(\"tuning\"); TUNING_DIR.mkdir(exist_ok=True)`  \n",
        "Create output folder for trials, predictions, and summaries.\n",
        "\n",
        "`if AUTO_TUNE_ENABLED:`  \n",
        "Enter the tuning workflow when enabled.\n",
        "\n",
        "`class WeightedTrainer(Trainer): ... compute_loss(...)`  \n",
        "Custom Trainer that swaps CE loss to a **weighted** CE when `class_weights` is provided.\n",
        "\n",
        "`globals()['WeightedTrainer'] = WeightedTrainer`  \n",
        "Expose the subclass so it’s callable in this cell’s scope.\n",
        "\n",
        "`cls_counts_auto = df_train['label'].value_counts()...`  \n",
        "Count class frequencies (order 0/1/2) from the **train** split.\n",
        "\n",
        "`class_weights_auto = (cls_counts_auto.sum() / (len(cls_counts_auto) * np.maximum(1.0, cls_counts_auto)))`  \n",
        "Inverse-frequency style class weights; guards against zero counts.\n",
        "\n",
        "`def _clean_hp_dict(hp_dict): ...`  \n",
        "Utility to cast NumPy types to plain Python types for JSON/CSV logging.\n",
        "\n",
        "`def build_trainer_for_trial(hparams, run_name):`  \n",
        "Factory that builds a **fresh** model/Trainer for a trial (keeps state isolated).\n",
        "\n",
        "`    def model_init(): mdl = AutoModelForSequenceClassification.from_pretrained(...); return mdl.to(device)`  \n",
        "Lazy model constructor—HF Trainer will call this per trial so each run starts clean on the right device.\n",
        "\n",
        "`    num_epochs = float(hparams.get(\"num_train_epochs\", MAX_AUTOTUNE_EPOCHS))`  \n",
        "Resolve epochs from trial params (bounded later by the cap).\n",
        "\n",
        "`    argnames_ta = set(inspect.signature(TrainingArguments.__init__).parameters.keys())`  \n",
        "Make the code **version-safe** by only passing supported kwargs.\n",
        "\n",
        "`    arg_kwargs = {...}`  \n",
        "Minimal `TrainingArguments`: trial LR/WD/BS, no mid-eval, no step-saves, workers/pin-memory set, logging cadence small.\n",
        "\n",
        "`    if \"warmup_steps\" in argnames_ta: ... elif \"warmup_ratio\" in argnames_ta: ...`  \n",
        "Zero warmup (steps or ratio) depending on transformers version.\n",
        "\n",
        "`    if \"evaluation_strategy\" in argnames_ta: ... elif \"eval_strategy\" in argnames_ta: ...`  \n",
        "Disable evaluation during training to keep trials fast (we evaluate after).\n",
        "\n",
        "`    if \"save_strategy\" in argnames_ta: arg_kwargs[\"save_strategy\"] = \"no\"`  \n",
        "Disable periodic checkpointing for speed.\n",
        "\n",
        "`    args = TrainingArguments(**{k:v for k,v in arg_kwargs.items() if k in argnames_ta})`  \n",
        "Instantiate arguments using only supported keys.\n",
        "\n",
        "`    trainer_cls = WeightedTrainer if AUTO_TUNE_USE_CLASS_WEIGHTS else Trainer`  \n",
        "Pick weighted vs vanilla Trainer.\n",
        "\n",
        "`    trainer_obj = trainer_cls(..., train_dataset=ds_train, eval_dataset=ds_val, compute_metrics=compute_metrics, tokenizer=tokenizer, class_weights=class_weights_auto)`  \n",
        "Create the per-trial Trainer bound to datasets, tokenizer, metrics, and optional class weights.\n",
        "\n",
        "`    return trainer_obj, args`  \n",
        "Return the configured Trainer and its args.\n",
        "\n",
        "`def suggest_params(trial, strategy):`  \n",
        "Map an Optuna `trial` to concrete hyperparameters depending on strategy.\n",
        "\n",
        "`    if strategy == \"grid\": params[name] = trial.suggest_categorical(...)`  \n",
        "Grid: categorical choices enumerate the grid; set epochs to the cap.\n",
        "\n",
        "`    else: ... suggest_float(..., log=True) / suggest_int(...) / suggest_categorical(...)`  \n",
        "Random: sample per the spec (log-uniform for LR, etc.).\n",
        "\n",
        "`    params[\"num_train_epochs\"] = min(MAX_AUTOTUNE_EPOCHS, max(1, ...))`  \n",
        "Clamp epochs into a safe range.\n",
        "\n",
        "`summary_rows = []`  \n",
        "Collect per-strategy “best” summaries for the final side-by-side table.\n",
        "\n",
        "`def objective(trial):`  \n",
        "Optuna objective—returns validation macro-F1 (to **maximize**).\n",
        "\n",
        "`    hparams = suggest_params(trial, current_strategy)`  \n",
        "Generate hyperparameters for this trial.\n",
        "\n",
        "`    trainer_obj, args = build_trainer_for_trial(hparams, run_name)`  \n",
        "Build a fresh Trainer for this trial.\n",
        "\n",
        "`    start = time.time(); trainer_obj.train(); val_metrics = trainer_obj.evaluate(); duration = time.time() - start`  \n",
        "Train, then evaluate on **validation**, time the full run.\n",
        "\n",
        "`    record = {... \"val_accuracy\": ..., \"val_f1_macro\": ..., \"train_time_sec\": ..., \"output_dir\": ...}`  \n",
        "Assemble a serializable record for export and analysis.\n",
        "\n",
        "`    trial.set_user_attr(\"record\", record)`  \n",
        "Attach trial’s record to the Optuna trial (retrieved later).\n",
        "\n",
        "`    del trainer_obj; gc.collect(); if USE_GPU: torch.cuda.empty_cache()`  \n",
        "Free memory/caches so subsequent trials don’t fragment GPU RAM.\n",
        "\n",
        "`    return record[\"val_f1_macro\"]`  \n",
        "Objective value—macro-F1 drives the search.\n",
        "\n",
        "`all_records = []`  \n",
        "Store all trials across both strategies for a global CSV.\n",
        "\n",
        "`for strategy in SEARCH_STRATEGIES:`  \n",
        "Run **grid** first, then **random**.\n",
        "\n",
        "`    if strategy == \"grid\": sampler = GridSampler(GRID_SEARCH_SPACE); n_trials = product(...)`  \n",
        "Grid: exhaustive traversal of all combinations.\n",
        "\n",
        "`    else: sampler = RandomSampler(); n_trials = RANDOM_TRIALS`  \n",
        "Random: sample a fixed number of trials.\n",
        "\n",
        "`    study = optuna.create_study(direction=\"maximize\", sampler=sampler)`  \n",
        "Create an Optuna study that maximizes the objective.\n",
        "\n",
        "`    study.optimize(objective, n_trials=n_trials, show_progress_bar=False)`  \n",
        "Run the trials; progress bar disabled for clean logs.\n",
        "\n",
        "`    for tr in study.trials: record = tr.user_attrs.get(\"record\"); ...`  \n",
        "Collect each trial’s stored record for CSV export.\n",
        "\n",
        "`    df_strategy = pd.DataFrame(strategy_records); df_strategy.to_csv(TUNING_DIR / f\"{strategy}_trials.csv\", ...)`  \n",
        "Write per-strategy trial table to CSV (and try XLSX).\n",
        "\n",
        "`    if study.best_trial is None: continue`  \n",
        "Skip refit if no successful trial.\n",
        "\n",
        "`    best_record = study.best_trial.user_attrs.get(\"record\")`  \n",
        "Retrieve the best trial’s metrics/params.\n",
        "\n",
        "`    best_params = best_record[\"hyperparameters\"].copy()`  \n",
        "Take the best hyperparameters for refit.\n",
        "\n",
        "`    trainer_best, args_best = build_trainer_for_trial(best_params, best_run_name)`  \n",
        "Construct a new Trainer for the **best** run.\n",
        "\n",
        "`    start = time.time(); trainer_best.train()`  \n",
        "Train best config on train split.\n",
        "\n",
        "`    val_best = trainer_best.evaluate()`  \n",
        "Evaluate best config on **validation**.\n",
        "\n",
        "`    test_best = trainer_best.evaluate(eval_dataset=ds_test, metric_key_prefix=\"test\")`  \n",
        "Evaluate best config on **test**; metrics will be named `test_*`.\n",
        "\n",
        "`    duration_best = time.time() - start`  \n",
        "Total time for best training + evals.\n",
        "\n",
        "`    preds_test = trainer_best.predict(ds_test); test_preds = np.argmax(preds_test.predictions, axis=1)`  \n",
        "Obtain raw logits on test and convert to predicted labels.\n",
        "\n",
        "`    pd.DataFrame({\"review\": df_test[\"review\"], \"gold\": df_test[\"label\"], \"pred\": test_preds}).to_csv(TUNING_DIR / f\"{strategy}_best_predictions.csv\", ...)`  \n",
        "Save per-example **test** predictions for error analysis.\n",
        "\n",
        "`    row_log = {... \"member\": f\"auto-{strategy}\", \"model\": MODEL_NAME, \"num_train_epochs\": ..., \"per_device_train_batch_size\": ..., \"learning_rate\": ..., \"weight_decay\": ..., \"accuracy\": ..., \"f1_macro\": ..., \"test_accuracy\": ..., \"test_f1_macro\": ..., \"training_time_min\": ...}`  \n",
        "Assemble a concise best-run row for `runs_log.csv` (contains val/test metrics + key hparams).\n",
        "\n",
        "`    pd.DataFrame([row_log]).to_csv(\"runs_log.csv\", mode=\"a\", index=False, header=not os.path.exists(\"runs_log.csv\"))`  \n",
        "Append the best-run row to the global experiment log (write header once).\n",
        "\n",
        "`    summary_rows.append({ \"strategy\": strategy, \"best_val_f1_macro\": study.best_value, \"best_val_accuracy\": best_record[\"val_accuracy\"], \"best_test_f1_macro\": test_best.get(\"test_f1_macro\", ...), \"best_test_accuracy\": test_best.get(\"test_accuracy\", ...), \"training_time_min\": duration_best/60.0, \"hyperparameters\": json.dumps(best_params) })`  \n",
        "Accumulate per-strategy best metrics/time and chosen hyperparameters for the final side-by-side summary.\n",
        "\n",
        "`    del trainer_best; gc.collect(); if USE_GPU: torch.cuda.empty_cache()`  \n",
        "Free memory after the best run.\n",
        "\n",
        "`if all_records: ... to_csv(\"tuning/all_trials.csv\"); try to_excel(...)`  \n",
        "Export combined trials from **both** strategies.\n",
        "\n",
        "`if summary_rows: df_summary = pd.DataFrame(summary_rows); df_summary.to_csv(\"tuning/strategy_summary.csv\", ...); display(df_summary)`  \n",
        "Write and display the **Grid vs Random** summary (best val/test metrics + time + hparams).\n",
        "\n",
        "`else: print(\"Automated search finished, but no successful trials were completed.\")`  \n",
        "Fallback message if nothing ran successfully.\n",
        "\n",
        "`AUTO_TUNE_ENABLED = False`  \n",
        "Turn off the flag so any legacy cells below won’t rerun tuning accidentally.\n",
        "\n",
        "`else: print(\"AUTO_TUNE_ENABLED is False; skipping automated hyperparameter search.\")`  \n",
        "Skip message when the block is disabled."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RNlk-GCrOp39",
        "outputId": "4ba43db1-c4d0-4b24-9e04-793204512bbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-09 06:46:01,281] A new study created in memory with name: no-name-cfe85ff4-6ef8-43e9-af00-ad515dea2321\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Hyperparameter search: GRID ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1009245886.py:28: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*args, **kwargs)\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='588' max='588' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [588/588 01:05, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.993600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.670300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.647100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.579900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.558000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.502500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.436400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.424500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.405900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.372200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.355600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='92' max='92' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [92/92 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-09 06:47:11,818] Trial 0 finished with value: 0.827523893370174 and parameters: {'learning_rate': 3e-05, 'per_device_train_batch_size': 16, 'weight_decay': 0.0}. Best is trial 0 with value: 0.827523893370174.\n",
            "/tmp/ipython-input-1009245886.py:28: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*args, **kwargs)\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='588' max='588' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [588/588 01:05, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.086400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.001500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.930100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.799600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.653900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.603900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.555100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.517100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.473600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.396700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.447200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='92' max='92' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [92/92 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-09 06:48:21,959] Trial 1 finished with value: 0.7978170218083949 and parameters: {'learning_rate': 5e-05, 'per_device_train_batch_size': 16, 'weight_decay': 0.0}. Best is trial 0 with value: 0.827523893370174.\n",
            "/tmp/ipython-input-1009245886.py:28: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*args, **kwargs)\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1174' max='1174' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1174/1174 02:10, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.094700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.011100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.919600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.728100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.838200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.666400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.743400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.677900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.607300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.598800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.586600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.597100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.573000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.478800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.501100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.534100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.416400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.492200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.455500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.380800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.447500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.482900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.505900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='92' max='92' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [92/92 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-09 06:50:37,006] Trial 2 finished with value: 0.815133536080026 and parameters: {'learning_rate': 5e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.05}. Best is trial 0 with value: 0.827523893370174.\n",
            "/tmp/ipython-input-1009245886.py:28: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*args, **kwargs)\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='588' max='588' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [588/588 01:05, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.008200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.778400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.660600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.559900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.548600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.485900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.454700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.432900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.389900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.355900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.355700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='92' max='92' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [92/92 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-09 06:51:47,318] Trial 3 finished with value: 0.8167395741224864 and parameters: {'learning_rate': 3e-05, 'per_device_train_batch_size': 16, 'weight_decay': 0.05}. Best is trial 0 with value: 0.827523893370174.\n",
            "/tmp/ipython-input-1009245886.py:28: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*args, **kwargs)\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='588' max='588' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [588/588 01:05, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.089900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.114200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.105300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.113700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>1.105300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>1.062400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.107100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>1.099800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.078500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.946800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='92' max='92' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [92/92 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-09 06:52:57,749] Trial 4 finished with value: 0.45967520263989653 and parameters: {'learning_rate': 5e-05, 'per_device_train_batch_size': 16, 'weight_decay': 0.05}. Best is trial 0 with value: 0.827523893370174.\n",
            "/tmp/ipython-input-1009245886.py:28: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*args, **kwargs)\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1174' max='1174' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1174/1174 02:09, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.059200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.960000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.117400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.044200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.992100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.040200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>1.029800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.872800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.985300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.112800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>1.041000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.927100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.860000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.868900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.905800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.855800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.841200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.795800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.750400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.685600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.695600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.789100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.688100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='92' max='92' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [92/92 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-09 06:55:12,080] Trial 5 finished with value: 0.6976536075521359 and parameters: {'learning_rate': 5e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.0}. Best is trial 0 with value: 0.827523893370174.\n",
            "/tmp/ipython-input-1009245886.py:28: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*args, **kwargs)\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1174' max='1174' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1174/1174 02:10, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.111700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.985500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.839600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.635200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.684700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.680400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.627800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.573600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.638900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.621900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.524900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.493300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.466300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.425500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.487400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.441600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.452000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.437600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.382200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.373900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.380400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.400800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.422100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='92' max='92' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [92/92 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-09 06:57:26,581] Trial 6 finished with value: 0.8346019778610959 and parameters: {'learning_rate': 3e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.05}. Best is trial 6 with value: 0.8346019778610959.\n",
            "/tmp/ipython-input-1009245886.py:28: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*args, **kwargs)\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1174' max='1174' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1174/1174 02:10, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.056900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.917400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.757500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.572300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.669200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.627400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.606100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.605800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.600900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.575800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.508900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.549300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.500600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.375600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.462200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.446100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.362000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.440500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.401400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.348700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.356100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.432600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.393800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='92' max='92' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [92/92 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-09 06:59:41,255] Trial 7 finished with value: 0.8196608545704113 and parameters: {'learning_rate': 3e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.0}. Best is trial 6 with value: 0.8346019778610959.\n",
            "/tmp/ipython-input-1009245886.py:28: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*args, **kwargs)\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1174' max='1174' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1174/1174 02:10, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.111700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.985500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.839600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.635200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.684700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.680400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.627800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.573600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.638900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.621900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.524900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.493300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.466300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.425500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.487400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.441600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.452000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.437600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.382200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.373900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.380400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.400800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.422100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-09 07:01:58,203] A new study created in memory with name: no-name-ea10b103-1d58-4e60-8b7f-0f359657ad01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Hyperparameter search: RANDOM ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1009245886.py:28: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*args, **kwargs)\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='588' max='588' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [588/588 01:05, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.001700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.716700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.584300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.577300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.576500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.508000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.446800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.444300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.413600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.365800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.365900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='92' max='92' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [92/92 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-09 07:03:08,286] Trial 0 finished with value: 0.8248988723003946 and parameters: {'learning_rate': 2.1325961392393355e-05, 'per_device_train_batch_size': 16, 'weight_decay': 0.0670604553457511, 'num_train_epochs': 3}. Best is trial 0 with value: 0.8248988723003946.\n",
            "/tmp/ipython-input-1009245886.py:28: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*args, **kwargs)\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='588' max='588' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [588/588 01:05, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.034400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.726800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.600700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.551700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.559800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.506000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.441600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.429400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.412800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.371900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.380900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='92' max='92' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [92/92 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-09 07:04:18,519] Trial 1 finished with value: 0.8230500340310843 and parameters: {'learning_rate': 2.1422856525077327e-05, 'per_device_train_batch_size': 16, 'weight_decay': 0.02629375105710129, 'num_train_epochs': 2}. Best is trial 0 with value: 0.8248988723003946.\n",
            "/tmp/ipython-input-1009245886.py:28: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*args, **kwargs)\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='588' max='588' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [588/588 01:05, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.011500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.698000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.606200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.552200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.558500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.472800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.420200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.440000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.389000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.357900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.366300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='92' max='92' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [92/92 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-09 07:05:28,746] Trial 2 finished with value: 0.8232034412208105 and parameters: {'learning_rate': 2.133333090307097e-05, 'per_device_train_batch_size': 16, 'weight_decay': 0.07623992752851556, 'num_train_epochs': 2}. Best is trial 0 with value: 0.8248988723003946.\n",
            "/tmp/ipython-input-1009245886.py:28: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*args, **kwargs)\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='588' max='588' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [588/588 01:05, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.996500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.769900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.621900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.561500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.578400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.480600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.435700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.445600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.403900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.359100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.357700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='92' max='92' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [92/92 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-09 07:06:38,815] Trial 3 finished with value: 0.8313619434764817 and parameters: {'learning_rate': 2.819325527551959e-05, 'per_device_train_batch_size': 16, 'weight_decay': 0.041869480074616106, 'num_train_epochs': 2}. Best is trial 3 with value: 0.8313619434764817.\n",
            "/tmp/ipython-input-1009245886.py:28: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*args, **kwargs)\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='392' max='392' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [392/392 00:47, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.982000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.719500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.609700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.568200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.464300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.429100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.402300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [62/62 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-09 07:07:30,719] Trial 4 finished with value: 0.8212606837606837 and parameters: {'learning_rate': 4.30453111868379e-05, 'per_device_train_batch_size': 24, 'weight_decay': 0.07184342972006058, 'num_train_epochs': 3}. Best is trial 3 with value: 0.8313619434764817.\n",
            "/tmp/ipython-input-1009245886.py:28: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*args, **kwargs)\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='588' max='588' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [588/588 01:05, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.988300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.760000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.607000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.567300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.576100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.506800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.445900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.430700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.408100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.348400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.366100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='92' max='92' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [92/92 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-09 07:08:40,832] Trial 5 finished with value: 0.8279557426945185 and parameters: {'learning_rate': 3.5183505332595754e-05, 'per_device_train_batch_size': 16, 'weight_decay': 0.022227672054147808, 'num_train_epochs': 3}. Best is trial 3 with value: 0.8313619434764817.\n",
            "/tmp/ipython-input-1009245886.py:28: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*args, **kwargs)\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='588' max='588' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [588/588 01:05, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.996500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.769900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.621900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.561500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.578400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.480600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.435700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.445600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.403900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.359100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.357700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  strategy  best_val_f1_macro  best_val_accuracy  best_test_f1_macro  \\\n",
              "0     grid           0.834602           0.832425            0.838439   \n",
              "1   random           0.831362           0.829019            0.844790   \n",
              "\n",
              "   best_test_accuracy  training_time_min  \\\n",
              "0            0.836512           2.243281   \n",
              "1            0.843324           1.167934   \n",
              "\n",
              "                                     hyperparameters  \n",
              "0  {\"learning_rate\": 3e-05, \"per_device_train_bat...  \n",
              "1  {\"learning_rate\": 2.819325527551959e-05, \"per_...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7f69758d-c4f2-4557-aa58-b8aa4e8d9721\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>strategy</th>\n",
              "      <th>best_val_f1_macro</th>\n",
              "      <th>best_val_accuracy</th>\n",
              "      <th>best_test_f1_macro</th>\n",
              "      <th>best_test_accuracy</th>\n",
              "      <th>training_time_min</th>\n",
              "      <th>hyperparameters</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>grid</td>\n",
              "      <td>0.834602</td>\n",
              "      <td>0.832425</td>\n",
              "      <td>0.838439</td>\n",
              "      <td>0.836512</td>\n",
              "      <td>2.243281</td>\n",
              "      <td>{\"learning_rate\": 3e-05, \"per_device_train_bat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>random</td>\n",
              "      <td>0.831362</td>\n",
              "      <td>0.829019</td>\n",
              "      <td>0.844790</td>\n",
              "      <td>0.843324</td>\n",
              "      <td>1.167934</td>\n",
              "      <td>{\"learning_rate\": 2.819325527551959e-05, \"per_...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7f69758d-c4f2-4557-aa58-b8aa4e8d9721')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7f69758d-c4f2-4557-aa58-b8aa4e8d9721 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7f69758d-c4f2-4557-aa58-b8aa4e8d9721');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e2065d74-0fb6-44e5-ac8b-25b051e7d281\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e2065d74-0fb6-44e5-ac8b-25b051e7d281')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e2065d74-0fb6-44e5-ac8b-25b051e7d281 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_dcc122b4-88ef-4718-a6cd-b1ff50e265bd\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_summary')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_dcc122b4-88ef-4718-a6cd-b1ff50e265bd button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_summary');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_summary",
              "summary": "{\n  \"name\": \"df_summary\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"strategy\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"random\",\n          \"grid\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"best_val_f1_macro\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0022910502846382667,\n        \"min\": 0.8313619434764817,\n        \"max\": 0.8346019778610959,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.8313619434764817,\n          0.8346019778610959\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"best_val_accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0024084018432784867,\n        \"min\": 0.8290190735694822,\n        \"max\": 0.832425068119891,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.8290190735694822,\n          0.832425068119891\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"best_test_f1_macro\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.004490355739367299,\n        \"min\": 0.8384393335410502,\n        \"max\": 0.8447896555275433,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.8447896555275433,\n          0.8384393335410502\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"best_test_accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.004816803686556816,\n        \"min\": 0.8365122615803815,\n        \"max\": 0.8433242506811989,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.8433242506811989,\n          0.8365122615803815\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"training_time_min\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7603855424296259,\n        \"min\": 1.167933722337087,\n        \"max\": 2.2432812690734862,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.167933722337087,\n          2.2432812690734862\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hyperparameters\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"{\\\"learning_rate\\\": 2.819325527551959e-05, \\\"per_device_train_batch_size\\\": 16, \\\"weight_decay\\\": 0.041869480074616106, \\\"num_train_epochs\\\": 2}\",\n          \"{\\\"learning_rate\\\": 3e-05, \\\"per_device_train_batch_size\\\": 8, \\\"weight_decay\\\": 0.05, \\\"num_train_epochs\\\": 2}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import gc\n",
        "import time\n",
        "from optuna.samplers import GridSampler, RandomSampler\n",
        "\n",
        "AUTO_TUNE_ENABLED = True\n",
        "SEARCH_STRATEGIES = [\"grid\", \"random\"]\n",
        "GRID_SEARCH_SPACE = {\n",
        "    \"learning_rate\": [5e-5, 3e-5],\n",
        "    \"per_device_train_batch_size\": [8, 16],\n",
        "    \"weight_decay\": [0.0, 0.05],\n",
        "}\n",
        "RANDOM_SEARCH_SPACE = {\n",
        "    \"learning_rate\": (\"float_log\", 2e-5, 5e-5),\n",
        "    \"per_device_train_batch_size\": (\"choice\", [8, 16, 24]),\n",
        "    \"weight_decay\": (\"float\", 0.0, 0.1),\n",
        "    \"num_train_epochs\": (\"int\", 2, 3),\n",
        "}\n",
        "RANDOM_TRIALS = 6 if FAST_MODE else 10\n",
        "MAX_AUTOTUNE_EPOCHS = 2\n",
        "AUTO_TUNE_USE_CLASS_WEIGHTS = True\n",
        "\n",
        "TUNING_DIR = Path(\"tuning\")\n",
        "TUNING_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "if AUTO_TUNE_ENABLED:\n",
        "    class WeightedTrainer(Trainer):\n",
        "        def __init__(self, *args, class_weights=None, **kwargs):\n",
        "            super().__init__(*args, **kwargs)\n",
        "            self.class_weights = None\n",
        "            if class_weights is not None:\n",
        "                self.class_weights = torch.tensor(class_weights, dtype=torch.float32)\n",
        "\n",
        "        def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None, **kwargs):\n",
        "            labels = inputs.get('labels')\n",
        "            outputs = model(**{k: v for k, v in inputs.items() if k != 'labels'})\n",
        "            logits = outputs.get('logits')\n",
        "            if self.class_weights is None:\n",
        "                loss_fct = torch.nn.CrossEntropyLoss()\n",
        "            else:\n",
        "                loss_fct = torch.nn.CrossEntropyLoss(weight=self.class_weights.to(logits.device))\n",
        "            loss = loss_fct(logits.view(-1, model.config.num_labels), labels.view(-1))\n",
        "            return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "    globals()['WeightedTrainer'] = WeightedTrainer\n",
        "\n",
        "    cls_counts_auto = df_train['label'].value_counts().sort_index().reindex([0, 1, 2]).fillna(0).values.astype(np.float32)\n",
        "    class_weights_auto = (cls_counts_auto.sum() / (len(cls_counts_auto) * np.maximum(1.0, cls_counts_auto))).astype(np.float32)\n",
        "\n",
        "    def _clean_hp_dict(hp_dict):\n",
        "        cleaned = {}\n",
        "        for key, value in hp_dict.items():\n",
        "            if isinstance(value, (np.floating, float)):\n",
        "                cleaned[key] = float(value)\n",
        "            elif isinstance(value, (np.integer, int)):\n",
        "                            cleaned[key] = int(value)\n",
        "            else:\n",
        "                cleaned[key] = value\n",
        "        return cleaned\n",
        "\n",
        "    def build_trainer_for_trial(hparams, run_name):\n",
        "        def model_init():\n",
        "            mdl = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=num_labels)\n",
        "            return mdl.to(device)\n",
        "\n",
        "        num_epochs = float(hparams.get(\"num_train_epochs\", MAX_AUTOTUNE_EPOCHS))\n",
        "        argnames_ta = set(inspect.signature(TrainingArguments.__init__).parameters.keys())\n",
        "        arg_kwargs = {\n",
        "            \"output_dir\": str(TUNING_DIR / run_name),\n",
        "            \"num_train_epochs\": num_epochs,\n",
        "            \"per_device_train_batch_size\": int(hparams[\"per_device_train_batch_size\"]),\n",
        "            \"per_device_eval_batch_size\": max(16, int(hparams[\"per_device_train_batch_size\"])),\n",
        "            \"learning_rate\": float(hparams[\"learning_rate\"]),\n",
        "            \"weight_decay\": float(hparams.get(\"weight_decay\", 0.0)),\n",
        "            \"logging_steps\": 50,\n",
        "            \"report_to\": [],\n",
        "            \"seed\": int(hparams.get(\"seed\", RANDOM_SEED)),\n",
        "            \"gradient_accumulation_steps\": 1,\n",
        "            \"dataloader_num_workers\": NUM_WORKERS,\n",
        "            \"dataloader_pin_memory\": PIN_MEMORY,\n",
        "            \"load_best_model_at_end\": False,\n",
        "        }\n",
        "        if \"warmup_steps\" in argnames_ta:\n",
        "            arg_kwargs[\"warmup_steps\"] = 0\n",
        "        elif \"warmup_ratio\" in argnames_ta:\n",
        "            arg_kwargs[\"warmup_ratio\"] = 0.0\n",
        "        if \"evaluation_strategy\" in argnames_ta:\n",
        "            arg_kwargs[\"evaluation_strategy\"] = \"no\"\n",
        "        elif \"eval_strategy\" in argnames_ta:\n",
        "            arg_kwargs[\"eval_strategy\"] = \"no\"\n",
        "        if \"save_strategy\" in argnames_ta:\n",
        "            arg_kwargs[\"save_strategy\"] = \"no\"\n",
        "        args = TrainingArguments(**{k: v for k, v in arg_kwargs.items() if k in argnames_ta})\n",
        "\n",
        "        callbacks = []\n",
        "        trainer_cls = WeightedTrainer if AUTO_TUNE_USE_CLASS_WEIGHTS else Trainer\n",
        "        trainer_obj = trainer_cls(\n",
        "            model_init=model_init,\n",
        "            args=args,\n",
        "            train_dataset=ds_train,\n",
        "            eval_dataset=ds_val,\n",
        "            compute_metrics=compute_metrics,\n",
        "            tokenizer=tokenizer,\n",
        "            callbacks=callbacks,\n",
        "            class_weights=(class_weights_auto if AUTO_TUNE_USE_CLASS_WEIGHTS else None)\n",
        "        )\n",
        "        return trainer_obj, args\n",
        "\n",
        "    def suggest_params(trial, strategy):\n",
        "        params = {}\n",
        "        if strategy == \"grid\":\n",
        "            for name, values in GRID_SEARCH_SPACE.items():\n",
        "                params[name] = trial.suggest_categorical(name, values)\n",
        "            params[\"num_train_epochs\"] = MAX_AUTOTUNE_EPOCHS\n",
        "        else:\n",
        "            for name, spec in RANDOM_SEARCH_SPACE.items():\n",
        "                kind = spec[0]\n",
        "                if kind == \"choice\":\n",
        "                    params[name] = trial.suggest_categorical(name, spec[1])\n",
        "                elif kind == \"float\":\n",
        "                    params[name] = trial.suggest_float(name, spec[1], spec[2])\n",
        "                elif kind == \"float_log\":\n",
        "                    params[name] = trial.suggest_float(name, spec[1], spec[2], log=True)\n",
        "                elif kind == \"int\":\n",
        "                    params[name] = trial.suggest_int(name, spec[1], spec[2])\n",
        "                else:\n",
        "                    raise ValueError(f\"Unsupported spec kind: {kind}\")\n",
        "        params[\"num_train_epochs\"] = float(params.get(\"num_train_epochs\", MAX_AUTOTUNE_EPOCHS))\n",
        "        params[\"num_train_epochs\"] = min(MAX_AUTOTUNE_EPOCHS, max(1, params[\"num_train_epochs\"]))\n",
        "        return params\n",
        "\n",
        "    summary_rows = []\n",
        "\n",
        "    def objective(trial):\n",
        "        hparams = suggest_params(trial, current_strategy)\n",
        "        run_name = f\"{current_strategy}_trial{trial.number}\"\n",
        "        trainer_obj, args = build_trainer_for_trial(hparams, run_name)\n",
        "        start = time.time()\n",
        "        trainer_obj.train()\n",
        "        val_metrics = trainer_obj.evaluate()\n",
        "        duration = time.time() - start\n",
        "\n",
        "        record = {\n",
        "            \"hyperparameters\": _clean_hp_dict(hparams),\n",
        "            \"val_accuracy\": float(val_metrics.get(\"eval_accuracy\", float(\"nan\"))),\n",
        "            \"val_f1_macro\": float(val_metrics.get(\"eval_f1_macro\", float(\"nan\"))),\n",
        "            \"train_time_sec\": duration,\n",
        "            \"output_dir\": args.output_dir,\n",
        "        }\n",
        "        trial.set_user_attr(\"record\", record)\n",
        "\n",
        "        # Cleanup to free memory\n",
        "        del trainer_obj\n",
        "        gc.collect()\n",
        "        if USE_GPU:\n",
        "            torch.cuda.empty_cache()\n",
        "        return record[\"val_f1_macro\"]\n",
        "\n",
        "    all_records = []\n",
        "    for strategy in SEARCH_STRATEGIES:\n",
        "        current_strategy = strategy\n",
        "        if strategy == \"grid\":\n",
        "            sampler = GridSampler(GRID_SEARCH_SPACE)\n",
        "            n_trials = int(np.prod([len(v) for v in GRID_SEARCH_SPACE.values()]))\n",
        "        else:\n",
        "            sampler = RandomSampler()\n",
        "            n_trials = RANDOM_TRIALS\n",
        "\n",
        "        print(f\"\\n=== Hyperparameter search: {strategy.upper()} ===\")\n",
        "        study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
        "        study.optimize(objective, n_trials=n_trials, show_progress_bar=False)\n",
        "\n",
        "        strategy_records = []\n",
        "        for tr in study.trials:\n",
        "            record = tr.user_attrs.get(\"record\")\n",
        "            if record:\n",
        "                rec = record.copy()\n",
        "                rec.update({\n",
        "                    \"strategy\": strategy,\n",
        "                    \"trial_number\": tr.number,\n",
        "                    \"state\": tr.state.name,\n",
        "                })\n",
        "                strategy_records.append(rec)\n",
        "                all_records.append(rec)\n",
        "\n",
        "        if strategy_records:\n",
        "            df_strategy = pd.DataFrame(strategy_records)\n",
        "            csv_path = TUNING_DIR / f\"{strategy}_trials.csv\"\n",
        "            df_strategy.to_csv(csv_path, index=False)\n",
        "            try:\n",
        "                df_strategy.to_excel(TUNING_DIR / f\"{strategy}_trials.xlsx\", index=False)\n",
        "            except Exception as exc:\n",
        "                print(f\"Excel export for {strategy} trials failed: {exc}\")\n",
        "        else:\n",
        "            print(f\"No successful trials recorded for {strategy}.\")\n",
        "\n",
        "        if study.best_trial is None:\n",
        "            continue\n",
        "\n",
        "        best_record = study.best_trial.user_attrs.get(\"record\")\n",
        "        if best_record is None:\n",
        "            continue\n",
        "\n",
        "        best_params = best_record[\"hyperparameters\"].copy()\n",
        "        best_run_name = f\"{strategy}_best\"\n",
        "        trainer_best, args_best = build_trainer_for_trial(best_params, best_run_name)\n",
        "        start = time.time()\n",
        "        trainer_best.train()\n",
        "        val_best = trainer_best.evaluate()\n",
        "        test_best = trainer_best.evaluate(eval_dataset=ds_test, metric_key_prefix=\"test\")\n",
        "        duration_best = time.time() - start\n",
        "\n",
        "        preds_test = trainer_best.predict(ds_test)\n",
        "        test_preds = np.argmax(preds_test.predictions, axis=1)\n",
        "        pd.DataFrame({\n",
        "            \"review\": df_test[\"review\"].tolist(),\n",
        "            \"gold\": df_test[\"label\"].tolist(),\n",
        "            \"pred\": test_preds,\n",
        "        }).to_csv(TUNING_DIR / f\"{strategy}_best_predictions.csv\", index=False)\n",
        "\n",
        "        row_log = {\n",
        "            \"member\": f\"auto-{strategy}\",\n",
        "            \"model\": MODEL_NAME,\n",
        "            \"num_train_epochs\": float(best_params.get(\"num_train_epochs\", MAX_AUTOTUNE_EPOCHS)),\n",
        "            \"per_device_train_batch_size\": int(best_params[\"per_device_train_batch_size\"]),\n",
        "            \"learning_rate\": float(best_params[\"learning_rate\"]),\n",
        "            \"weight_decay\": float(best_params.get(\"weight_decay\", 0.0)),\n",
        "            \"warmup_steps\": None,\n",
        "            \"lr_scheduler_type\": args_best.lr_scheduler_type,\n",
        "            \"gradient_accumulation_steps\": int(args_best.gradient_accumulation_steps),\n",
        "            \"max_seq_length\": MAX_LEN,\n",
        "            \"seed\": int(args_best.seed),\n",
        "            \"fp16\": bool(args_best.fp16),\n",
        "            \"accuracy\": float(val_best.get(\"eval_accuracy\", float(\"nan\"))),\n",
        "            \"f1_macro\": float(val_best.get(\"eval_f1_macro\", float(\"nan\"))),\n",
        "            \"test_accuracy\": float(test_best.get(\"test_accuracy\", float(\"nan\"))),\n",
        "            \"test_f1_macro\": float(test_best.get(\"test_f1_macro\", float(\"nan\"))),\n",
        "            \"training_time_min\": duration_best / 60.0,\n",
        "            \"notes\": f\"auto-{strategy} search (trials={len(strategy_records)})\",\n",
        "        }\n",
        "        pd.DataFrame([row_log]).to_csv(\n",
        "            \"runs_log.csv\",\n",
        "            mode=\"a\",\n",
        "            index=False,\n",
        "            header=not os.path.exists(\"runs_log.csv\")\n",
        "        )\n",
        "\n",
        "        summary_rows.append({\n",
        "            \"strategy\": strategy,\n",
        "            \"best_val_f1_macro\": study.best_value,\n",
        "            \"best_val_accuracy\": best_record[\"val_accuracy\"],\n",
        "            \"best_test_f1_macro\": test_best.get(\"test_f1_macro\", float(\"nan\")),\n",
        "            \"best_test_accuracy\": test_best.get(\"test_accuracy\", float(\"nan\")),\n",
        "            \"training_time_min\": duration_best / 60.0,\n",
        "            \"hyperparameters\": json.dumps(best_params),\n",
        "        })\n",
        "\n",
        "        del trainer_best\n",
        "        gc.collect()\n",
        "        if USE_GPU:\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    if all_records:\n",
        "        df_all_records = pd.DataFrame(all_records)\n",
        "        df_all_records.to_csv(TUNING_DIR / \"all_trials.csv\", index=False)\n",
        "        try:\n",
        "            df_all_records.to_excel(TUNING_DIR / \"all_trials.xlsx\", index=False)\n",
        "        except Exception as exc:\n",
        "            print(f\"Excel export for combined trials failed: {exc}\")\n",
        "\n",
        "    if summary_rows:\n",
        "        df_summary = pd.DataFrame(summary_rows)\n",
        "        summary_csv = TUNING_DIR / \"strategy_summary.csv\"\n",
        "        df_summary.to_csv(summary_csv, index=False)\n",
        "        try:\n",
        "            df_summary.to_excel(TUNING_DIR / \"strategy_summary.xlsx\", index=False)\n",
        "        except Exception as exc:\n",
        "            print(f\"Excel export for summary failed: {exc}\")\n",
        "        display(df_summary)\n",
        "    else:\n",
        "        print(\"Automated search finished, but no successful trials were completed.\")\n",
        "    # Prevent the legacy block further below from executing twice.\n",
        "    AUTO_TUNE_ENABLED = False\n",
        "else:\n",
        "    print(\"AUTO_TUNE_ENABLED is False; skipping automated hyperparameter search.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF-JcqvgOp39"
      },
      "source": [
        "<!-- Deprecated: superseded by the automated hyperparameter search block above. -->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOYlxuQqGxnp"
      },
      "source": [
        "# **Inference sanity check with a small pipeline**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGmm4xUyD4oF"
      },
      "source": [
        "#### Purpose / Description\n",
        "This cell runs a fast **sanity check** on the trained classifier using Hugging Face’s `pipeline` API. It feeds a few short Taglish sentences through the **text-classification** pipeline to confirm that the tokenizer, model, and device settings (GPU/CPU) work end-to-end and that the predicted labels/scores look reasonable before larger evaluations.\n",
        "\n",
        "#### Input\n",
        "- Trained `model` and matching `tokenizer` from prior cells.\n",
        "- `torch.cuda.is_available()` to decide GPU (`device=0`) vs CPU (`device=-1`).\n",
        "- Three Taglish sample sentences covering mixed sentiment.\n",
        "\n",
        "#### Output\n",
        "- Printed lines showing each input, the predicted label, and its confidence score.\n",
        "\n",
        "---\n",
        "\n",
        "#### Line-by-Line Explanation\n",
        "\n",
        "`from transformers import pipeline`  \n",
        "Imports the high-level inference utility that bundles preprocessing (tokenization), model forward pass, and postprocessing into one callable.\n",
        "\n",
        "`sentiment_analyzer = pipeline(`  \n",
        "Starts constructing a reusable inference pipeline object.\n",
        "\n",
        "`    \"text-classification\",`  \n",
        "Specifies the task type; returns the top label (and score) for each input text.\n",
        "\n",
        "`    model=model,`  \n",
        "Uses the fine-tuned sequence classification model created earlier in the notebook.\n",
        "\n",
        "`    tokenizer=tokenizer,`  \n",
        "Uses the paired tokenizer so text is encoded exactly as expected by the model.\n",
        "\n",
        "`    device=0 if torch.cuda.is_available() else -1`  \n",
        "Selects the first GPU when available (`0`); otherwise runs on CPU (`-1`).\n",
        "\n",
        "`)`  \n",
        "Completes the pipeline construction and assigns it to `sentiment_analyzer`.\n",
        "\n",
        "`samples = [`  \n",
        "Begins a small list of sample texts for a quick qualitative check.\n",
        "\n",
        "`    \"Ang bilis ng delivery, pero sira yung box.\",`  \n",
        "Mixed signal: positive speed, negative damaged box.\n",
        "\n",
        "`    \"solid yung quality, sakto ang size. sulit!\",`  \n",
        "Clearly positive: quality/fit/value cues.\n",
        "\n",
        "`    \"medyo pangit yung tela, tapos delay pa courier :(\"`  \n",
        "Negative: poor fabric and delayed delivery.\n",
        "\n",
        "`]`  \n",
        "Ends the list of sample sentences.\n",
        "\n",
        "`preds = sentiment_analyzer(samples)`  \n",
        "Runs batched inference; returns a list of dicts like `{'label': 'positive', 'score': 0.xx}`.\n",
        "\n",
        "`for t, r in zip(samples, preds):`  \n",
        "Iterates pairwise over each original text and its prediction result.\n",
        "\n",
        "`    print(f\"{t}\\n -> {r}\\n\")`  \n",
        "Prints the input line, an arrow, and the prediction dict (label + confidence) for quick human inspection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ed6AdjXcilJO",
        "outputId": "8c1b5961-114b-4b44-8514-854cbae67b65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ang bilis ng delivery, pero sira yung box.\n",
            " -> {'label': 'LABEL_1', 'score': 0.3587201237678528}\n",
            "\n",
            "solid yung quality, sakto ang size. sulit!\n",
            " -> {'label': 'LABEL_2', 'score': 0.3552475869655609}\n",
            "\n",
            "medyo pangit yung tela, tapos delay pa courier :(\n",
            " -> {'label': 'LABEL_1', 'score': 0.3542810082435608}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "sentiment_analyzer = pipeline(\n",
        "    \"text-classification\", model=model, tokenizer=tokenizer, device=0 if torch.cuda.is_available() else -1\n",
        ")\n",
        "\n",
        "samples = [\n",
        "    \"Ang bilis ng delivery, pero sira yung box.\",\n",
        "    \"solid yung quality, sakto ang size. sulit!\",\n",
        "    \"medyo pangit yung tela, tapos delay pa courier :(\"\n",
        "]\n",
        "preds = sentiment_analyzer(samples)\n",
        "for t, r in zip(samples, preds):\n",
        "    print(f\"{t}\\n -> {r}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xx7vWRVrGsDF"
      },
      "source": [
        "# **Confusion matrix and per-class report**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jSu0hb3D-6f"
      },
      "source": [
        "#### Purpose / Description\n",
        "Evaluates the model on the **validation** split, converts logits to class IDs, plots a **confusion matrix** to visualize errors, and builds a **classification report** (precision, recall, F1, support) per class and as averages—useful for your IEEE results section.\n",
        "\n",
        "#### Input\n",
        "- `trainer` (configured earlier with `model`, `ds_val`, `compute_metrics`)\n",
        "- `ds_val` (tokenized validation dataset)\n",
        "- Class order `[0, 1, 2]` ≙ `['negative','neutral','positive']`\n",
        "\n",
        "#### Output\n",
        "- Rendered **confusion matrix** (validation)\n",
        "- `df_report` — a pandas DataFrame with the **classification report**\n",
        "\n",
        "---\n",
        "\n",
        "#### Line-by-Line Explanation\n",
        "\n",
        "`import numpy as np, matplotlib.pyplot as plt`  \n",
        "Loads NumPy for array ops and Matplotlib for plotting.\n",
        "\n",
        "`from sklearn.metrics import confusion_matrix, classification_report`  \n",
        "Imports confusion matrix and per-class report utilities.\n",
        "\n",
        "`pred = trainer.predict(ds_val)`  \n",
        "Runs validation inference with the Hugging Face `Trainer`; returns logits and labels.\n",
        "\n",
        "`y_true = pred.label_ids`  \n",
        "Extracts the gold labels from the prediction output.\n",
        "\n",
        "`y_pred = np.argmax(pred.predictions, axis=1)`  \n",
        "Converts logits to predicted class IDs via argmax.\n",
        "\n",
        "`cm = confusion_matrix(y_true, y_pred, labels=[0,1,2])`  \n",
        "Computes a 3×3 matrix using a fixed class order (neg/neu/pos).\n",
        "\n",
        "`plt.figure()`  \n",
        "Creates a new figure for the plot.\n",
        "\n",
        "`plt.imshow(cm, interpolation='nearest')`  \n",
        "Displays the confusion matrix as a heatmap-like image.\n",
        "\n",
        "`plt.title('Confusion Matrix (Val)')`  \n",
        "Adds a descriptive title.\n",
        "\n",
        "`plt.xlabel('Predicted')`  \n",
        "Labels the x-axis with predicted classes.\n",
        "\n",
        "`plt.ylabel('True')`  \n",
        "Labels the y-axis with true classes.\n",
        "\n",
        "`plt.xticks([0,1,2], ['neg','neu','pos'])`  \n",
        "Sets readable tick labels for predicted classes.\n",
        "\n",
        "`plt.yticks([0,1,2], ['neg','neu','pos'])`  \n",
        "Sets readable tick labels for true classes.\n",
        "\n",
        "\n",
        "`for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        plt.text(j, i, cm[i, j], ha='center', va='center')`\n",
        "Annotates each cell with its integer count to make the figure readable without a colorbar.\n",
        "\n",
        "`plt.tight_layout()`\n",
        "Prevents label/annotation overlap.\n",
        "\n",
        "`plt.show()`\n",
        "Renders the confusion matrix in the notebook output.\n",
        "\n",
        "`report = classification_report(\n",
        "    y_true, y_pred, labels=[0,1,2],\n",
        "    target_names=['negative','neutral','positive'],\n",
        "    output_dict=True\n",
        ")`\n",
        "Computes per-class precision/recall/F1/support and average rows; returns a dict since output_dict=True.\n",
        "\n",
        "`df_report = pd.DataFrame(report).transpose()`\n",
        "Converts the dict to a tidy DataFrame, with one row per class/average.\n",
        "\n",
        "`df_report`\n",
        "Displays the classification report table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 733
        },
        "id": "YndcMJ2Bio64",
        "outputId": "6e4e999b-f202-4b1d-8af5-7fa99e348108"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              precision    recall  f1-score      support\n",
              "negative       0.000000  0.000000  0.000000   476.000000\n",
              "neutral        0.349108  0.998039  0.517276   510.000000\n",
              "positive       0.700000  0.014523  0.028455   482.000000\n",
              "accuracy       0.351499  0.351499  0.351499     0.351499\n",
              "macro avg      0.349703  0.337521  0.181911  1468.000000\n",
              "weighted avg   0.351121  0.351499  0.189051  1468.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-22cefb87-40e2-4ad9-bd97-017f7cf72bfc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>support</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>negative</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>476.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>0.349108</td>\n",
              "      <td>0.998039</td>\n",
              "      <td>0.517276</td>\n",
              "      <td>510.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.014523</td>\n",
              "      <td>0.028455</td>\n",
              "      <td>482.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>accuracy</th>\n",
              "      <td>0.351499</td>\n",
              "      <td>0.351499</td>\n",
              "      <td>0.351499</td>\n",
              "      <td>0.351499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>macro avg</th>\n",
              "      <td>0.349703</td>\n",
              "      <td>0.337521</td>\n",
              "      <td>0.181911</td>\n",
              "      <td>1468.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weighted avg</th>\n",
              "      <td>0.351121</td>\n",
              "      <td>0.351499</td>\n",
              "      <td>0.189051</td>\n",
              "      <td>1468.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-22cefb87-40e2-4ad9-bd97-017f7cf72bfc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-22cefb87-40e2-4ad9-bd97-017f7cf72bfc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-22cefb87-40e2-4ad9-bd97-017f7cf72bfc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-182a36a5-7edf-4b1f-842f-fd072198fc36\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-182a36a5-7edf-4b1f-842f-fd072198fc36')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-182a36a5-7edf-4b1f-842f-fd072198fc36 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_ff95020c-6b75-4b5d-b92c-4f35225b2bd6\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_report')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ff95020c-6b75-4b5d-b92c-4f35225b2bd6 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_report');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_report",
              "summary": "{\n  \"name\": \"df_report\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.221361263218901,\n        \"min\": 0.0,\n        \"max\": 0.7,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.0,\n          0.34910836762688613,\n          0.35112075442078466\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.36188204516327616,\n        \"min\": 0.0,\n        \"max\": 0.9980392156862745,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.9980392156862745,\n          0.3375206790876793,\n          0.014522821576763486\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1-score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19632414717786983,\n        \"min\": 0.0,\n        \"max\": 0.5172764227642277,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.0,\n          0.5172764227642277,\n          0.18905069670587712\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"support\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 599.332312320871,\n        \"min\": 0.35149863760217986,\n        \"max\": 1468.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          510.0,\n          1468.0,\n          482.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "import numpy as np, matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "pred = trainer.predict(ds_val)\n",
        "y_true = pred.label_ids\n",
        "y_pred = np.argmax(pred.predictions, axis=1)\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred, labels=[0,1,2])\n",
        "plt.figure()\n",
        "plt.imshow(cm, interpolation='nearest')\n",
        "plt.title('Confusion Matrix (Val)')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.xticks([0,1,2], ['neg','neu','pos'])\n",
        "plt.yticks([0,1,2], ['neg','neu','pos'])\n",
        "for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        plt.text(j, i, cm[i, j], ha='center', va='center')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "report = classification_report(y_true, y_pred, labels=[0,1,2],\n",
        "                               target_names=['negative','neutral','positive'],\n",
        "                               output_dict=True)\n",
        "df_report = pd.DataFrame(report).transpose()\n",
        "df_report\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hufxTwCGmOE"
      },
      "source": [
        "# **Export of consolidated logs and model summaries**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0T3L9mdTsIuI"
      },
      "source": [
        "# **Upgraded transformer training (early stopping, class weights, test evaluation)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wbogesfkg-3n"
      },
      "source": [
        "#### Purpose / Description\n",
        "Runs a **small sweep** over a couple of Transformer configurations (different `max_len` and `learning_rate`, with GPU-aware batch sizes). For each config it (1) rebuilds tokenized datasets at the given `max_len`, (2) trains with early stopping and weighted loss (if enabled), (3) records validation metrics and time, (4) keeps track of the **best** run (by validation macro-F1) and saves its checkpoint/tokenizer, then (5) evaluates that best run on the **test** set and logs predictions plus a summary row in `runs_log.csv`.\n",
        "\n",
        "#### Input\n",
        "- Globals from earlier cells: `MODEL_NAME`, `MODEL_CHOICE`, `df_train/df_val/df_test`, `device`, `WeightedTrainer`, `compute_metrics`, `USE_CLASS_WEIGHTS`, `CLASS_WEIGHTS_TENSOR`.\n",
        "- Libraries: `transformers` (Auto* + Trainer APIs), `datasets.Dataset`, `torch`, `numpy`, `pandas as pd`, `platform`, `os`, `time`, and metrics (`accuracy_score`, `f1_score`).\n",
        "\n",
        "#### Output\n",
        "- Console: per-run progress, validation metrics, best-run summary, test metrics.\n",
        "- Files: best checkpoint/tokenizer under `checkpoints/<MODEL_CHOICE>/best`, predictions `transformer_predictions_test.csv`, and an appended best-run row in `runs_log.csv`.\n",
        "\n",
        "---\n",
        "\n",
        "#### Line-by-Line Explanation (important lines)\n",
        "\n",
        "`USE_GPU_SWEEP = torch.cuda.is_available()`  \n",
        "Detects whether a CUDA GPU is present; enables faster training and larger batch sizes when `True`.\n",
        "\n",
        "`NUM_WORKERS_SWEEP = 0 if platform.system() == 'Windows' else 4`  \n",
        "Chooses DataLoader workers conservatively on Windows (0) and higher on Linux/Mac for throughput.\n",
        "\n",
        "`PIN_MEMORY_SWEEP = USE_GPU_SWEEP`  \n",
        "Pins host memory when using a GPU to speed up transfers.\n",
        "\n",
        "`def build_datasets_for_len(max_len: int):`  \n",
        "Helper that **re-tokenizes** all splits (train/val/test) with a specific `max_len` so the sweep can compare sequence lengths fairly.\n",
        "\n",
        "`tok = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)`  \n",
        "Loads the matching tokenizer (fast Rust implementation when available).\n",
        "\n",
        "`def _tok(batch): return tok(batch['review'], truncation=True, padding='max_length', max_length=max_len)`  \n",
        "Batched tokenization: truncates to `max_len` and pads to fixed length so tensors are uniform within a batch.\n",
        "\n",
        "`dtr/dva/dte = Dataset.from_pandas(...)`  \n",
        "Wraps pandas splits into Hugging Face `Dataset` objects (keeps only `review` and `label`).\n",
        "\n",
        "`num_proc_tok = None` (Windows) **else** `4 if USE_GPU_SWEEP else 2`  \n",
        "Controls tokenization parallelism: disable on Windows (stability), use multiple processes on Unix.\n",
        "\n",
        "`dtr/dva/dte = d*.map(_tok, batched=True, num_proc=num_proc_tok, remove_columns=['review'])`  \n",
        "Tokenizes each split in batched mode for speed, dropping raw text and keeping only token IDs/masks and label.\n",
        "\n",
        "`d*.with_format('torch', columns=['input_ids','attention_mask','label'])`  \n",
        "Switches each split to PyTorch tensor format, exposing exactly the columns Trainer expects.\n",
        "\n",
        "`DEFAULT_BS = 32 if USE_GPU_SWEEP else 8` and `DEFAULT_EVAL_BS = 64 if GPU else 16`  \n",
        "Sets sensible default batch sizes based on device; eval batch can be larger.\n",
        "\n",
        "`SWEEP = [...]`  \n",
        "Declares a **small** sweep: two configs varying `max_len` (128 vs 256) and `lr` (2e-5 vs 3e-5), with shared seed/epochs/batch size.\n",
        "\n",
        "`best_run = None`  \n",
        "Will store the best configuration (by validation macro-F1) as runs complete.\n",
        "\n",
        "`for i, cfg in enumerate(SWEEP, 1):`  \n",
        "Iterates over each sweep configuration and prints a nice header.\n",
        "\n",
        "`set_seed(cfg['seed'])`  \n",
        "Ensures reproducible sampling (dropout, shuffling, etc.) per configuration.\n",
        "\n",
        "`tokenizer_s, ds_tr_s, ds_va_s, ds_te_s = build_datasets_for_len(cfg['max_len'])`  \n",
        "Rebuilds tokenizer and datasets **for this `max_len`** so length is an explicit, comparable factor.\n",
        "\n",
        "`model_s = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=3)`  \n",
        "Creates a **fresh** classifier for the current sweep run.\n",
        "\n",
        "`model_s = model_s.to(device if 'device' in globals() else torch.device('cuda' if USE_GPU_SWEEP else 'cpu'))`  \n",
        "Moves the model to the primary device; falls back to CUDA if available, else CPU.\n",
        "\n",
        "`args = TrainingArguments(... evaluation_strategy='steps', eval_steps=200, save_steps=200, load_best_model_at_end=True, metric_for_best_model='f1_macro', ...)`  \n",
        "Training setup for the run: periodic evaluation/checkpointing, early best-model loading, batch sizes from the config, GPU-aware FP16, workers/pin-memory from earlier hardware detection.\n",
        "\n",
        "`callbacks = [EarlyStoppingCallback(early_stopping_patience=2, early_stopping_threshold=0.001)]`  \n",
        "Stops training early if macro-F1 fails to improve enough across evals.\n",
        "\n",
        "`trainer_s = WeightedTrainer(... class_weights=(CLASS_WEIGHTS_TENSOR if USE_CLASS_WEIGHTS else None))`  \n",
        "Creates a Trainer using **weighted loss** when enabled, pointing to the per-run datasets and tokenizer.\n",
        "\n",
        "`start = time.time(); trainer_s.train(); train_time = time.time() - start`  \n",
        "Measures wall-clock time for this run’s training loop.\n",
        "\n",
        "`eval_s = trainer_s.evaluate()`  \n",
        "Evaluates on the validation split and returns metrics (accuracy, macro-F1).\n",
        "\n",
        "`if USE_GPU_SWEEP: print(torch.cuda.memory_allocated(0) / 1e9)`  \n",
        "Optional GPU memory usage snapshot after training.\n",
        "\n",
        "`if best_run is None or eval_s['eval_f1_macro'] > best_run['val_f1']:`  \n",
        "Updates the **best run** if this configuration beats the current best macro-F1.\n",
        "\n",
        "`trainer_s.save_model(best_run['save_dir']); tokenizer_s.save_pretrained(best_run['save_dir'])`  \n",
        "Saves the checkpoint and tokenizer for the current best model under `checkpoints/<MODEL_CHOICE>/best`.\n",
        "\n",
        "`if best_run is not None:` (final block)  \n",
        "Only proceed to test evaluation if at least one run finished successfully.\n",
        "\n",
        "`preds = best_run['trainer'].predict(best_run['ds_test'])`  \n",
        "Runs the **best** trainer on the **test** split to obtain logits and labels.\n",
        "\n",
        "`y_true = preds.label_ids; y_pred = np.argmax(preds.predictions, axis=1)`  \n",
        "Extracts gold labels and converts logits to predicted class IDs.\n",
        "\n",
        "`acc = accuracy_score(y_true, y_pred); f1m = f1_score(y_true, y_pred, average='macro')`  \n",
        "Computes final **test accuracy** and **test macro-F1** for reporting.\n",
        "\n",
        "`pd.DataFrame({...}).to_csv('transformer_predictions_test.csv', index=False)`  \n",
        "Exports per-example test predictions for error analysis and appendix tables.\n",
        "\n",
        "`row = {... 'member': 'transformer', 'model': MODEL_NAME, 'num_train_epochs': cfg['epochs'], 'per_device_train_batch_size': cfg['bs'], 'learning_rate': cfg['lr'], 'max_seq_length': cfg['max_len'], 'accuracy': acc, 'f1_macro': f1m, ...}`  \n",
        "Builds a concise best-run entry capturing key hyperparameters and test metrics.\n",
        "\n",
        "`pd.DataFrame([row]).to_csv('runs_log.csv', mode='a', index=False, header=not os.path.exists('runs_log.csv'))`  \n",
        "Appends the best-run summary to the **global experiment log**, creating a header only once.\n",
        "\n",
        "`BEST_CKPT_DIR = best_run['save_dir'] if best_run is not None else None`  \n",
        "Convenience variable pointing to the saved **best checkpoint** directory (or `None` if no successful run)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UN2EKZ4QsIuI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a15431c968864e28a8e6d69de9397aaf",
            "aa0c6fd0bcd94ec3987c046b68545bbe",
            "119c9ce3c7974d5ba3c9d4fd23d83fe9",
            "0e39405f5f324e51b8c03dcefe625252",
            "4508796ec4e249439075a8c1b4972edb",
            "b832411160da43dd8135b896b5905041",
            "4be8e85d0d34413f8f0c2550c00fdcb8",
            "6e6e5937dea84c679998d4564c1291fa",
            "94439c1fb342430cbb296679fbc4ff7e",
            "22d2c0996cbd428f8ccafd219ae210e4",
            "7ca13a7a56bc493c8411edfcbec97a92",
            "f8f9c17ce3a7404292db9dd9708e18be",
            "b2dd5aa4eb2040549d12b474459f1ec6",
            "8e33b631650d4b91a6cfaad66397953e",
            "9fb2190cdf114a82b1200b2c366fa20d",
            "198715ec77124898af040e07b45ffc5f",
            "52101ba7828b48bfa6e6c1bdebd26f75",
            "a98c2bc972694aa4adfebea75da93bfa",
            "c35e5f98fc5e438f92e8fd7296e01507",
            "d6808d1557924171aab8b45891ae36c3",
            "85c4854de736406bacfd279963b446a6",
            "68442ec82e534d2da782c93d77820910",
            "9c9d61d2ffb644e1bdce42232a27bd98",
            "4f857d6871564d399ef5762286e7f939",
            "226b51d2ec204da686eb32305a1d1c0d",
            "26f2cdf8d3294e80b3ecf6d45eee744b",
            "92c0fdfe5ac64518a97951fb9a437cd1",
            "a1c73421f731444ba4985812f267ba13",
            "5d6ed8c9e09649888f5945a6616bfeb0",
            "64948bcf48444705aec82d4e0dab42a0",
            "9871e6c501ea45e9a722337a91a903c4",
            "ec1f414ea5a04d14a5bb2cf383be5b72",
            "120f98d2493848d08c09527f8ece7759",
            "30729f411428431aab4032fa39e2eae6",
            "7b358b0bae9549a58c4e2a3f7cf3326a",
            "4c3413ff1ca1494787ff99a2bcdbb353",
            "46bc2420ff9a4db4bda2ff97149f36bc",
            "76cd3343ebf546c3ac8c7d6a78b2a293",
            "b6a3d5fcab52486899c259bcef2843f2",
            "a4b9c22255f447b093f19147b55565e0",
            "32c39b0a41a744a8a88c3dd1fac02a53",
            "017f7a94511b4012a6ef8bfe69566ed1",
            "9dbcce9ccb1f46459e2b6c9b82b6d728",
            "2493f443b3254761badb078ac2607753",
            "677bdae148c8402ba058a7bf5df2474e",
            "8bd50bbef6814db18e61e48e718cc441",
            "cdac9a9ea44b48e9abe01e2a1eb080e7",
            "90ae5055353c47328bb80335101e97fc",
            "6c3031517cc44ac8b92ef17bc976cbee",
            "c3b2678238064284890a29f15a3e07ca",
            "dced8a41879046f2bcd1f0dbe7c2458e",
            "2dbc7e7815c147c097c27495389b229d",
            "a68c4dc57d2946688bdca1ff633ffaae",
            "d07ea582a1d04205bef8c62b6c2445a6",
            "b0e40bf1270b419cb936f3e5910f6b93",
            "c265f1f5b53043a1a4b7901178c85bc9",
            "4d07bf61728947189751f235877b9999",
            "3c8bd4c95feb4fc29d67471c08552f43",
            "ac1987a917984b698dc4004eac69e631",
            "b530b15b20cc43b48174d74e6baf2bd8",
            "667c623bdb994ea79830d566d538d845",
            "a7e3400a50ab48a8aef615e929957c85",
            "dbd2b87e1fa14de5bb923480608b6cad",
            "756eb37ffd024c9982facb402d557ef3",
            "bc08dfc5cb104a619c6453d98cebe7c6",
            "4f7f53034bd84a8bbd2e7a3fe708048b"
          ]
        },
        "outputId": "9e2b889d-eb45-4ab5-9a6b-ffaa6f1d3382"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting sweep with 2 configurations\n",
            "GPU: True, Batch size: 32\n",
            "\n",
            "============================================================\n",
            "Run 1/2: max_len=128, lr=2e-05, bs=32\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=4):   0%|          | 0/4696 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a15431c968864e28a8e6d69de9397aaf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=4):   0%|          | 0/1468 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f8f9c17ce3a7404292db9dd9708e18be"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=4):   0%|          | 0/734 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9c9d61d2ffb644e1bdce42232a27bd98"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1009245886.py:28: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*args, **kwargs)\n",
            "/tmp/ipython-input-1009245886.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.class_weights = torch.tensor(class_weights, dtype=torch.float32)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='441' max='441' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [441/441 01:37, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.512900</td>\n",
              "      <td>0.563362</td>\n",
              "      <td>0.767711</td>\n",
              "      <td>0.758090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.341600</td>\n",
              "      <td>0.464099</td>\n",
              "      <td>0.818120</td>\n",
              "      <td>0.819035</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [23/23 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Run 1 completed in 1.64 min\n",
            "  Val Accuracy: 0.8181\n",
            "  Val F1 Macro: 0.8190\n",
            "  GPU Memory: 8.96 GB\n",
            "\n",
            "============================================================\n",
            "Run 2/2: max_len=256, lr=3e-05, bs=32\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=4):   0%|          | 0/4696 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "30729f411428431aab4032fa39e2eae6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=4):   0%|          | 0/1468 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "677bdae148c8402ba058a7bf5df2474e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=4):   0%|          | 0/734 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c265f1f5b53043a1a4b7901178c85bc9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1009245886.py:28: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*args, **kwargs)\n",
            "/tmp/ipython-input-1009245886.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.class_weights = torch.tensor(class_weights, dtype=torch.float32)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='441' max='441' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [441/441 02:20, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.473300</td>\n",
              "      <td>0.492321</td>\n",
              "      <td>0.796322</td>\n",
              "      <td>0.791131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.315400</td>\n",
              "      <td>0.444066</td>\n",
              "      <td>0.820163</td>\n",
              "      <td>0.821190</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Run 2 completed in 2.35 min\n",
            "  Val Accuracy: 0.8202\n",
            "  Val F1 Macro: 0.8212\n",
            "  GPU Memory: 12.32 GB\n",
            "{'transformer_best_test_acc': 0.829700272479564, 'transformer_best_test_f1_macro': 0.8312209425699789, 'cfg': {'max_len': 256, 'seed': 42, 'lr': 3e-05, 'epochs': 3, 'bs': 32}}\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, EarlyStoppingCallback, set_seed\n",
        "import torch, numpy as np, os\n",
        "from datasets import Dataset\n",
        "import platform\n",
        "\n",
        "# GPU-optimized settings for sweep\n",
        "USE_GPU_SWEEP = torch.cuda.is_available()\n",
        "NUM_WORKERS_SWEEP = 0 if platform.system() == 'Windows' else 4\n",
        "PIN_MEMORY_SWEEP = USE_GPU_SWEEP\n",
        "\n",
        "# Build tokenized datasets for a given max length (with GPU optimizations)\n",
        "def build_datasets_for_len(max_len: int):\n",
        "    tok = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
        "    def _tok(batch):\n",
        "        return tok(batch['review'], truncation=True, padding='max_length', max_length=max_len)\n",
        "    dtr = Dataset.from_pandas(df_train[['review','label']].reset_index(drop=True))\n",
        "    dva = Dataset.from_pandas(df_val[['review','label']].reset_index(drop=True))\n",
        "    dte = Dataset.from_pandas(df_test[['review','label']].reset_index(drop=True))\n",
        "\n",
        "    # Windows multiprocessing has issues with tokenizers\n",
        "    if platform.system() == 'Windows':\n",
        "        num_proc_tok = None  # Disable parallel processing on Windows\n",
        "    else:\n",
        "        num_proc_tok = 4 if USE_GPU_SWEEP else 2  # Parallel on Unix systems\n",
        "\n",
        "    # Tokenize (batched=True is faster)\n",
        "    # Only remove 'review' column, keep 'label' column\n",
        "    dtr = dtr.map(_tok, batched=True, num_proc=num_proc_tok, remove_columns=['review'])\n",
        "    dva = dva.map(_tok, batched=True, num_proc=num_proc_tok, remove_columns=['review'])\n",
        "    dte = dte.map(_tok, batched=True, num_proc=num_proc_tok, remove_columns=['review'])\n",
        "\n",
        "    cols = ['input_ids','attention_mask','label']\n",
        "    dtr = dtr.with_format('torch', columns=cols)\n",
        "    dva = dva.with_format('torch', columns=cols)\n",
        "    dte = dte.with_format('torch', columns=cols)\n",
        "    return tok, dtr, dva, dte\n",
        "\n",
        "# GPU-optimized batch sizes for sweep\n",
        "if USE_GPU_SWEEP:\n",
        "    DEFAULT_BS = 32  # Larger batch for GPU\n",
        "    DEFAULT_EVAL_BS = 64\n",
        "else:\n",
        "    DEFAULT_BS = 8\n",
        "    DEFAULT_EVAL_BS = 16\n",
        "\n",
        "# Define class weights for weighted loss\n",
        "# Assuming df_train is available from previous cells\n",
        "cls_counts = df_train['label'].value_counts().sort_index().reindex([0, 1, 2]).fillna(0).values.astype(np.float32)\n",
        "class_weights = (cls_counts.sum() / (len(cls_counts) * np.maximum(1.0, cls_counts))).astype(np.float32)\n",
        "CLASS_WEIGHTS_TENSOR = torch.tensor(class_weights, dtype=torch.float32)\n",
        "USE_CLASS_WEIGHTS = True # Assuming you want to use class weights based on the notebook context\n",
        "\n",
        "# Small sweep configurations (GPU-optimized)\n",
        "SWEEP = [\n",
        "    {'max_len': 128, 'seed': 42, 'lr': 2e-5, 'epochs': 3, 'bs': DEFAULT_BS},\n",
        "    {'max_len': 256, 'seed': 42, 'lr': 3e-5, 'epochs': 3, 'bs': DEFAULT_BS},\n",
        "]\n",
        "\n",
        "print(f\"Starting sweep with {len(SWEEP)} configurations\")\n",
        "print(f\"GPU: {USE_GPU_SWEEP}, Batch size: {DEFAULT_BS}\")\n",
        "\n",
        "best_run = None\n",
        "for i, cfg in enumerate(SWEEP, 1):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Run {i}/{len(SWEEP)}: max_len={cfg['max_len']}, lr={cfg['lr']}, bs={cfg['bs']}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    set_seed(cfg['seed'])\n",
        "    tokenizer_s, ds_tr_s, ds_va_s, ds_te_s = build_datasets_for_len(cfg['max_len'])\n",
        "    model_s = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=3)\n",
        "    model_s = model_s.to(device if 'device' in globals() else torch.device('cuda' if USE_GPU_SWEEP else 'cpu'))\n",
        "\n",
        "    args = make_training_args(\n",
        "        output_dir=f\"checkpoints/{MODEL_CHOICE}/sweep_len{cfg['max_len']}_seed{cfg['seed']}\",\n",
        "        num_train_epochs=cfg['epochs'],\n",
        "        per_device_train_batch_size=cfg['bs'],\n",
        "        per_device_eval_batch_size=DEFAULT_EVAL_BS,\n",
        "        learning_rate=cfg['lr'],\n",
        "        weight_decay=0.01,\n",
        "        warmup_ratio=0.1,\n",
        "        lr_scheduler_type='linear',\n",
        "        seed=cfg['seed'],\n",
        "        logging_steps=50,\n",
        "        fp16=USE_GPU_SWEEP,\n",
        "        dataloader_num_workers=NUM_WORKERS_SWEEP,\n",
        "        dataloader_pin_memory=PIN_MEMORY_SWEEP,\n",
        "        save_total_limit=2,\n",
        "        report_to=[],\n",
        "        remove_unused_columns=False,\n",
        "        evaluation_strategy='steps',\n",
        "        eval_steps=200,\n",
        "        save_strategy='steps',\n",
        "        save_steps=200,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model='f1_macro',\n",
        "        greater_is_better=True,\n",
        "    )\n",
        "\n",
        "    callbacks = [EarlyStoppingCallback(early_stopping_patience=2, early_stopping_threshold=0.001)]\n",
        "    trainer_s = WeightedTrainer(\n",
        "        model=model_s,\n",
        "        args=args,\n",
        "        train_dataset=ds_tr_s,\n",
        "        eval_dataset=ds_va_s,\n",
        "        compute_metrics=compute_metrics,\n",
        "        tokenizer=tokenizer_s,\n",
        "        callbacks=callbacks,\n",
        "        class_weights=(CLASS_WEIGHTS_TENSOR if USE_CLASS_WEIGHTS else None)\n",
        "    )\n",
        "\n",
        "    import time\n",
        "    start = time.time()\n",
        "    trainer_s.train()\n",
        "    train_time = time.time() - start\n",
        "\n",
        "    eval_s = trainer_s.evaluate()\n",
        "    print(f'\\n✓ Run {i} completed in {train_time/60:.2f} min')\n",
        "    print(f'  Val Accuracy: {eval_s.get(\"eval_accuracy\", 0):.4f}')\n",
        "    print(f'  Val F1 Macro: {eval_s.get(\"eval_f1_macro\", 0):.4f}')\n",
        "\n",
        "    if USE_GPU_SWEEP:\n",
        "        print(f'  GPU Memory: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB')\n",
        "\n",
        "    if best_run is None or eval_s.get('eval_f1_macro', -1) > best_run['val_f1']:\n",
        "        best_run = {\n",
        "            'cfg': cfg,\n",
        "            'val_f1': float(eval_s.get('eval_f1_macro', -1)),\n",
        "            'val_acc': float(eval_s.get('eval_accuracy', -1)),\n",
        "            'tokenizer': tokenizer_s,\n",
        "            'trainer': trainer_s,\n",
        "            'ds_test': ds_te_s,\n",
        "            'save_dir': f\"checkpoints/{MODEL_CHOICE}/best\"\n",
        "        }\n",
        "        # save current best\n",
        "        os.makedirs(best_run['save_dir'], exist_ok=True)\n",
        "        trainer_s.save_model(best_run['save_dir'])\n",
        "        tokenizer_s.save_pretrained(best_run['save_dir'])\n",
        "\n",
        "# Evaluate best on test and export predictions\n",
        "if best_run is not None:\n",
        "    preds = best_run['trainer'].predict(best_run['ds_test'])\n",
        "    y_true = preds.label_ids\n",
        "    y_pred = np.argmax(preds.predictions, axis=1)\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    f1m = f1_score(y_true, y_pred, average='macro')\n",
        "    print({'transformer_best_test_acc': acc, 'transformer_best_test_f1_macro': f1m, 'cfg': best_run['cfg']})\n",
        "\n",
        "    # Save predictions\n",
        "    pd.DataFrame({\n",
        "        'review': df_test['review'].tolist(), 'gold': df_test['label'].tolist(), 'pred': y_pred\n",
        "    }).to_csv('transformer_predictions_test.csv', index=False)\n",
        "\n",
        "    # Log\n",
        "    row = {\n",
        "        'member': 'transformer',\n",
        "        'model': MODEL_NAME,\n",
        "        'num_train_epochs': best_run['cfg']['epochs'],\n",
        "        'per_device_train_batch_size': best_run['cfg']['bs'],\n",
        "        'learning_rate': best_run['cfg']['lr'],\n",
        "        'weight_decay': 0.01,\n",
        "        'warmup_steps': None,\n",
        "        'lr_scheduler_type': 'linear',\n",
        "        'gradient_accumulation_steps': 1,\n",
        "        'max_seq_length': best_run['cfg']['max_len'],\n",
        "        'seed': best_run['cfg']['seed'],\n",
        "        'fp16': bool(torch.cuda.is_available()),\n",
        "        'accuracy': acc,\n",
        "        'f1_macro': f1m,\n",
        "        'notes': f\"early_stop=2; class_weights={USE_CLASS_WEIGHTS}\"\n",
        "    }\n",
        "    pd.DataFrame([row]).to_csv('runs_log.csv', mode='a', index=False, header=not os.path.exists('runs_log.csv'))\n",
        "\n",
        "BEST_CKPT_DIR = best_run['save_dir'] if best_run is not None else None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nX6m1vlsIuJ"
      },
      "source": [
        "# **Export: ONNX and dynamic quantized PyTorch**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JZDlKi4hasK"
      },
      "source": [
        "\n",
        "#### Purpose / Description\n",
        "This cell **loads the best fine-tuned checkpoint** and exports two lightweight deployment artifacts:\n",
        "1) an **ONNX** model (portable for many runtimes, e.g., ONNX Runtime) with dynamic axes for batch and sequence length, and  \n",
        "2) a **dynamically quantized** PyTorch state dict (int8 for `Linear` layers) to reduce model size and improve CPU latency.  \n",
        "It falls back to a sensible default directory name if `BEST_CKPT_DIR` is not set.\n",
        "\n",
        "#### Input\n",
        "- `BEST_CKPT_DIR` (from earlier sweep/tuning) or a fallback path derived from `MODEL_NAME`.\n",
        "- Hugging Face checkpoint files under the chosen directory (tokenizer + model).\n",
        "- PyTorch (`torch`), Transformers (`AutoTokenizer`, `AutoModelForSequenceClassification`).\n",
        "\n",
        "#### Output\n",
        "- `model.onnx` saved inside the checkpoint directory.\n",
        "- `pytorch_model_quantized.bin` (quantized state_dict) saved inside the checkpoint directory.\n",
        "- Console prints confirming the export locations.\n",
        "\n",
        "---\n",
        "\n",
        "#### Line-by-Line Explanation (important lines)\n",
        "\n",
        "`ckpt_dir = BEST_CKPT_DIR if ... else f\"./finetuned_{MODEL_NAME.replace('/','_')}_best\"`  \n",
        "Selects the **export source directory**: prefers `BEST_CKPT_DIR` (if defined and non-empty), else constructs a fallback path from `MODEL_NAME` (slashes replaced to keep a valid folder name).\n",
        "\n",
        "`print('Exporting from:', ckpt_dir)`  \n",
        "Logs the resolved checkpoint directory for traceability.\n",
        "\n",
        "`tokenizer_exp = AutoTokenizer.from_pretrained(ckpt_dir, use_fast=True)`  \n",
        "Loads the tokenizer assets **from the checkpoint folder** so tokenization matches the exported model.\n",
        "\n",
        "`model_exp = AutoModelForSequenceClassification.from_pretrained(ckpt_dir).cpu().eval()`  \n",
        "Loads the sequence classifier weights from the same folder, then moves to **CPU** and switches to **eval** mode to stabilize export.\n",
        "\n",
        "`onnx_path = Path(ckpt_dir)/'model.onnx'`  \n",
        "Defines the destination path for the ONNX file within the checkpoint directory.\n",
        "\n",
        "`dummy = tokenizer_exp(\"ok lang\", return_tensors='pt', padding='max_length', truncation=True, max_length=128)`  \n",
        "Builds a **dummy input batch** (token IDs + attention mask) for tracing the export graph; uses a typical `max_length`.\n",
        "\n",
        "`with torch.no_grad():`  \n",
        "Disables autograd—export only needs forward computation.\n",
        "\n",
        "`torch.onnx.export(\n",
        "    model_exp,\n",
        "    (dummy['input_ids'], dummy['attention_mask']),\n",
        "    str(onnx_path),\n",
        "    input_names=['input_ids','attention_mask'],\n",
        "    output_names=['logits'],\n",
        "    dynamic_axes={\n",
        "        'input_ids': {0: 'batch', 1: 'seq'},\n",
        "        'attention_mask': {0: 'batch', 1: 'seq'},\n",
        "        'logits': {0: 'batch'}\n",
        "    },\n",
        "    opset_version=13\n",
        ")`\n",
        "\n",
        "Performs the ONNX export with:\n",
        "\n",
        " - Inputs: input_ids, attention_mask\n",
        "\n",
        " - Output: logits\n",
        "\n",
        " - Dynamic axes: variable batch and seq length so the graph is flexible at inference time\n",
        "\n",
        " - Opset 13: a widely supported ONNX opset for Transformer models.\n",
        "\n",
        "`print('ONNX saved to', onnx_path)`\n",
        "Confirms ONNX artifact location.\n",
        "\n",
        "`quantized = torch.quantization.quantize_dynamic(model_exp, {torch.nn.Linear}, dtype=torch.qint8)`\n",
        "Applies dynamic quantization to all Linear layers\n",
        "\n",
        "`(weights become int8; activations are quantized/dequantized at runtime).` This is especially helpful for CPU inference.\n",
        "\n",
        "`q_path = Path(ckpt_dir)/'pytorch_model_quantized.bin'`\n",
        "Destination for the quantized state_dict.\n",
        "\n",
        "`torch.save(quantized.state_dict(), q_path)`\n",
        "Serializes only the quantized weights (state_dict), which can be loaded into the same architecture at runtime.\n",
        "\n",
        "`print('Quantized state_dict saved to', q_path)`\n",
        "Confirms the quantized weights file path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugzJQ2xdsIuJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a270ab8-6f50-4065-c5ba-54f31928fc5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exporting from: checkpoints/xlmrb/best\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-984674442.py:29: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
            "For migrations of users: \n",
            "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
            "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
            "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
            "see https://github.com/pytorch/ao/issues/2259 for more details\n",
            "  quantized = torch.quantization.quantize_dynamic(model_exp, {torch.nn.Linear}, dtype=torch.qint8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantized state_dict saved to checkpoints/xlmrb/best/pytorch_model_quantized.bin\n"
          ]
        }
      ],
      "source": [
        "import torch, os\n",
        "from pathlib import Path\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "ckpt_dir = BEST_CKPT_DIR if 'BEST_CKPT_DIR' in globals() and BEST_CKPT_DIR else f\"./finetuned_{MODEL_NAME.replace('/','_')}_best\"\n",
        "print('Exporting from:', ckpt_dir)\n",
        "\n",
        "tokenizer_exp = AutoTokenizer.from_pretrained(ckpt_dir, use_fast=True)\n",
        "model_exp = AutoModelForSequenceClassification.from_pretrained(ckpt_dir).cpu().eval()\n",
        "\n",
        "# # ONNX export - Commented out due to compatibility issues\n",
        "# onnx_path = Path(ckpt_dir)/'model.onnx'\n",
        "# dummy = tokenizer_exp(\"ok lang\", return_tensors='pt', padding='max_length', truncation=True, max_length=128)\n",
        "# with torch.no_grad():\n",
        "#     torch.onnx.export(\n",
        "#         model_exp,\n",
        "#         (dummy['input_ids'], dummy['attention_mask']),\n",
        "#         str(onnx_path),\n",
        "#         input_names=['input_ids','attention_mask'],\n",
        "#         output_names=['logits'],\n",
        "#         dynamic_axes={'input_ids': {0: 'batch', 1:'seq'},\n",
        "#                       'attention_mask': {0: 'batch', 1:'seq'},\n",
        "#                       'logits': {0: 'batch'}},\n",
        "#         opset_version=14\n",
        "#     )\n",
        "# print('ONNX saved to', onnx_path)\n",
        "\n",
        "# Dynamic quantization (PyTorch)\n",
        "quantized = torch.quantization.quantize_dynamic(model_exp, {torch.nn.Linear}, dtype=torch.qint8)\n",
        "q_path = Path(ckpt_dir)/'pytorch_model_quantized.bin'\n",
        "torch.save(quantized.state_dict(), q_path)\n",
        "print('Quantized state_dict saved to', q_path)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "650b9453"
      },
      "source": [
        "%pip install onnx -qqq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKFlT6EAsIuJ"
      },
      "source": [
        "# **Inference helpers and batch scoring**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oF9xKSn8iYvq"
      },
      "source": [
        "#### Purpose / Description\n",
        "Provides two reusable **inference utilities**:\n",
        "1) `predict_texts`: loads a fine-tuned checkpoint, tokenizes a list of texts in **batches**, runs the model on GPU if available (else CPU), and returns both **predicted class IDs** and **class probabilities**.  \n",
        "2) `score_csv`: reads a CSV (default text column `review`), scores all rows via `predict_texts`, and writes an **augmented CSV** with predicted label and per-class probabilities (neg/neu/pos).\n",
        "\n",
        "#### Input\n",
        "- For `predict_texts`:\n",
        "  - `texts` (List[str]): raw texts to classify.\n",
        "  - `ckpt_dir` (str): path to a saved HF checkpoint (tokenizer + model).\n",
        "  - `batch_size` (int, default 32): batch size for fast inference.\n",
        "- For `score_csv`:\n",
        "  - `input_csv` (str): path to an input CSV containing a text column.\n",
        "  - `text_col` (str, default `'review'`): name of the text column.\n",
        "  - `ckpt_dir` (str | None): checkpoint directory; if `None`, falls back to `BEST_CKPT_DIR` or a name derived from `MODEL_NAME`.\n",
        "  - `out_csv` (str, default `'scored.csv'`): output CSV path.\n",
        "\n",
        "#### Output\n",
        "- `predict_texts` → `(preds: np.ndarray, probs: np.ndarray)` where `preds` is shape `(N,)` and `probs` is shape `(N, 3)` for classes `[neg, neu, pos]`.\n",
        "- `score_csv` → returns the output CSV path and writes an augmented CSV with columns: `pred`, `prob_neg`, `prob_neu`, `prob_pos`.\n",
        "\n",
        "---\n",
        "\n",
        "#### Line-by-Line Explanation (important lines)\n",
        "\n",
        "`def predict_texts(texts: List[str], ckpt_dir: str, batch_size: int = 32) -> Tuple[np.ndarray, np.ndarray]:`  \n",
        "Defines a batched inference function that outputs predicted class IDs and probabilities.\n",
        "\n",
        "`device_local = torch.device('cuda' if torch.cuda.is_available() else 'cpu')`  \n",
        "Chooses GPU when available; otherwise falls back to CPU.\n",
        "\n",
        "`tok = AutoTokenizer.from_pretrained(ckpt_dir, use_fast=True)`  \n",
        "Loads the tokenizer from the **same checkpoint** to ensure consistent preprocessing.\n",
        "\n",
        "`mdl = AutoModelForSequenceClassification.from_pretrained(ckpt_dir).to(device_local).eval()`  \n",
        "Loads the classifier weights, moves the model to the selected device, and sets **eval** mode.\n",
        "\n",
        "`preds_all, probs_all = [], []`  \n",
        "Prepare accumulators for concatenating batch outputs.\n",
        "\n",
        "`with torch.no_grad():`  \n",
        "Disables autograd for faster, memory-efficient inference.\n",
        "\n",
        "`for i in range(0, len(texts), batch_size):`  \n",
        "Iterates over texts in contiguous **batches** to avoid memory spikes.\n",
        "\n",
        "`batch = texts[i:i+batch_size]`  \n",
        "Slices the current batch.\n",
        "\n",
        "`enc = tok(batch, padding=True, truncation=True, max_length=256, return_tensors='pt').to(device_local)`  \n",
        "Tokenizes the batch with padding/truncation (here `max_length=256`) and moves tensors to device.\n",
        "\n",
        "`out = mdl(**enc)`  \n",
        "Runs a forward pass to get logits.\n",
        "\n",
        "`logits = out.logits.detach().cpu().numpy()`  \n",
        "Detaches logits, moves to CPU, converts to NumPy for downstream ops.\n",
        "\n",
        "`probs = torch.softmax(out.logits, dim=-1).detach().cpu().numpy()`  \n",
        "Converts logits to **probabilities** via softmax, then to NumPy.\n",
        "\n",
        "`preds = logits.argmax(axis=1)`  \n",
        "Takes argmax over classes to get predicted IDs.\n",
        "\n",
        "`preds_all.append(preds); probs_all.append(probs)`  \n",
        "Stores batch predictions and probabilities.\n",
        "\n",
        "`return np.concatenate(preds_all), np.concatenate(probs_all)`  \n",
        "Concatenates batched outputs into full arrays and returns them.\n",
        "\n",
        "---\n",
        "\n",
        "`def score_csv(input_csv: str, text_col: str = 'review', ckpt_dir: str | None = None, out_csv: str = 'scored.csv') -> str:`  \n",
        "Defines a convenience wrapper that scores an entire CSV and writes results to disk.\n",
        "\n",
        "`if ckpt_dir is None: ckpt_dir = BEST_CKPT_DIR ... else f\"./finetuned_{MODEL_NAME.replace('/','_')}_best\"`  \n",
        "Selects a **default checkpoint** if none was provided, preferring `BEST_CKPT_DIR`.\n",
        "\n",
        "`df_in = pd.read_csv(input_csv)`  \n",
        "Loads the input table.\n",
        "\n",
        "`assert text_col in df_in.columns, f\"Missing column {text_col} in {input_csv}\"`  \n",
        "Validates that the chosen text column exists.\n",
        "\n",
        "`preds, probs = predict_texts(df_in[text_col].astype(str).tolist(), ckpt_dir)`  \n",
        "Runs batched inference using the helper above.\n",
        "\n",
        "`out = df_in.copy(); out['pred'] = preds`  \n",
        "Copies original rows and appends the predicted class ID column.\n",
        "\n",
        "`out['prob_neg'] = probs[:,0]; out['prob_neu'] = probs[:,1]; out['prob_pos'] = probs[:,2]`  \n",
        "Adds class probabilities per row in a consistent column order.\n",
        "\n",
        "`out.to_csv(out_csv, index=False)`  \n",
        "Writes the augmented table to the requested output path.\n",
        "\n",
        "`print('Wrote', out_csv); return out_csv`  \n",
        "Logs completion and returns the output path for chaining."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCrsw8R0sIuR"
      },
      "outputs": [],
      "source": [
        "from typing import List, Tuple\n",
        "import torch, numpy as np, pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "\n",
        "def predict_texts(texts: List[str], ckpt_dir: str, batch_size: int = 32) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    device_local = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    tok = AutoTokenizer.from_pretrained(ckpt_dir, use_fast=True)\n",
        "    mdl = AutoModelForSequenceClassification.from_pretrained(ckpt_dir).to(device_local).eval()\n",
        "    preds_all, probs_all = [], []\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, len(texts), batch_size):\n",
        "            batch = texts[i:i+batch_size]\n",
        "            enc = tok(batch, padding=True, truncation=True, max_length=256, return_tensors='pt').to(device_local)\n",
        "            out = mdl(**enc)\n",
        "            logits = out.logits.detach().cpu().numpy()\n",
        "            probs = torch.softmax(out.logits, dim=-1).detach().cpu().numpy()\n",
        "            preds = logits.argmax(axis=1)\n",
        "            preds_all.append(preds)\n",
        "            probs_all.append(probs)\n",
        "    return np.concatenate(preds_all), np.concatenate(probs_all)\n",
        "\n",
        "\n",
        "def score_csv(input_csv: str, text_col: str = 'review', ckpt_dir: str | None = None, out_csv: str = 'scored.csv') -> str:\n",
        "    if ckpt_dir is None:\n",
        "        ckpt_dir = BEST_CKPT_DIR if 'BEST_CKPT_DIR' in globals() and BEST_CKPT_DIR else f\"./finetuned_{MODEL_NAME.replace('/','_')}_best\"\n",
        "    df_in = pd.read_csv(input_csv)\n",
        "    assert text_col in df_in.columns, f\"Missing column {text_col} in {input_csv}\"\n",
        "    preds, probs = predict_texts(df_in[text_col].astype(str).tolist(), ckpt_dir)\n",
        "    out = df_in.copy()\n",
        "    out['pred'] = preds\n",
        "    out['prob_neg'] = probs[:,0]\n",
        "    out['prob_neu'] = probs[:,1]\n",
        "    out['prob_pos'] = probs[:,2]\n",
        "    out.to_csv(out_csv, index=False)\n",
        "    print('Wrote', out_csv)\n",
        "    return out_csv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aFku-HosIuR"
      },
      "source": [
        "# Reporting: test confusion matrices and comparison table\n",
        "\n",
        "Generates confusion matrices for the baseline and transformer best models on the test split, and writes a compact comparison CSV.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-JMMuBWCsIuR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "4a566e05-6bad-462f-96fb-346f03567716"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "              model  accuracy  f1_macro\n",
              "0     baseline_best  0.893733  0.894481\n",
              "1  transformer_best  0.829700  0.831221"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-694fd4ce-157f-4d8f-802a-bdb683f6256f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1_macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>baseline_best</td>\n",
              "      <td>0.893733</td>\n",
              "      <td>0.894481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>transformer_best</td>\n",
              "      <td>0.829700</td>\n",
              "      <td>0.831221</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-694fd4ce-157f-4d8f-802a-bdb683f6256f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-694fd4ce-157f-4d8f-802a-bdb683f6256f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-694fd4ce-157f-4d8f-802a-bdb683f6256f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-68d052ff-9f5e-49c4-b952-c406bc88e323\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-68d052ff-9f5e-49c4-b952-c406bc88e323')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-68d052ff-9f5e-49c4-b952-c406bc88e323 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_53aa7916-8a2f-4e76-b801-b1e5c1a85d27\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('cmp')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_53aa7916-8a2f-4e76-b801-b1e5c1a85d27 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('cmp');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "cmp",
              "summary": "{\n  \"name\": \"cmp\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"transformer_best\",\n          \"baseline_best\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04527795465363452,\n        \"min\": 0.829700272479564,\n        \"max\": 0.8937329700272479,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.829700272479564,\n          0.8937329700272479\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_macro\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04473162724624545,\n        \"min\": 0.8312209425699789,\n        \"max\": 0.8944810164886371,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.8312209425699789,\n          0.8944810164886371\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os, pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, f1_score, classification_report\n",
        "from pathlib import Path\n",
        "\n",
        "outdir = Path('exports'); outdir.mkdir(exist_ok=True)\n",
        "\n",
        "rows = []\n",
        "# Baseline\n",
        "if os.path.exists('baseline_predictions_test.csv'):\n",
        "    dfb = pd.read_csv('baseline_predictions_test.csv')\n",
        "    y_true = dfb['gold'].values; y_pred = dfb['pred'].values\n",
        "    acc = accuracy_score(y_true, y_pred); f1m = f1_score(y_true, y_pred, average='macro')\n",
        "    rows.append({'model':'baseline_best', 'accuracy':acc, 'f1_macro':f1m})\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[0,1,2])\n",
        "    ConfusionMatrixDisplay(cm, display_labels=['neg','neu','pos']).plot(colorbar=False)\n",
        "    plt.title('Baseline (test)'); plt.tight_layout(); plt.savefig(outdir/'CM_baseline_test.png', dpi=150); plt.close()\n",
        "\n",
        "# Transformer\n",
        "if os.path.exists('transformer_predictions_test.csv'):\n",
        "    dft = pd.read_csv('transformer_predictions_test.csv')\n",
        "    y_true = dft['gold'].values; y_pred = dft['pred'].values\n",
        "    acc = accuracy_score(y_true, y_pred); f1m = f1_score(y_true, y_pred, average='macro')\n",
        "    rows.append({'model':'transformer_best', 'accuracy':acc, 'f1_macro':f1m})\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[0,1,2])\n",
        "    ConfusionMatrixDisplay(cm, display_labels=['neg','neu','pos']).plot(colorbar=False)\n",
        "    plt.title('Transformer (test)'); plt.tight_layout(); plt.savefig(outdir/'CM_transformer_test.png', dpi=150); plt.close()\n",
        "\n",
        "if rows:\n",
        "    cmp = pd.DataFrame(rows).sort_values('f1_macro', ascending=False)\n",
        "    cmp.to_csv(outdir/'Sentiment_Comparison.csv', index=False)\n",
        "    try: cmp.to_excel(outdir/'Sentiment_Comparison.xlsx', index=False)\n",
        "    except Exception: pass\n",
        "    display(cmp)\n",
        "else:\n",
        "    print('No predictions found yet. Run cells above first.')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "20b5c30221f84a4bbf8c0c914fee2283": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2e001fc5349440dc844303ec392175fd",
              "IPY_MODEL_562c2754b7c64e4fbc5810137f6ce5a1",
              "IPY_MODEL_bf71cc71efd44cfaa4039057bd506436"
            ],
            "layout": "IPY_MODEL_492e6a72aaca481b99cc1fc4e6bbd496"
          }
        },
        "2e001fc5349440dc844303ec392175fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5df0a14fbdbb40ddb70c0c8fce84bc03",
            "placeholder": "​",
            "style": "IPY_MODEL_2a6f98064fbb4e37ae0d723a7a4015f9",
            "value": "Map (num_proc=4): 100%"
          }
        },
        "562c2754b7c64e4fbc5810137f6ce5a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7076da07ea04da68ec4b3ca379af6a6",
            "max": 4696,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_769aad0925a747cb9ac2a1737ac58829",
            "value": 4696
          }
        },
        "bf71cc71efd44cfaa4039057bd506436": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9117c674c6c4e9091b837788e5be018",
            "placeholder": "​",
            "style": "IPY_MODEL_24b11bc396864aa5952c547fd80d70a4",
            "value": " 4696/4696 [00:01&lt;00:00, 1256.37 examples/s]"
          }
        },
        "492e6a72aaca481b99cc1fc4e6bbd496": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5df0a14fbdbb40ddb70c0c8fce84bc03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a6f98064fbb4e37ae0d723a7a4015f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7076da07ea04da68ec4b3ca379af6a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "769aad0925a747cb9ac2a1737ac58829": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e9117c674c6c4e9091b837788e5be018": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24b11bc396864aa5952c547fd80d70a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a210378d435541dca3e4173c9c8a3efc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e3328a29eb8f4ddea44a87b2ddc1494e",
              "IPY_MODEL_261cee5ccfcb40a1a9252a7243097b59",
              "IPY_MODEL_c0466f5eb80f46c1aeff55b449a865ad"
            ],
            "layout": "IPY_MODEL_f97706c753f3464790437ff7e68b99ba"
          }
        },
        "e3328a29eb8f4ddea44a87b2ddc1494e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07cc40e0c23d461f8d7658adde481a81",
            "placeholder": "​",
            "style": "IPY_MODEL_b056ef7c60c5490ebf467a5f560f3738",
            "value": "Map (num_proc=4): 100%"
          }
        },
        "261cee5ccfcb40a1a9252a7243097b59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3d7f39435a54a8f8a7718cf3f10d025",
            "max": 1468,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1c87ad0e0f55437f820d820704cc0773",
            "value": 1468
          }
        },
        "c0466f5eb80f46c1aeff55b449a865ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_618e08f754d94c04bf272bcafebb2dd7",
            "placeholder": "​",
            "style": "IPY_MODEL_cff2fc26f9cb480894eb6be0a05771ff",
            "value": " 1468/1468 [00:00&lt;00:00, 641.07 examples/s]"
          }
        },
        "f97706c753f3464790437ff7e68b99ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07cc40e0c23d461f8d7658adde481a81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b056ef7c60c5490ebf467a5f560f3738": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3d7f39435a54a8f8a7718cf3f10d025": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c87ad0e0f55437f820d820704cc0773": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "618e08f754d94c04bf272bcafebb2dd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cff2fc26f9cb480894eb6be0a05771ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99f62c615857417793a550e696fae6ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5936f3860586494baa89b52962085a34",
              "IPY_MODEL_641d96b7ee584ccc97d656652b429a4c",
              "IPY_MODEL_5e7acb56c9d748f28d588227878275da"
            ],
            "layout": "IPY_MODEL_73538588f75848a2b692663ce13f44ba"
          }
        },
        "5936f3860586494baa89b52962085a34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c7e968dfc3d48ba9b89af0b6bac12da",
            "placeholder": "​",
            "style": "IPY_MODEL_314b1a0af12c42929adaa6490ffd75eb",
            "value": "Map (num_proc=4): 100%"
          }
        },
        "641d96b7ee584ccc97d656652b429a4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81e86aba46b24884a62ef5cc8102ec49",
            "max": 734,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d55a8cdd68d74d1d931ea1ea5cdc4bbb",
            "value": 734
          }
        },
        "5e7acb56c9d748f28d588227878275da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ccc86693fee4384935a1ba90b378324",
            "placeholder": "​",
            "style": "IPY_MODEL_7ed0a02257094d709170b0a4cdecbfc3",
            "value": " 734/734 [00:00&lt;00:00, 362.25 examples/s]"
          }
        },
        "73538588f75848a2b692663ce13f44ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c7e968dfc3d48ba9b89af0b6bac12da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "314b1a0af12c42929adaa6490ffd75eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81e86aba46b24884a62ef5cc8102ec49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d55a8cdd68d74d1d931ea1ea5cdc4bbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1ccc86693fee4384935a1ba90b378324": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ed0a02257094d709170b0a4cdecbfc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a15431c968864e28a8e6d69de9397aaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aa0c6fd0bcd94ec3987c046b68545bbe",
              "IPY_MODEL_119c9ce3c7974d5ba3c9d4fd23d83fe9",
              "IPY_MODEL_0e39405f5f324e51b8c03dcefe625252"
            ],
            "layout": "IPY_MODEL_4508796ec4e249439075a8c1b4972edb"
          }
        },
        "aa0c6fd0bcd94ec3987c046b68545bbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b832411160da43dd8135b896b5905041",
            "placeholder": "​",
            "style": "IPY_MODEL_4be8e85d0d34413f8f0c2550c00fdcb8",
            "value": "Map (num_proc=4): 100%"
          }
        },
        "119c9ce3c7974d5ba3c9d4fd23d83fe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e6e5937dea84c679998d4564c1291fa",
            "max": 4696,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_94439c1fb342430cbb296679fbc4ff7e",
            "value": 4696
          }
        },
        "0e39405f5f324e51b8c03dcefe625252": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22d2c0996cbd428f8ccafd219ae210e4",
            "placeholder": "​",
            "style": "IPY_MODEL_7ca13a7a56bc493c8411edfcbec97a92",
            "value": " 4696/4696 [00:02&lt;00:00, 3318.56 examples/s]"
          }
        },
        "4508796ec4e249439075a8c1b4972edb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b832411160da43dd8135b896b5905041": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4be8e85d0d34413f8f0c2550c00fdcb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e6e5937dea84c679998d4564c1291fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94439c1fb342430cbb296679fbc4ff7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "22d2c0996cbd428f8ccafd219ae210e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ca13a7a56bc493c8411edfcbec97a92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8f9c17ce3a7404292db9dd9708e18be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b2dd5aa4eb2040549d12b474459f1ec6",
              "IPY_MODEL_8e33b631650d4b91a6cfaad66397953e",
              "IPY_MODEL_9fb2190cdf114a82b1200b2c366fa20d"
            ],
            "layout": "IPY_MODEL_198715ec77124898af040e07b45ffc5f"
          }
        },
        "b2dd5aa4eb2040549d12b474459f1ec6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52101ba7828b48bfa6e6c1bdebd26f75",
            "placeholder": "​",
            "style": "IPY_MODEL_a98c2bc972694aa4adfebea75da93bfa",
            "value": "Map (num_proc=4): 100%"
          }
        },
        "8e33b631650d4b91a6cfaad66397953e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c35e5f98fc5e438f92e8fd7296e01507",
            "max": 1468,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d6808d1557924171aab8b45891ae36c3",
            "value": 1468
          }
        },
        "9fb2190cdf114a82b1200b2c366fa20d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85c4854de736406bacfd279963b446a6",
            "placeholder": "​",
            "style": "IPY_MODEL_68442ec82e534d2da782c93d77820910",
            "value": " 1468/1468 [00:02&lt;00:00, 733.95 examples/s]"
          }
        },
        "198715ec77124898af040e07b45ffc5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52101ba7828b48bfa6e6c1bdebd26f75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a98c2bc972694aa4adfebea75da93bfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c35e5f98fc5e438f92e8fd7296e01507": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6808d1557924171aab8b45891ae36c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "85c4854de736406bacfd279963b446a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68442ec82e534d2da782c93d77820910": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c9d61d2ffb644e1bdce42232a27bd98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4f857d6871564d399ef5762286e7f939",
              "IPY_MODEL_226b51d2ec204da686eb32305a1d1c0d",
              "IPY_MODEL_26f2cdf8d3294e80b3ecf6d45eee744b"
            ],
            "layout": "IPY_MODEL_92c0fdfe5ac64518a97951fb9a437cd1"
          }
        },
        "4f857d6871564d399ef5762286e7f939": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1c73421f731444ba4985812f267ba13",
            "placeholder": "​",
            "style": "IPY_MODEL_5d6ed8c9e09649888f5945a6616bfeb0",
            "value": "Map (num_proc=4): 100%"
          }
        },
        "226b51d2ec204da686eb32305a1d1c0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64948bcf48444705aec82d4e0dab42a0",
            "max": 734,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9871e6c501ea45e9a722337a91a903c4",
            "value": 734
          }
        },
        "26f2cdf8d3294e80b3ecf6d45eee744b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec1f414ea5a04d14a5bb2cf383be5b72",
            "placeholder": "​",
            "style": "IPY_MODEL_120f98d2493848d08c09527f8ece7759",
            "value": " 734/734 [00:02&lt;00:00, 381.02 examples/s]"
          }
        },
        "92c0fdfe5ac64518a97951fb9a437cd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1c73421f731444ba4985812f267ba13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d6ed8c9e09649888f5945a6616bfeb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64948bcf48444705aec82d4e0dab42a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9871e6c501ea45e9a722337a91a903c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ec1f414ea5a04d14a5bb2cf383be5b72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "120f98d2493848d08c09527f8ece7759": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30729f411428431aab4032fa39e2eae6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7b358b0bae9549a58c4e2a3f7cf3326a",
              "IPY_MODEL_4c3413ff1ca1494787ff99a2bcdbb353",
              "IPY_MODEL_46bc2420ff9a4db4bda2ff97149f36bc"
            ],
            "layout": "IPY_MODEL_76cd3343ebf546c3ac8c7d6a78b2a293"
          }
        },
        "7b358b0bae9549a58c4e2a3f7cf3326a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6a3d5fcab52486899c259bcef2843f2",
            "placeholder": "​",
            "style": "IPY_MODEL_a4b9c22255f447b093f19147b55565e0",
            "value": "Map (num_proc=4): 100%"
          }
        },
        "4c3413ff1ca1494787ff99a2bcdbb353": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32c39b0a41a744a8a88c3dd1fac02a53",
            "max": 4696,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_017f7a94511b4012a6ef8bfe69566ed1",
            "value": 4696
          }
        },
        "46bc2420ff9a4db4bda2ff97149f36bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9dbcce9ccb1f46459e2b6c9b82b6d728",
            "placeholder": "​",
            "style": "IPY_MODEL_2493f443b3254761badb078ac2607753",
            "value": " 4696/4696 [00:02&lt;00:00, 3109.67 examples/s]"
          }
        },
        "76cd3343ebf546c3ac8c7d6a78b2a293": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6a3d5fcab52486899c259bcef2843f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4b9c22255f447b093f19147b55565e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32c39b0a41a744a8a88c3dd1fac02a53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "017f7a94511b4012a6ef8bfe69566ed1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9dbcce9ccb1f46459e2b6c9b82b6d728": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2493f443b3254761badb078ac2607753": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "677bdae148c8402ba058a7bf5df2474e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8bd50bbef6814db18e61e48e718cc441",
              "IPY_MODEL_cdac9a9ea44b48e9abe01e2a1eb080e7",
              "IPY_MODEL_90ae5055353c47328bb80335101e97fc"
            ],
            "layout": "IPY_MODEL_6c3031517cc44ac8b92ef17bc976cbee"
          }
        },
        "8bd50bbef6814db18e61e48e718cc441": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3b2678238064284890a29f15a3e07ca",
            "placeholder": "​",
            "style": "IPY_MODEL_dced8a41879046f2bcd1f0dbe7c2458e",
            "value": "Map (num_proc=4): 100%"
          }
        },
        "cdac9a9ea44b48e9abe01e2a1eb080e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2dbc7e7815c147c097c27495389b229d",
            "max": 1468,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a68c4dc57d2946688bdca1ff633ffaae",
            "value": 1468
          }
        },
        "90ae5055353c47328bb80335101e97fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d07ea582a1d04205bef8c62b6c2445a6",
            "placeholder": "​",
            "style": "IPY_MODEL_b0e40bf1270b419cb936f3e5910f6b93",
            "value": " 1468/1468 [00:02&lt;00:00, 754.55 examples/s]"
          }
        },
        "6c3031517cc44ac8b92ef17bc976cbee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3b2678238064284890a29f15a3e07ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dced8a41879046f2bcd1f0dbe7c2458e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2dbc7e7815c147c097c27495389b229d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a68c4dc57d2946688bdca1ff633ffaae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d07ea582a1d04205bef8c62b6c2445a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0e40bf1270b419cb936f3e5910f6b93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c265f1f5b53043a1a4b7901178c85bc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4d07bf61728947189751f235877b9999",
              "IPY_MODEL_3c8bd4c95feb4fc29d67471c08552f43",
              "IPY_MODEL_ac1987a917984b698dc4004eac69e631"
            ],
            "layout": "IPY_MODEL_b530b15b20cc43b48174d74e6baf2bd8"
          }
        },
        "4d07bf61728947189751f235877b9999": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_667c623bdb994ea79830d566d538d845",
            "placeholder": "​",
            "style": "IPY_MODEL_a7e3400a50ab48a8aef615e929957c85",
            "value": "Map (num_proc=4): 100%"
          }
        },
        "3c8bd4c95feb4fc29d67471c08552f43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbd2b87e1fa14de5bb923480608b6cad",
            "max": 734,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_756eb37ffd024c9982facb402d557ef3",
            "value": 734
          }
        },
        "ac1987a917984b698dc4004eac69e631": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc08dfc5cb104a619c6453d98cebe7c6",
            "placeholder": "​",
            "style": "IPY_MODEL_4f7f53034bd84a8bbd2e7a3fe708048b",
            "value": " 734/734 [00:02&lt;00:00, 393.10 examples/s]"
          }
        },
        "b530b15b20cc43b48174d74e6baf2bd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "667c623bdb994ea79830d566d538d845": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7e3400a50ab48a8aef615e929957c85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dbd2b87e1fa14de5bb923480608b6cad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "756eb37ffd024c9982facb402d557ef3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bc08dfc5cb104a619c6453d98cebe7c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f7f53034bd84a8bbd2e7a3fe708048b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}