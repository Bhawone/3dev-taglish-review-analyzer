Taglish Product Review Understanding with Multilingual Transformers: Sentiment, Aspect, and Deception Analysis for Philippine E-Commerce
Bharon Christopher P. Candelaria
Computer Studies and Engineering
Jose Rizal University
Mandaluyong City, Philippines
bharonchristopher.candelaria@my.jru.edu

   Abstract- This is because this paper introduces a Taglig conscious system of interpreting product reviews under Philippine e-commerce. Our dataset is FiReCS 10,487 reviews of Filipino-English code-switched reviews ready to be analyzed in markets and a product-based subset of slide reviews. The strategy is a combination of three tasks within one workflow. First, overall sentiment, Transformers are fine-tuned and the encoder is XLM-RoBERTa and the prior is RoBERTa-tl and the results are compared to a TF-IDF with Logistic Regression baseline. Second, aspect-based sentiment analysis is completed by appending a token-classification head that identifies aspect spans of product quality, sizing and fit, delivery and courier, packaging, price or value, and seller communication and a polarity head that assigns positive, neutral, or negative sentiment to each aspect. Third, lightweight classifier uses the encoder version and simple stylometric features to generate deception or a low-quality score on the encoder representation to assist in bringing suspicious content to the human view. Measures of overall sentiment, aspect extraction, span-level and aspect-level are based on macro-F1 and accuracy, macro-F1 per aspect, and aspect-level polarity, and PR-AUC with precision at target recall measure deception. Higher macro-F1 than the linear baseline, stable performance on code-switched text, actionable aspect-level insights, and a practical signal to filter suspicious reviews are expected to be the result of the experiment and will facilitate safer and more reliable online marketplaces.
   Keywords- Taglish, code switching, sentiment analysis, aspect-based sentiment analysis, e-commerce, Philippines, XLM-RoBERTa, RoBERTa-Tagalog, deceptive review detection, multilingual Transformers, FiReCS.
I. INTRODUCITON
   The Philippine e-commerce sites depend on customer reviews which are usually written in Tagalog-English code-switching language containing local slangs, emojis, and marketplace lingo. Misreading These reviews are often misread by tools which are largely trained on monolingual English and fail to provide useful concerns which buyers and sellers are often interested in e.g. delivery speed, quality of packaging, size and fit, price to value and communication with the seller. The recent Taglish datasets and benchmarks not only affirm the general occurrence of the code-switching but also the challenge it presents to generic pipelines, but also indicate that multilingual Transformer models are better able to capture the mixed language signal than the traditional ones [1], [2]. Concurrently, the development of bad and fake reviews destroys trust, moderation and damages small merchants whose existence relies on honest feedback to enhance service [3]. 
   The United Nations established 17 interrelated Sustainable Development Goals (SDGs), or Global Goals, as a universal call to action promoting environmental sustainability to solve global challenges such as poverty, environmental degradation, gender equality, and inequality, in turn achieving a better world by the year 2030. 

Figure 1. Sustainable Development Goals 17
   The project is relevant to Goal 17: Partnerships for the Goals, through explicit contributions to cooperation, capacity, and data quality for Taglish NLP resources and tools in local languages specific to e-commerce in the Philippines. The primary synergy with Target 17.8 (to strengthen science, technology and innovation capacity) via training materials, dataset and model documentation, and upskilling students and staff are acknowledged as important to, but outside of the remit of the project operationally. [4]-[6]. This study correlates to SDG 17 (Target 17.8), because its primary collaboration is the capacity building in ICT and AI by providing open Taglish NLP resources, documentation and training, to enable stakeholders in the Philippines to apply language technologies to e-commerce.
   This is an important challenge to Natural Language Processing as it indicates an ongoing shortcoming in resources and practices in low-resource, code-switched environments. Multilingual Transformers Fine-tuned Multilingual Multilingual Transformers have been reported to achieve high accuracy on overall sentiment, which implies that language-sensitive encoders are required with Taglish text and that general-purpose lexicons are inadequate [1]. Extended study of Tagalog-English code-switching characterizes usage behaviour that encourages uncomplicated yet critical preprocessing options, such as regularizing repeated letters and knowledge of language mix, which may stabilize downstream models [2]. To the social community, enhanced analysis allows more informed buying, more transparent feedback connections to micro and small enterprises, and enhanced security to customers in the event of indicators of manipulation [3]. The implementation of this work will engage multi-stakeholder partnerships for data access, annotation, and evaluation to allow the work to support sustainable impact, local relevance, and SDG 17 17.8, 

Figure 2. Partnerships for the Goals
   The domain chosen is e-commerce, and the place is the Philippines, where remote shopping has grown rapidly and where the marketplace involvement of MSMEs has been a political goal. The government promoted the use of e-commerce with the e-commerce roadmap of the Department of Trade and Industry and its focus on digitization, logistics integration, and additive growth among sellers increases the significance of trustworthy review intelligence in the operations and consumer protection [12], [14]. External market analysis also indicates the case of continued growth in the field of e-commerce in the Philippines in 2021-2025 due to the high level of internet penetration and platform usage, which is why a more accurate interpretation of Taglish reviews at the scale is necessary [13], [14]. Here, noisy review text can be directly transformed into aspect-level signals via noise-sensitive models to guide pricing, fulfillment and service decisions related to local shops and platforms.
   Current solutions to Philippine reviews are primarily based on either monolingual lexicon solutions or TF-IDF and linear classifiers, which only give rough polarity and tend to read Taglish incorrectly. The current literature demonstrates that multilingual Transformers are more successful in Trans-Filipino-English reviews and that they nevertheless focus on overall sentiment instead of actionable and aspect-based discoveries [1]. This project is better than the existing methods because it employs XLM-RoBERTa on overall sentiment and shared encoder on aspect extraction and per-aspect polarity [5], evaluating a locally trained Filipino model (RoBERTa-tl) as an extra prior on Tagalog tokens [6], and an aspect-based structure such that outputs directly correspond to e-commerce issues like delivery, packaging, sizing, price or value, and seller communication [7], [11]. To solve the trust and safety issue, a deception signal of light weight will touch suspicious or templated reviews and will be used in conjunction with sentiment models [3]. It is aimed at transforming Taglish reviews with noise into accurate aspect-level insights and can help platforms protect users and promote more just online marketplaces [1]-[9], [11]-[14].
   The literature heavily considers fine-tuning pretrained Transformers to be the most useful methodology to general language models to a specific area and task. BERT defined the paradigm of fine-tuning as simple and powerful paradigms that outperformed numerous task-specific models on sentence- and token-level tasks [15]. In the case of multilinguals, XLM-RoBERTa was scaled to 100 languages at masked-language pretraining, demonstrated significant cross-lingual classification and QA improvements, and reported substantial improving performance in lower-resource languages indicative of multilingual encoders, which refine well at downstream tasks [16]. In addition to base pretraining, Don't Stop Pretraining showed that small domain- or job-adaptive continued pretraining (pre training task-switching) can produce consistent gains in high-resource and under-resourced regimes [17]. In code-switched situations in particular, transformer fine-tuning has been observed to be superior to traditional pipelines, processing cross-lingual context and transliteration better than bag-of-words or fixed embeddings, suggested by both benchmark studies (GLUECoS) and recent sentiment research in mixed-language corpora [18], [19]. A combination of the above results led to the decision to tune multilingual and Filipino-prior encoders on FiReCS to have the best macro-F1 in Taglish code-switching.
II. PROBLEM STATEMENT
   Philippine e-commerce platform reviews are conducted in Tagalog and English featuring high amounts of code-switching, slang, and emojis. Tools trained on monolingual English often misconstrue what is a mixed-language text and revert back only coarse polarity that doesn't surface the actual retail matters of delivery speed, packaging quality, sizing and fit, price to value, and seller communication. Recent work on Filipino-English reviews indicates that multilingual Transformers outperform traditional methods for overall sentiment [1], [2]. However, existing approaches still look only for a single label and do not provide actionable guidance for business operations. Simultaneously, platforms have increasing exposure to deceptive and low-quality reviews that erode trust, which sentiment classifiers do not address [3]. The project will find results in addressing previously noted gaps by building and measuring an additional Taglish-aware system using multilingual Transformer models to provide accurate overall sentiment and aspect-based sentiment for key facets of e-commerce, and an extra lightweight deception signal to bring suspicious content to the forefront of moderation and decision making [1],[2],[3],[7].
III. RESEARCH OBJECTIVES

    Specific - Develop and evaluate multilingual Transformer models for Taglish product reviews with XLM-RoBERTa, overall sentiment, replicate encoder with aspect extraction and per-aspect sentiment for relevant e-commerce nuances (not the packaging but the product quality, fit and size, delivery and courier), and lightweight classifier for likely deceptive, or low-quality, reviews. Produce a small API and a simple dashboard to show per-aspect summary and queue reviews that are suspect.
    Measurable - On FiReCS product filtered test subset, achieve macro-F1 for overall sentiment. For aspect extraction, achieve span-level F1 and for per aspect sentiment F1 macro on defined aspects. For decision signals, target for PR-AUC nd recalled when classified. Report accuracy, precision, recall and F1 for all the tasks in comparison with a baseline TF-IDF plus Logistic Regression.
    Achievable - Use the given FiReCS train/test files with the product-only subspace with about 7900 reviews, annotate about 1200 to 1800 aspect spans and per-aspect sentiment, and annotate about a smaller amount for deception likelihood. Utilize open models and tooling that are available to students, for instance (but not limited to) XLM-RoBERTa, and use it on Google Colab or GPUs You can re-use some of the cleaning and split scripts that you have prepared in the past from the dataset load..
    Relevant - Accurate and interpretable analysis of Taglish reviews can lead to better purchase decisions, enable micro and small sellers to address concrete problems related to fulfillment and service, can be done for the NLP community related to code-switched and low-resource scenario and the key output of Taglish-aware models and Taglish-aware model evaluation.
    Time bound - The study will be carried out within 5 weeks, within which the different milestones for data collection, model development, evaluation, and reporting would be achieved.
    
IV. SCOPE OF WORK
A. Overview
    The project will read the already prepared product-filtered subset for Philippine e-commerce from the FiReCS train and test files and apply the project system on it. It will conclude an aspect schema for retail process (product quality, size and fit, delivery and courier, packaging, price or value, seller communication), generate an annotation template, and annotate a subset for aspect spans, aspect sentiment, and degree of deception. It will establish baselines of general sentiment and then fine-tune multilingual Transformer models and test against the baselines. System results will be shared via a simple API and a lightweight dashboard that gives an overview of the per aspect signals and lists of suspicious reviews, followed by documentation of methods, ethics, dataset-card and model-card.
B. Key Activities
    Data collection will focus on FiReCS and the product-filtered slice and a limited number of newly labeled aspects and deception data (enrichment may include some samples of the PH marketplace products), appropriately stripped of PII. Slight token cleaning, emoji management and repeat text normalization will be preprocessed as well as simple markers for mixed language analysis. Model selection will be based on TF-IDF as a baseline sentiment model, then xlm-r Roberta for overall sentiment & as a shared encoder for aspect extraction and per-aspect polarity (RoBERTa-tl will be used for an ablation). Training methods will include stratified splits, hyperparameter tuning and early stopping, aspect extraction will be token classification, and per aspect polarity will be a classification head. Evaluation will include accuracy, precision, recall, macro-F1 for sentiment level, per-aspect sentiment, span-level F1 for aspect extraction, PR-AUC for deception and ablation studies on preprocessing and model variants. Outputs to be deployed will be serialized checkpoints, an inference script and REST endpoint, and a simple dashboard for qualitative review and error analysis.
V. METHODOLOGY
A. Data Collection & Sources
    
    This study utilizes the FiReCS (https://huggingface.co/datasets/ccosme/FiReCS) is a Filipino-English code-switched review dataset consisting of 10,487 instances labeled into 3 sentiment classes (positive, neutral, and negative) taken from publicly available product and service reviews and was created from datasets, which consisted of review texts from e-commerce platforms (Shopee Philippines) and Google Maps Reviews respectively. dataset card dataset card. and human annotation checkers (native Filipino speakers) Review Source: Shopee Philippines Google Maps Reviews These characteristics make FiReCS directly relevant to the Philippines e-commerce as well as Taglish text, and the license is clear and documented labeling protocol supports reproducible research. The dataset card also displays these exact fields (review, label) and label encoding that were used in our experiments. [20].
    
B. Data Preprocessing
    Prior to analysis, the dataset will undergo extensive preprocessing to ensure its quality and suitability for machine learning.
    
1. Data Cleaning
- Eliminating Irrelevant Fields - Retain only the fields that are useful for modeling (e.g., review, label, source tags). Eliminate helper fields or empty columns to decrease noise and prepare for processing.
- Addressing Missing Values - Identify empty or null text rows and eliminate those. Eliminate any records without a defined label as they will only produce errors during training.
- Removing Duplicates - Determine if the dataset have exact duplicate reviews, or very near duplicates, so that repeated text does not bias the model.
- Normalizing Text Artifacts - Remove HTML tags, extraneous control characters, or extra white space that do not supplement the review with meaning.

2. Text Normalization
- Length Control: Reduce repeated letters while maintaining emphasis (for example "soobraaa" becomes "soobraa").
- Emojis and Emoticons: Treat emojis as tokens since they encapsulate sentiment. Replace infrequent emoticons with token stable but predictable variable.
- Lower and Upper Case Punctuation: Retain case and simple punctuation, as subword tokenizers in Transformer models can learn these patterns.
- Code-Switch Indicator: Provide each review with a simple indicator (the ratio of approximate Filipino vs. English tokens for the review), which will be used for exploratory analysis and ablation. It does not apply hard filtering.

    All of these processes hence become essential in Text Normalization and data cleansing to further guarantee a sound, reliable, and most appropriate dataset for accurately constructing predictive models.
    
3. Tokenization and Length Control
- Subword Tokenization: Utilize the tokenizer from the chosen model (XLM-R or RoBERTa-tl).
- Sequence Length: Either take long reviews and truncate, or split them, with the goal of getting them to a fixed token length, ensuring they remain as full sentences wherever possible.
4. Train-Validation-Test Split
- Stratified Splits: Keep the FiReCS test set unchanged for final scoring. Generate a validation split from the training set using stratified sampling to ensure balanced labels.
- Product Subset Handling: Should wish to examine e-commerce only, use the same splitting rules after the product filter to guarantee some level of balance.
C. Machine Learning Model Selection
TF-IDF + Logistic Regression
    This baseline is the representation of every review according to term-frequency and inverse-document-frequency weights and sentiment prediction with a linear classifier. It is easy, understandable and can be trained quickly and this is why it is useful in establishing clear performance bar. The coefficients show what words drive predictions to positive, neutral, or negative categories, which means that Taglish tokens and emojis can be promptly analyzed in terms of errors. Outputs of this model will be compared to Transformer models to ensure that improvements are made by improved language representation and not label benefits.
XLM-RoBERTa (Multilingual Transformer) Overall Sentiment
    It is a processing model that learns contextual representation with many languages, such as English and Filipino, by processing text in subword tokens. It is narrowed down to a three-class sentiment classifier on FiReCS. Since it can encode a context on each side of a token, it is able to recognize patterns of code-switching, slang, and even emographics that can easily be confused with bag-of-words models. It is assumed that XLM-RoBERTa will outperform the linear baseline on macro-F1 and will provide more consistent forecasts in the context of diverse Taglish styles of writing.
RoBERTa-tl (Filipino) as a Local Prior
    This variant is taught Filipino text and tested to see whether a local language prior helps on words and morphemes that seem to mostly occur in Tagalog. It is fined with an identical configuration as XLM-RoBERTa. When comparing these two models, it will be demonstrated whether a Filipino-oriented encoder can compete with or be complimentary to a multilingual encoder in case reviews consist of both languages.
Token Classification for Aspect Span Extraction (BIO Tags)
    Aspect extraction is posed as a sequence labeling. Atop the shared encoder (XLM-RoBERTa or RoBERTa-tl), the common encoder is then topped with a token-classification head that assigns BIO tags to refer to spans that relate to terms product quality, sizing and fit, delivery and courier, and packaging, price or value, and seller communication. This design enables the model to acquire limits of pertinent phrases like, late delivery or a mali ang size or secure ang packaging that are vital to action.
Per-Aspect Polarity Classifier
    A small classification head is placed over every detected span that will be either positive, neutral or negative. The head also drinks a pooled representation of the span and this makes the decision concentrated on the phrase and not on the whole review. This transformation turns span data in raw form into data that is directly applicable to operations, like ruling negative delivery experience and preserving positive quality of product in the same review.
Lightweight Deception or Low-Quality Review Classifier
    To aid trust and safety, a small-scale classifier is trained on-top of the pooled representations of the encoder and some handful of stylometric features including length, repetitions, presence of referral codes and text that looks like templates. Here, the end point is not to arrive at final judgments but to generate a calibrated score the generation of which aids in ranking the reviews to be checked by humans. This module is a complement of sentiment and aspects as it emphasizes content that can be manipulated or uninformative despite a positive polarity.

D. Training & Fine-Tuning
1. Overall Sentiment
- Objective and Loss: Objective and Loss - Use a three-class cross-entropy on the FiReCS training set.
- Optimizer and Schedule - Use AdamW with linear warmup and weight decay.
- Regularization - Use dropout in the encoder and early stopping on macro-F1 with the validation set.
- Class Handling - Use stratified batching. Apply class weights only if an imbalance is shown in the product subset.
- Model Selection - Save the checkpoint with the best macro-F1 from the validation split, report results on the held-out FiReCS test set.Tokenization and Length Control
2. Aspect Extraction and Per-Aspect Sentiment 
- Aspect Spans (BIO): Aspect Spans (BIO) - Learn a token classification head with cross-entropy loss at the level of BIO tags.
- Aspect Polarity - Learn a small classification head using pooled representations of the detected spans; optimize the macro-F1 score across aspects.
- Multi-Task Option - Use one encoder and two heads to learn spans and polarity at the same time; select the best approach by validation scores.
- Annotation - Utilize an annotated subset of the reviews spans and per-aspect label. Implement simple consistency checks as you are labeling.Tokenization and Length Control
3. Deception Signal
- Small Labeled Subgroup: Small Labeled Subgroup - Train with a small number of data labeled as genuine, suspicious, or uncertain.
- Transfer Option - When labels are limited, we can warm-start the head using a larger public source of fake reviews, then adapt on the Philippines data.
- Calibration - Threshold tuning can be done on a validation fold to achieve goal precision and recall in practice.
4. Export and Inference
- Checkpoint Export: Store final models and tokenizers.
- Efficiency - Provide an ONNX or 8 bit quantized export of the best encoder to speed up inference.
- Serving - Provide a simple script or REST endpoint that takes raw review text and returns the overall sentiment, aspect spans with polarity and the deception flag. 
VI. EVALUATION AND BASELINE COMPARISON
A. Evaluation Metrics
    General impression will be graded mainly using macro-F1, but the data on precision, recall, and accuracy will be given as they are important to complete the image as there may be a difference in class distribution when using positive, neutral, and negative classes. The selection of macro-F1 is to do just a weighted average of the classes and associates with recent code-switching review literature that finds great performance by Transformer based on an F1-based evaluation [1]. In the case of aspect-based sentiment analysis (ABSA), span-level F1 will be used to extract aspects (BIO tags), and macro-F1 per aspect will be used to extract aspect polarity, which is traditional to the ABSA in e-commerce research [4]. The main measure in the case of the deception/low-quality signal will be PR-AUC (precision-recall area under the curve), also precision will be reported at a certain recall value, which is relevant in the literature of fake-review screening trade-offs [3]. Confidence intervals or bootstrap resampling and confusion matrices, we will include to aid the error analysis among Taglish variants.
B. Baseline Model
     The TF-IDF + Logistic Regression as a simple and transparent text-classification arrangement is going to serve as a baseline of the overall sentiment and is one of the standards that will always have a reference point. It gives interpretable coefficients across words/subwords and puts the lower limit on performance that Transformer models should surpass on the FiReCS test split (macro-F1 and accuracy). In the case of ABSA, aspect cues and lightweight baseline will be comprises of keyword/phrase rules and a logistic classifier that uses TF-IDF features to make per-aspect polarity comparisons; a weak yet explainable baseline which will be used to compare the shared-encoder ABSA model [4]. To deceive, rules + stylometrics (base) (length, repetition, URL/code tokens) with Logistic Regression will establish an initial PR-AUC which the encoder-based classifier has to pass, which is subject to screening heuristics in recent surveys [3]. Combined, these baselines make sure that the improvements of XLM-R and RoBERTa-tl fine-tuning are caused by an improved language representation rather than the evaluation artifacts [1], [3], [4].
VII. EXPECTED OUTCOMES: 
    The project is supposed to come up with a Taglinglass aware system of review analysis that produces three outputs of each review in the form of accurate overall sentiment, extracted aspect spans (with per-aspect polarity): quality, sizing/fit, delivery/courier, packaging, price/value, seller communication, and a calibrated deception/low-quality score. The sentiment model on FiReCS product subset must be successfully hitting both targets (macro-F1 [?]0.84), aspect extractor ought to be at a good span-F1 with obvious highlighted phrases, and deception module ought to be suitably screening (PR-AUC [?]0.70 with biased precision/recall). The work will also consist of a small web/API demo and a lightweight dashboard that sums up aspects summaries per shop or product, plus Dataset/Model Cards, annotation guidelines, and ablation results that will document that effect of code-switch-conscious preprocessing and model choice.
    The project is expected to be better along four dimensions with respect to existing strategies: language fit, as it will use multilingual and Filipino models which are better at handling Taglish than single-polarity lexicons or bag of words baselines; actionability, as one will stop at aspect-level rather than single-polarity signals relevant to the retail operations (such as negative delivery even good quality in the same review); trust, since less deceptive indicators will be added that raise the eyebrows of the moderator and sellers; and interpretability, because instead of providing opaque scores, span highlights will be The combination of these improvements should result in improved macro-F1 over TF-IDF + Logistic Regression, stability in performance across code-switched styles, and informative and comprehensible conclusions that can be useful to Philippine e-commerce stakeholders.
VIII. PROJECT TIMELINE

Fig. 1 Gantt Chart

    Phase 1: Organization of the project and acquisition of data (Week 1): 
    The team completes the IEEE proposal outline, gains the approval of the advisor on scope, and finishes with the FiReCS dataset secured with the product-focused subset ready to be dedicated to Philippine e-commerce. Research activities like polishing the aspect schema, writing the annotation guideline, and establishing the code repository and experiment tracker are important. The week ends with a brief proposal pitch and a data preparedness note which attests to splits, licensing and ethics.
    Phase 2: Preprocessing and Baselines (Week 2): 
    Raw reviews are purified and normalized to Taglish (control of elongation) and stratified splits ensured. A TF-IDF + Logistic Regression final sentiment baseline is used to provide a baseline score. To fix aspect spans and per-aspect polarity label validation, the annotation pilot starts on a small set of annotations, and modifies the guideline accordingly given inter-annotator feedback. 
    Phase 3: Sentiment and ABSA Core Model Training (Week 3): 
    XLM-RoBERTa is fine-tuned on three-class sentiment on FiReCS, and RoBERTa-tl results are an ablation. The macro-F1 shared encoder the better the model with F1 is. The BIO tagging aspect extraction head is presented and adopted on the growing annotated subset. In the mid-week, the team is reviewing the validation curves, optimizing learning rates and batch sizes, and backing out the inference schema to deliver spans and polarities. 
    Phase 4: ABSA Refinement and Deception Refrain (Week 4): 
    Aspect extraction is optimized (analysis of analysis of error on boundary errors), and head on per aspect polarity is trained and calibrated. A deception classifier of approximate lightweight is then appended to the pooled output derived on the encoder, stylometrically endowed, and thresholded to desired useful precision-recall trade-off. The phase provides the outcome of the processes of ablation to make preprocessing decisions and an approximation of the API providing an overall sentiment, aspect spans in various policies and a deception score.
    Phase 5: Evaluation, Integration and Reporting (Week 5):
    Last testing This tests the held-out FiReCS split, product split reporting of macro-F1, span-F1, per-aspect macro-F1, PR-AUC and confusion matrices. A Spartan dashboard combines per-aspect overviews and queue on suspicious reviews to undergo qualitative verification. The IEEE manuscript parts and the Introduction to the Evaluation are made tidy in terms of tables and figures; Dataset/ Model Cards and the annotation appendix are filled. At the end of the week, the presentation should be rehearsed and the checkpoints and the demo API should be packed and released.
IX. REFERENCES
[1] C. J. Cosme and M. M. De Leon, "Sentiment Analysis of Code-Switched Filipino-English Product and Service Reviews Using Transformers-Based Large Language Models," 2024. Available: Archium Ateneo.
[2] M. Herrera, A. Aich, and N. Parde, "A Dataset for Investigating Tagalog-English Code-Switching," in Proc. LREC, 2022.
[3] H. Paul, R. Bansal, and M. Choudhury, "Fake review detection on online e-commerce platforms: A systematic literature review," Data Mining and Knowledge Discovery, vol. 35, no. 6, pp. 2168-2211, 2021.
[4] United Nations, "Sustainable Development Goal 17: Partnerships for the Goals," United Nations Sustainable Development Goals, 2015-present.
[5] S. Verhulst and A. Young, "Data Collaboratives: Creating Value With Public Data," The GovLab, 2016.
[6] R. Vinuesa, H. Azizpour, I. Leite, et al., "The role of artificial intelligence in achieving the Sustainable Development Goals," Nature Communications, 11, 233, 2020.
[7] A. Dey, D. Patra, S. Saha, and S. K. Ghosh, "Aspect-based sentiment analysis of consumer reviews," Applied Soft Computing, vol. 155, 112259, 2024.
[8] A. Conneau et al., "Unsupervised Cross-lingual Representation Learning at Scale," in Proc. ACL, 2020.
[9] DOST-ASTI, "RoBERTa-tl-sentiment-analysis," Model Card, 2024. Available: Hugging Face.
[10] Associated Press, "The internet is rife with fake reviews. Will AI make it worse?," Dec. 23, 2024.
[11] P. Quoc-Hung, L. Thi-Thanh-Hien, and N. Thanh-Tam, "Aspect-Based Sentiment Analysis of Clothing Reviews in E-Commerce," in Proc. PACLIC, 2024.
[12] Department of Trade and Industry (Philippines), E-Commerce Philippines 2022 Roadmap, 2021.
[13] U.S. Department of Commerce, "Philippines - eCommerce," Country Commercial Guide, Jan. 24, 2024.
[14] Google, Temasek, and Bain & Company, e-Conomy SEA 2024 report, 2024.
[15] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding," Proc. NAACL-HLT, 2019.
[16] A. Conneau et al., "Unsupervised Cross-lingual Representation Learning at Scale," Proc. ACL, 2020.
[17] S. Gururangan, A. Marasovic, S. Swayamdipta, K. Lo, I. Beltagy, D. Downey, and N. A. Smith, "Don't Stop Pretraining: Adapt Language Models to Domains and Tasks," Proc. ACL, 2020.
[18] S. Khanuja, S. Dandapat, A. Srinivasan, S. Sitaram, and M. Choudhury, "GLUECoS: An Evaluation Benchmark for Code-Switched NLP," Proc. ACL, 2020.
[19] E. Hashmi, R. Abbas, and A. Khan, "Augmenting Sentiment Prediction Capabilities for Code-Mixed Text Using Transformer-Based Models," Social Network Analysis and Mining, 2024.
[20] C. J. Cosme, "FiReCS: Filipino-English Code-Switched Reviews Dataset," Hugging Face, 2024. [Online]. Available: https://huggingface.co/datasets/ccosme/FiReCS


XXX-X-XXXX-XXXX-X/XX/$XX.00 (c)20XX IEEE

