{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9UbJzzYHqkh"
      },
      "source": [
        "\n",
        "\n",
        "> This notebook presents a complete workflow for tri-class sentiment classification on the FiReCS dataset of Taglish product reviews. The pipeline begins with data loading, cleaning, and a reproducible 80/20 stratified split that preserves class balance and writes split IDs to disk for consistent evaluation across runs. A simple baseline is then established using TF-IDF features with Logistic Regression to provide an interpretable reference score. The workflow proceeds to transformer fine-tuning with two backbones: a multilingual encoder (XLM-RoBERTa) and a Filipino-prior encoder (RoBERTa-Tagalog). Both models are adapted to three sentiment labels and trained using a shared evaluation function that reports macro-F1 and accuracy on the fixed validation split.\n",
        "\n",
        "> Each section of the notebook follows a consistent structure to aid replication. The preprocessing cell prepares tokenization with a fixed sequence length and converts the data into tensor-ready datasets. The training cell configures arguments, constructs the trainer, performs fine-tuning, evaluates on the validation set, and saves the best checkpoint together with its tokenizer. A brief inference cell verifies behavior on short sample texts, while an analysis cell produces a confusion matrix and a per-class report to explain common errors between negative, neutral, and positive. A final export cell aggregates all runs into a single log, writes spreadsheet summaries for grading and reporting, and highlights the strongest configuration per model.\n",
        "\n",
        "> The notebook supports both thorough runs and quick sweeps. A fast mode reduces training time by using a smaller training slice and an optional early-stopping callback, which is useful for exploring learning rate, batch size, and epoch count under limited time or hardware. Final headline scores are obtained from full runs that reuse the same split and metric function. Saved checkpoints, split ID files, and exported logs ensure that results can be reproduced and compared fairly across members and model choices.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIiqkobxHKGk"
      },
      "source": [
        "# **Setup, imports, dataset load, and split**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSZSQ3nPC3sL"
      },
      "source": [
        "**`Purpose`**\n",
        "\n",
        "This block prepares the environment, ensures required libraries are available, and loads the FiReCS dataset into memory in a clean, consistent format. It also establishes a reproducible train–validation split so that all later experiments evaluate on the same examples. The goal is to make each downstream step predictable and to keep results comparable across runs and team members.\n",
        "\n",
        "**`Input`**\n",
        "\n",
        "The cell expects either a local copy of FiReCS.csv in the current working directory or, if absent, a file that will be provided through the upload dialog. The CSV must contain at least two columns named review and label, which represent the input text and its sentiment class. No other inputs are required at this stage, and any additional columns are ignored.\n",
        "\n",
        "**`Output`**\n",
        "\n",
        "The cell produces two pandas DataFrames, train_df and val_df, with stratified class proportions and a new id column to uniquely identify each row. It also writes two small files, train_ids.csv and val_ids.csv, which store the chosen row IDs for reuse. The printed device line indicates whether a GPU is available. Two proportion tables are printed as a quick check that label ratios are closely matched across splits.\n",
        "\n",
        "**`Details`**\n",
        "\n",
        "The cell installs the core NLP stack, imports common utilities, and detects the runtime device. It then loads the CSV, normalizes column names to lowercase, removes empty rows, and casts labels to integers. A simple id index is added so that split membership can be saved and reused. A stratified split holds label balance constant, which is printed to confirm the split is fair. Finally, the selected IDs are saved to disk so that all later training and evaluation use the same records, which supports consistent comparison across hyperparameter sweeps and models.\n",
        "\n",
        "**`Line-by-line Description.`**\n",
        "\n",
        "`!pip -q install transformers datasets accelerate scikit-learn openpyxl -U` installs or upgrades the libraries needed for tokenization, training, metrics, and spreadsheet export.\n",
        "\n",
        "`import os, numpy as np, pandas as pd, torch` pulls in filesystem helpers, numerical tools, data frames, and the deep learning backend.\n",
        "\n",
        "`from sklearn.model_selection import train_test_split` and `from sklearn.metrics import accuracy_score, f1_score` load utilities for splitting and scoring.\n",
        "`try: from google.colab import files ...` sets up an optional upload path that only activates when running in Colab.\n",
        "\n",
        "`device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')` detects whether a GPU is present and prints the choice so training expectations are clear.\n",
        "\n",
        "`if not os.path.exists('FiReCS.csv') and files is not None: files.upload()` requests an upload when the CSV is missing, which keeps the workflow flexible.\n",
        "\n",
        "`df = pd.read_csv('FiReCS.csv')` loads the data, and `df.columns = [c.lower() for c in df.columns]` enforces lowercase names so downstream code can assume consistent headers.\n",
        "\n",
        "`df = df.dropna(subset=['review','label']).copy()` removes incomplete rows to avoid errors and noisy training examples.\n",
        "`df['label'] = df['label'].astype(int)` fixes the label type so models receive proper integers.\n",
        "\n",
        "`df['id'] = np.arange(len(df))` assigns a stable identifier to each row so the split can be persisted.\n",
        "\n",
        "The branch that checks for `train_ids.csv` and `val_ids.csv` either reuses an existing split or creates a new stratified split with `train_test_split(... stratify=df['label'])`.\n",
        "\n",
        "`train_df[['id']].to_csv('train_ids.csv', index=False)` and the matching line for validation serialize the split for later reuse.\n",
        "\n",
        "The final `print(...)` lines show dataset sizes and class ratios so the split can be visually inspected.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ej9srJoYd3o",
        "outputId": "4a479ac0-049f-4912-e6c5-155b9aefd9ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ torch already installed\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ivanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ transformers already installed\n",
            "✓ datasets already installed\n",
            "✓ accelerate already installed\n",
            "✓ optuna already installed\n",
            "✓ scikit-learn already installed\n",
            "✓ pandas already installed\n",
            "✓ numpy already installed\n",
            "✓ matplotlib already installed\n",
            "✓ openpyxl already installed\n",
            "✓ optuna already installed\n",
            "Using device: cpu\n",
            "label\n",
            "0    0.324421\n",
            "1    0.347241\n",
            "2    0.328338\n",
            "Name: proportion, dtype: float64\n",
            "label\n",
            "0    0.324251\n",
            "1    0.347411\n",
            "2    0.328338\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "# Package mapping: (pip_name, import_name)\n",
        "packages_map = [\n",
        "    (\"torch\", \"torch\"),\n",
        "    (\"transformers\", \"transformers\"),\n",
        "    (\"datasets\", \"datasets\"),\n",
        "    (\"accelerate\", \"accelerate\"),\n",
        "    (\"optuna\", \"optuna\"),\n",
        "    (\"scikit-learn\", \"sklearn\"),\n",
        "    (\"pandas\", \"pandas\"),\n",
        "    (\"numpy\", \"numpy\"),\n",
        "    (\"matplotlib\", \"matplotlib\"),\n",
        "    (\"openpyxl\", \"openpyxl\"),\n",
        "    (\"optuna\", \"optuna\"),\n",
        "]\n",
        "\n",
        "for pip_name, import_name in packages_map:\n",
        "    try:\n",
        "        __import__(import_name)\n",
        "        print(f\"✓ {pip_name} already installed\")\n",
        "    except ImportError:\n",
        "        print(f\"Installing {pip_name}...\")\n",
        "        try:\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pip_name],\n",
        "                                stdout=subprocess.DEVNULL, stderr=subprocess.PIPE)\n",
        "            print(f\"✓ {pip_name} installed successfully\")\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"⚠ Warning: Could not install {pip_name}. You may need to install it manually.\")\n",
        "\n",
        "import os, numpy as np, pandas as pd, torch, json, inspect, optuna\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import optuna\n",
        "\n",
        "# Optional Colab support\n",
        "try:\n",
        "    from google.colab import files\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "    files = None\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "if not os.path.exists(\"FiReCS.csv\"):\n",
        "    if IN_COLAB and files is not None:\n",
        "        uploaded = files.upload()\n",
        "    else:\n",
        "        raise FileNotFoundError(\"FiReCS.csv not found. Please ensure the file is in the current directory.\")\n",
        "df = pd.read_csv(\"FiReCS.csv\")\n",
        "\n",
        "df = df.rename(columns={c:c.lower() for c in df.columns})\n",
        "assert {'review','label'} <= set(df.columns), \"CSV must have 'review' and 'label' columns.\"\n",
        "\n",
        "df = df.dropna(subset=['review','label']).copy()\n",
        "df['label'] = df['label'].astype(int)\n",
        "df['id'] = np.arange(len(df))\n",
        "\n",
        "train_df, val_df = train_test_split(\n",
        "    df, test_size=0.2, random_state=42, stratify=df['label']\n",
        ")\n",
        "print(train_df['label'].value_counts(normalize=True).sort_index())\n",
        "print(val_df['label'].value_counts(normalize=True).sort_index())\n",
        "\n",
        "train_df[['id']].to_csv('train_ids.csv', index=False)\n",
        "val_df[['id']].to_csv('val_ids.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--4_ssDysIuA"
      },
      "source": [
        "# Data cleaning and 80/10/10 split (reproducible)\n",
        "\n",
        "This cell applies light cleaning suitable for Taglish text and prepares reproducible 80/10/10 stratified splits. We:\n",
        "- keep case and emojis; remove control/HTML artifacts and trim whitespace\n",
        "- cap elongated character repeats to 2 (e.g., \"soobrraaa\" -> \"soobraa\")\n",
        "- drop empty rows and exact duplicates\n",
        "- persist `train_ids.csv`, `val_ids.csv`, `test_ids.csv` to reuse the same split across runs\n",
        "\n",
        "Note: A simple code-switch ratio is computed for EDA only; it is not used for model training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBDLlqdEsIuA",
        "outputId": "646fc866-3fe5-4637-a7af-bb035ce10c7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cleaned dataset: kept 7338/7340 rows\n",
            "{'train': 5870, 'val': 1468, 'test': 734}\n",
            "Label ratios (train): {0: 0.32453151618398635, 1: 0.3471890971039182, 2: 0.3282793867120954}\n",
            "Label ratios (val):   {0: 0.3242506811989101, 1: 0.3474114441416894, 2: 0.32833787465940056}\n",
            "Label ratios (test):  {0: 0.3242506811989101, 1: 0.3474114441416894, 2: 0.32833787465940056}\n"
          ]
        }
      ],
      "source": [
        "import re, html\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# --- Cleaning helpers ---\n",
        "CTRL_RE = re.compile(r\"[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F]\")\n",
        "REPEAT_RE = re.compile(r\"(\\w)\\1{2,}\")\n",
        "\n",
        "def strip_html(text: str) -> str:\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    # unescape HTML entities then drop tags\n",
        "    t = html.unescape(text)\n",
        "    t = re.sub(r\"<[^>]+>\", \" \", t)\n",
        "    return t\n",
        "\n",
        "def squash_repeats(text: str) -> str:\n",
        "    return REPEAT_RE.sub(r\"\\1\\1\", text)\n",
        "\n",
        "def basic_clean(text: str) -> str:\n",
        "    t = str(text)\n",
        "    t = strip_html(t)\n",
        "    t = CTRL_RE.sub(\" \", t)\n",
        "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
        "    t = squash_repeats(t)\n",
        "    return t\n",
        "\n",
        "# Apply cleaning to the loaded df (from earlier cell)\n",
        "df = df.copy()\n",
        "df['review'] = df['review'].astype(str).map(basic_clean)\n",
        "# drop empties and exact duplicates\n",
        "before = len(df)\n",
        "df = df[(df['review'].str.len() > 0)].drop_duplicates(subset=['review','label']).reset_index(drop=True)\n",
        "after = len(df)\n",
        "print(f\"Cleaned dataset: kept {after}/{before} rows\")\n",
        "\n",
        "# Optional: simple code-switch ratio (EDA only)\n",
        "EN_RE = re.compile(r\"[A-Za-z]{3,}\")\n",
        "TL_HINTS = set([\"po\",\"opo\",\"naman\",\"kuya\",\"ate\",\"nga\",\"na\",\"lang\",\"din\",\"rin\",\"daw\",\"ba\",\"yung\",\"yung\",\"ang\",\"sa\",\"si\",\"ni\",\"kay\",\"sana\",\"wala\",\"meron\",\"sobrang\",\"sobrang\",\"ganda\",\"pang\",\"bilis\",\"salamat\"])  # lightweight hints\n",
        "\n",
        "def code_switch_ratio(text: str) -> float:\n",
        "    tokens = re.findall(r\"\\w+\", text.lower())\n",
        "    if not tokens:\n",
        "        return 0.0\n",
        "    en_like = sum(1 for tok in tokens if EN_RE.fullmatch(tok) is not None)\n",
        "    tl_like = sum(1 for tok in tokens if tok in TL_HINTS)\n",
        "    return en_like / max(1, (en_like + tl_like))\n",
        "\n",
        "df['cs_ratio'] = df['review'].map(code_switch_ratio)\n",
        "\n",
        "# --- Reproducible 80/10/10 split ---\n",
        "RANDOM_SEED = 42\n",
        "if not {'train_ids.csv','val_ids.csv','test_ids.csv'} <= set(os.listdir('.')):\n",
        "    # stratified train vs temp (80/20)\n",
        "    df_train, df_temp = train_test_split(\n",
        "        df, test_size=0.2, random_state=RANDOM_SEED, stratify=df['label']\n",
        "    )\n",
        "    # split temp 50/50 -> 10/10\n",
        "    df_val, df_test = train_test_split(\n",
        "        df_temp, test_size=0.5, random_state=RANDOM_SEED, stratify=df_temp['label']\n",
        "    )\n",
        "    df_train[['id']].to_csv('train_ids.csv', index=False)\n",
        "    df_val[['id']].to_csv('val_ids.csv', index=False)\n",
        "    df_test[['id']].to_csv('test_ids.csv', index=False)\n",
        "else:\n",
        "    ids_tr = set(pd.read_csv('train_ids.csv')['id'].tolist())\n",
        "    ids_va = set(pd.read_csv('val_ids.csv')['id'].tolist())\n",
        "    ids_te = set(pd.read_csv('test_ids.csv')['id'].tolist())\n",
        "    df_train = df[df['id'].isin(ids_tr)].copy()\n",
        "    df_val   = df[df['id'].isin(ids_va)].copy()\n",
        "    df_test  = df[df['id'].isin(ids_te)].copy()\n",
        "\n",
        "print({\n",
        "    'train': len(df_train), 'val': len(df_val), 'test': len(df_test)\n",
        "})\n",
        "print('Label ratios (train):', df_train['label'].value_counts(normalize=True).sort_index().to_dict())\n",
        "print('Label ratios (val):  ', df_val['label'].value_counts(normalize=True).sort_index().to_dict())\n",
        "print('Label ratios (test): ', df_test['label'].value_counts(normalize=True).sort_index().to_dict())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lx0TZIOsIuB"
      },
      "source": [
        "# Fast mode toggle (optional)\n",
        "\n",
        "Set `FAST_MODE` to `True` to downsample the training split (40%) for quicker CPU experiments. Leave it `False` for full-run results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmAC-3F0sIuB",
        "outputId": "fec419d7-5c48-4286-88ad-17bc9a255fbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FAST_MODE] train=2348 (~40%), val=1468, test=734)\n"
          ]
        }
      ],
      "source": [
        "FAST_MODE = True  # Set False for full runs\n",
        "TRAIN_FRACTION = 0.40 if FAST_MODE else 1.0\n",
        "VAL_FRACTION = 1.0  # Keep full validation/test by default\n",
        "\n",
        "if FAST_MODE and TRAIN_FRACTION < 1.0:\n",
        "    df_train = (df_train\n",
        "                .sample(frac=TRAIN_FRACTION, random_state=RANDOM_SEED)\n",
        "                .sort_values('id')\n",
        "                .reset_index(drop=True))\n",
        "    if VAL_FRACTION < 1.0:\n",
        "        df_val = (df_val\n",
        "                  .sample(frac=VAL_FRACTION, random_state=RANDOM_SEED)\n",
        "                  .sort_values('id')\n",
        "                  .reset_index(drop=True))\n",
        "        df_test = (df_test\n",
        "                   .sample(frac=VAL_FRACTION, random_state=RANDOM_SEED)\n",
        "                   .sort_values('id')\n",
        "                   .reset_index(drop=True))\n",
        "    print(f\"[FAST_MODE] train={len(df_train)} (~{TRAIN_FRACTION*100:.0f}%), val={len(df_val)}, test={len(df_test)})\")\n",
        "else:\n",
        "    print(\"FAST_MODE disabled: using full train/val/test splits\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Automated hyperparameter tuning configuration\n",
        "\n",
        "Controls the Optuna-based grid and random searches. Toggle `AUTO_TUNE_ENABLED` to run the section, and adjust the search spaces as needed.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Automated hyperparameter tuning configuration\n",
        "\n",
        "Toggle these settings to enable or customise the grid and random search experiments that will be executed later in the notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "AUTO_TUNE_ENABLED = True  # Set to False to skip automated searches\n",
        "\n",
        "GRID_SEARCH_SPACE = {\n",
        "    \"learning_rate\": [5e-5, 3e-5, 2e-5],\n",
        "    \"per_device_train_batch_size\": [8, 16],\n",
        "    \"weight_decay\": [0.0, 0.05],\n",
        "    \"num_train_epochs\": [2, 3],\n",
        "}\n",
        "\n",
        "RANDOM_SEARCH_SPACE = {\n",
        "    # (mode, low, high, log_scale?) definitions, interpreted later\n",
        "    \"learning_rate\": (\"log_uniform\", 2e-5, 5e-5),\n",
        "    \"per_device_train_batch_size\": (\"choice\", [8, 12, 16, 24]),\n",
        "    \"weight_decay\": (\"uniform\", 0.0, 0.1),\n",
        "    \"num_train_epochs\": (\"int\", 2, 4),\n",
        "}\n",
        "\n",
        "RANDOM_TRIALS = 8  # adjust for more extensive exploration\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9q0q_b0HE_w"
      },
      "source": [
        "# **Baseline TF-IDF + Logistic Regression and log row**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kwe7KU5uDQzz"
      },
      "source": [
        "**`Purpose`**\n",
        "\n",
        "This block builds a fast and transparent baseline that serves as a reference point for the later transformer models. It turns each review into a TF-IDF vector over single words and bigrams, trains a linear classifier, and records validation performance. The intent is to establish a clear bar that later fine-tuned models should exceed.\n",
        "\n",
        "**`Input`**\n",
        "\n",
        "The inputs are the train_df and val_df frames created earlier. Only the review and label columns are used. The TF-IDF vectorizer is configured with a vocabulary limit to cap memory and training time, and the labels are taken directly as integer classes.\n",
        "\n",
        "**`Output`**\n",
        "\n",
        "The block prints a compact dictionary that contains baseline accuracy and macro-F1. It also appends a structured row to runs_log.csv so that the baseline appears in the experiment ledger with model name, scores, and a note. These outputs provide both an on-screen summary and a durable record for later tables and charts.\n",
        "\n",
        "**`Details`**\n",
        "\n",
        "A TF-IDF vectorizer is fit on the training text and applied to the validation text, producing sparse matrices. A Logistic Regression model is trained with a high iteration cap to ensure convergence. Predictions for the validation set are compared against the gold labels to compute accuracy and macro-F1, where macro-F1 treats all classes equally. The metrics are printed and then written to the log file with consistent column names so that later export steps can merge and sort results without extra work.\n",
        "\n",
        "\n",
        "**`Line-by-line Description`**\n",
        "\n",
        "`from sklearn.feature_extraction.text import TfidfVectorizer` and `from sklearn.linear_model import LogisticRegression` import the tools for representation and classification.\n",
        "\n",
        "`tfidf = TfidfVectorizer(max_features=50000, ngram_range=(1,2), lowercase=True)` defines the vocabulary limit and includes single words and bigrams to capture short phrases.\n",
        "\n",
        "`X_tr = tfidf.fit_transform(train_df['review'])` learns the vocabulary and weights from training text and returns the training matrix.\n",
        "\n",
        "`y_tr = train_df['label'].values` extracts the training labels as a dense array.\n",
        "\n",
        "`X_va = tfidf.transform(val_df['review'])` applies the same mapping to validation text to ensure a consistent feature space.\n",
        "\n",
        "`y_va = val_df['label'].values` collects validation labels.\n",
        "\n",
        "`logreg = LogisticRegression(max_iter=2000)` raises the iteration cap to support convergence in high-dimensional space.\n",
        "\n",
        "`logreg.fit(X_tr, y_tr)` learns the linear classifier on the training features.\n",
        "\n",
        "`preds = logreg.predict(X_va)` generates predicted labels for validation examples.\n",
        "\n",
        "`acc_base = accuracy_score(y_va, preds)` and `f1_base = f1_score(..., average='macro')` compute the two main scores.\n",
        "\n",
        "The dictionary `{'model':..., 'accuracy':..., 'f1_macro':...}` is printed to show the baseline performance clearly.\n",
        "\n",
        "The `row = {...}` dictionary collects metadata and scores, and the `with open('runs_log.csv','a',...)` block appends it to the experiment ledger, writing headers when the file is new.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQkWVS7TYdm6",
        "outputId": "adfa3fb2-fae4-4a83-9d41-5d8f8842151c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'model': 'tfidf-logreg', 'accuracy': 0.803133514986376, 'f1_macro': 0.8057244174688569}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "tfidf = TfidfVectorizer(\n",
        "    max_features=50000,\n",
        "    ngram_range=(1,2),\n",
        "    lowercase=True\n",
        ")\n",
        "X_tr = tfidf.fit_transform(train_df['review'])\n",
        "y_tr = train_df['label'].values\n",
        "X_va = tfidf.transform(val_df['review'])\n",
        "y_va = val_df['label'].values\n",
        "\n",
        "logreg = LogisticRegression(max_iter=2000, n_jobs=None, class_weight=None)\n",
        "logreg.fit(X_tr, y_tr)\n",
        "\n",
        "preds = logreg.predict(X_va)\n",
        "acc_base = accuracy_score(y_va, preds)\n",
        "f1_base  = f1_score(y_va, preds, average='macro')\n",
        "print({\"model\":\"tfidf-logreg\", \"accuracy\":acc_base, \"f1_macro\":f1_base})\n",
        "\n",
        "row = {\n",
        "    \"member\":\"baseline\", \"model\":\"tfidf-logreg\",\n",
        "    \"num_train_epochs\":None, \"per_device_train_batch_size\":None,\n",
        "    \"learning_rate\":None, \"weight_decay\":None, \"warmup_steps\":None,\n",
        "    \"lr_scheduler_type\":None, \"gradient_accumulation_steps\":None,\n",
        "    \"max_seq_length\":None, \"seed\":42, \"fp16\":False,\n",
        "    \"accuracy\":acc_base, \"f1_macro\":f1_base, \"notes\":\"TF-IDF + LogReg baseline\"\n",
        "}\n",
        "pd.DataFrame([row]).to_csv(\"runs_log.csv\", mode=\"a\",\n",
        "                           index=False, header=not os.path.exists(\"runs_log.csv\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0neAE-lsIuD"
      },
      "source": [
        "# Baseline ablations (TF‑IDF + Logistic Regression)\n",
        "\n",
        "We select the best baseline via 5‑fold CV on training data across two representations:\n",
        "- word 1–2 ngrams (50k features)\n",
        "- char_wb 3–5 ngrams (100k features)\n",
        "\n",
        "We then refit on train+val and evaluate on the held‑out test set. Outputs: predictions CSV, confusion matrix, and a log row in `runs_log.csv`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpr5r5uRsIuD",
        "outputId": "91f845be-badc-43aa-8e92-be913f09c84c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception in thread ExecutorManagerThread:\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\ivanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"c:\\Users\\ivanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 626, in run\n",
            "    self.terminate_broken(bpe)\n",
            "  File \"c:\\Users\\ivanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 833, in terminate_broken\n",
            "    self.kill_workers(reason=\"broken executor\")\n",
            "  File \"c:\\Users\\ivanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 866, in kill_workers\n",
            "    kill_process_tree(p)\n",
            "  File \"c:\\Users\\ivanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\utils.py\", line 19, in kill_process_tree\n",
            "    _kill_process_tree_with_psutil(process)\n",
            "  File \"c:\\Users\\ivanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\utils.py\", line 35, in _kill_process_tree_with_psutil\n",
            "    descendants = psutil.Process(process.pid).children(recursive=True)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\ivanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\psutil\\__init__.py\", line 977, in children\n",
            "    ppid_map = _ppid_map()\n",
            "               ^^^^^^^^^^^\n",
            "OSError: [WinError 1455] The paging file is too small for this operation to complete\n"
          ]
        },
        {
          "ename": "BrokenProcessPool",
          "evalue": "A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31m_RemoteTraceback\u001b[39m                          Traceback (most recent call last)",
            "\u001b[31m_RemoteTraceback\u001b[39m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\ivanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 453, in _process_worker\n    call_item = call_queue.get(block=True, timeout=timeout)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\ivanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\queues.py\", line 122, in get\n    return _ForkingPickler.loads(res)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\ivanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\__init__.py\", line 281, in <module>\n    _load_dll_libraries()\n  File \"c:\\Users\\ivanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\__init__.py\", line 264, in _load_dll_libraries\n    raise err\nOSError: [WinError 1455] The paging file is too small for this operation to complete. Error loading \"c:\\Users\\ivanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\lib\\shm.dll\" or one of its dependencies.\n\"\"\"",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mBrokenProcessPool\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     25\u001b[39m pipe = Pipeline([\n\u001b[32m     26\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mvec\u001b[39m\u001b[33m'\u001b[39m, vec),\n\u001b[32m     27\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mclf\u001b[39m\u001b[33m'\u001b[39m, LogisticRegression(max_iter=\u001b[32m2000\u001b[39m))\n\u001b[32m     28\u001b[39m ])\n\u001b[32m     29\u001b[39m gs = GridSearchCV(\n\u001b[32m     30\u001b[39m     pipe, param_grid=param_grid, scoring=\u001b[33m'\u001b[39m\u001b[33mf1_macro\u001b[39m\u001b[33m'\u001b[39m, cv=skf, n_jobs=-\u001b[32m1\u001b[39m, verbose=\u001b[32m1\u001b[39m\n\u001b[32m     31\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[43mgs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mVariant \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m best CV f1_macro: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgs.best_score_\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgs.best_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m best \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m gs.best_score_ > best[\u001b[33m'\u001b[39m\u001b[33mcv\u001b[39m\u001b[33m'\u001b[39m]:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ivanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ivanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1045\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1046\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1047\u001b[39m     )\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1055\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ivanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1605\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1603\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1604\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1605\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ivanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:997\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    993\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    994\u001b[39m         )\n\u001b[32m    995\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1017\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1018\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ivanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ivanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ivanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ivanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1784\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1778\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._wait_retrieval():\n\u001b[32m   1779\u001b[39m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[32m   1780\u001b[39m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[32m   1781\u001b[39m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[32m   1782\u001b[39m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[32m   1783\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._aborting:\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1785\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1787\u001b[39m     nb_jobs = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._jobs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ivanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1859\u001b[39m, in \u001b[36mParallel._raise_error_fast\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1855\u001b[39m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[32m   1856\u001b[39m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[32m   1857\u001b[39m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[32m   1858\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1859\u001b[39m     \u001b[43merror_job\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ivanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:758\u001b[39m, in \u001b[36mBatchCompletionCallBack.get_result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    752\u001b[39m backend = \u001b[38;5;28mself\u001b[39m.parallel._backend\n\u001b[32m    754\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backend.supports_retrieve_callback:\n\u001b[32m    755\u001b[39m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[32m    756\u001b[39m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[32m    757\u001b[39m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m758\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    760\u001b[39m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[32m    761\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ivanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:773\u001b[39m, in \u001b[36mBatchCompletionCallBack._return_or_raise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    771\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    772\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.status == TASK_ERROR:\n\u001b[32m--> \u001b[39m\u001b[32m773\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n\u001b[32m    774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n\u001b[32m    775\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
            "\u001b[31mBrokenProcessPool\u001b[39m: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable."
          ]
        }
      ],
      "source": [
        "import numpy as np, matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score, f1_score\n",
        "\n",
        "X_tr = df_train['review'].tolist(); y_tr = df_train['label'].values\n",
        "X_va = df_val['review'].tolist();   y_va = df_val['label'].values\n",
        "X_te = df_test['review'].tolist();  y_te = df_test['label'].values\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
        "param_grid = {\n",
        "    'clf__C': [0.5, 1.0, 2.0, 4.0],\n",
        "    'clf__class_weight': [None, 'balanced']\n",
        "}\n",
        "\n",
        "variants = {\n",
        "    'word_1_2': TfidfVectorizer(max_features=50000, ngram_range=(1,2), lowercase=True),\n",
        "    'charwb_3_5': TfidfVectorizer(analyzer='char_wb', ngram_range=(3,5), max_features=100000, lowercase=True)\n",
        "}\n",
        "\n",
        "best = None\n",
        "for name, vec in variants.items():\n",
        "    pipe = Pipeline([\n",
        "        ('vec', vec),\n",
        "        ('clf', LogisticRegression(max_iter=2000))\n",
        "    ])\n",
        "    gs = GridSearchCV(\n",
        "        pipe, param_grid=param_grid, scoring='f1_macro', cv=skf, n_jobs=-1, verbose=1\n",
        "    )\n",
        "    gs.fit(X_tr, y_tr)\n",
        "    print(f\"Variant {name} best CV f1_macro: {gs.best_score_:.4f} with {gs.best_params_}\")\n",
        "    if best is None or gs.best_score_ > best['cv']:\n",
        "        best = {\n",
        "            'name': name,\n",
        "            'cv': gs.best_score_,\n",
        "            'best_params': gs.best_params_,\n",
        "            'estimator': gs.best_estimator_\n",
        "        }\n",
        "\n",
        "# Validate picked model on val\n",
        "val_preds = best['estimator'].predict(X_va)\n",
        "val_acc = accuracy_score(y_va, val_preds)\n",
        "val_f1m = f1_score(y_va, val_preds, average='macro')\n",
        "print({'pick': best['name'], 'val_acc': val_acc, 'val_f1_macro': val_f1m})\n",
        "\n",
        "# Refit on train+val\n",
        "X_trval = X_tr + X_va\n",
        "y_trval = np.concatenate([y_tr, y_va])\n",
        "best_refit = Pipeline([\n",
        "    ('vec', variants[best['name']]),\n",
        "    ('clf', LogisticRegression(max_iter=2000, **{k.split('__')[1]:v for k,v in best['best_params'].items()}))\n",
        "])\n",
        "best_refit.fit(X_trval, y_trval)\n",
        "\n",
        "y_pred = best_refit.predict(X_te)\n",
        "acc = accuracy_score(y_te, y_pred)\n",
        "f1m = f1_score(y_te, y_pred, average='macro')\n",
        "print({'baseline_best_test_acc': acc, 'baseline_best_test_f1_macro': f1m, 'variant': best['name']})\n",
        "\n",
        "# Save predictions and confusion matrix\n",
        "import pandas as pd, os\n",
        "pd.DataFrame({'review': X_te, 'gold': y_te, 'pred': y_pred}).to_csv('baseline_predictions_test.csv', index=False)\n",
        "cm = confusion_matrix(y_te, y_pred, labels=[0,1,2])\n",
        "fig, ax = plt.subplots(figsize=(4,4))\n",
        "ConfusionMatrixDisplay(cm, display_labels=['neg','neu','pos']).plot(ax=ax, colorbar=False)\n",
        "plt.tight_layout(); plt.savefig('baseline_cm_test.png', dpi=150); plt.close()\n",
        "\n",
        "# Append to log\n",
        "row = {\n",
        "    'member': 'baseline-grid',\n",
        "    'model': f'tfidf-{best[\"name\"]}',\n",
        "    'num_train_epochs': None,\n",
        "    'per_device_train_batch_size': None,\n",
        "    'learning_rate': None,\n",
        "    'weight_decay': None,\n",
        "    'warmup_steps': None,\n",
        "    'lr_scheduler_type': None,\n",
        "    'gradient_accumulation_steps': None,\n",
        "    'max_seq_length': None,\n",
        "    'seed': RANDOM_SEED,\n",
        "    'fp16': False,\n",
        "    'accuracy': acc,\n",
        "    'f1_macro': f1m,\n",
        "    'notes': f'GridSearchCV 5-fold; best_params={best[\"best_params\"]}'\n",
        "}\n",
        "pd.DataFrame([row]).to_csv('runs_log.csv', mode='a', index=False, header=not os.path.exists('runs_log.csv'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yad0QwfTsIuE"
      },
      "source": [
        "# GPU Diagnostics and Setup\n",
        "\n",
        "Check GPU availability and configuration. If no GPU is detected, training will be slower on CPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qT4y3UtVsIuE",
        "outputId": "65fb5baa-5c85-4758-b0a8-dbdab129ffe6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "SYSTEM INFORMATION\n",
            "============================================================\n",
            "Platform: Windows 10\n",
            "Python: 3.11.9\n",
            "PyTorch: 2.9.0+cpu\n",
            "\n",
            "⚠ NO GPU DETECTED\n",
            "  Training will use CPU (slow)\n",
            "  Consider using Google Colab with GPU runtime for faster training\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import platform\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"SYSTEM INFORMATION\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Platform: {platform.system()} {platform.release()}\")\n",
        "print(f\"Python: {platform.python_version()}\")\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print()\n",
        "\n",
        "# GPU Check\n",
        "if torch.cuda.is_available():\n",
        "    print(\"✓ GPU DETECTED\")\n",
        "    print(f\"  Device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"  CUDA Version: {torch.version.cuda}\")\n",
        "    print(f\"  cuDNN Version: {torch.backends.cudnn.version()}\")\n",
        "    print(f\"  GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "    print(f\"  GPU Count: {torch.cuda.device_count()}\")\n",
        "    print(f\"  Current Device: {torch.cuda.current_device()}\")\n",
        "    print(\"\\n✓ Training will use GPU (fast)\")\n",
        "    USE_GPU_FLAG = True\n",
        "else:\n",
        "    print(\"⚠ NO GPU DETECTED\")\n",
        "    print(\"  Training will use CPU (slow)\")\n",
        "    print(\"  Consider using Google Colab with GPU runtime for faster training\")\n",
        "    USE_GPU_FLAG = False\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EANPmOOIHBX6"
      },
      "source": [
        "# **Model switcher, tokenization, dataset tensors, and model init**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXiJwfJkDZ_K"
      },
      "source": [
        "**`Purpose`**\n",
        "\n",
        "This block activates the transformer route by choosing a backbone, preparing tokenization, converting data to the dataset format expected by the trainer, and constructing a sequence-classification head for three sentiment classes. It standardizes inputs so that training runs follow a single, repeatable path.\n",
        "\n",
        "**`Input`**\n",
        "\n",
        "The inputs are the training and validation DataFrames and a model key that selects either the multilingual encoder or the Tagalog-prior encoder. A maximum sequence length is specified to keep batch shapes uniform. The tokenizer is loaded to map raw text into token IDs and attention masks.\n",
        "\n",
        "**`Output`**\n",
        "\n",
        "The block prints the resolved model name to document which backbone is active. Two datasets.Dataset objects are produced with tensor columns input_ids, attention_mask, and label. A classification model with three output labels is created and moved to the detected device so that subsequent training calls can run immediately.\n",
        "\n",
        "**`Details`**\n",
        "\n",
        "A small dictionary maps human-readable keys to exact model identifiers. The tokenizer is loaded with the fast backend and wrapped in a function that applies truncation and padding to a fixed length. The pandas frames are converted into Dataset objects, tokenization is applied in batches for speed, and the dataset columns are formatted as PyTorch tensors. The model is loaded with a task-specific head sized to three classes and placed on CPU or GPU, depending on availability. These steps ensure that both backbones present the same interface to the training loop.\n",
        "\n",
        "**`Line-by-line Description`**\n",
        "\n",
        "`from datasets import Dataset` and `from transformers import AutoTokenizer, AutoModelForSequenceClassification` load dataset and model utilities.\n",
        "\n",
        "`MODEL_CHOICES = {...}` defines a readable switch between multilingual and Tagalog-prior encoders.\n",
        "\n",
        "`MODEL_CHOICE = 'xlmrb'` selects the active key, and `MODEL_NAME = MODEL_CHOICES[MODEL_CHOICE]` resolves it to a full identifier.\n",
        "\n",
        "`print('Using model:', MODEL_NAME)` documents the chosen model in the runtime log.\n",
        "\n",
        "`MAX_LEN = 128` sets a fixed sequence length to control memory and speed.\n",
        "\n",
        "`tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)` loads the matching fast tokenizer for efficient token handling.\n",
        "\n",
        "`def tok(batch): return tokenizer(batch['review'], truncation=True, padding='max_length', max_length=MAX_LEN)` defines a reusable tokenization function that enforces consistent length.\n",
        "\n",
        "`ds_train = Dataset.from_pandas(train_df[['review','label']].reset_index(drop=True))` and the similar line for validation convert pandas frames into Dataset objects with only the needed columns.\n",
        "\n",
        "`ds_train = ds_train.map(tok, batched=True)` applies tokenization in batches to speed up preprocessing.\n",
        "\n",
        "`ds_train = ds_train.with_format('torch', columns=['input_ids','attention_mask','label'])` and the matching line for validation expose tensors that the trainer consumes.\n",
        "\n",
        "`num_labels = 3` sets the number of sentiment classes.\n",
        "\n",
        "`model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=num_labels).to(device)` loads the encoder with a classification head and moves it to CPU or GPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376,
          "referenced_widgets": [
            "54ce2cbf872e4a1bace9d357224af54f",
            "f86573a9431e45ac90ebebc4fefaa637",
            "5a98a9565c80437eb5fbff7959f641af",
            "de4e6cb32d1c4cb1a144d45cfdd69716",
            "404cb20929ae449bbfdcec1c1120e492",
            "cd8c033f142e4cfa8ada243107fb6d9e",
            "25a9b69db84d4019bfcf4468de0230f0",
            "35ee990f87ff4e08875f67b39634a733",
            "a62adb4544da44c08eb9e0b2490a1dbe",
            "9fd7900968bb4fcc933209f91c2a6d13",
            "0f08a2cde1a943b7b7bbc6700bb81a7c",
            "7998ea6b1b6746ee9b0b646d86515b55",
            "885427d083a14807a16138dbc4578041",
            "1245c9f4b94044f89da706b7ad6e1e15",
            "7a1c7c195a8a4f308edef2de43b3fcae",
            "4216e6ed3fb24da18e99fe0c717db045",
            "0a4ea765a86c4f4bb359ea799b6a14bc",
            "5a3eb5c3ddb64655b8e50bff64be19d3",
            "1b1eac066cf34176853032a4cc2bccd0",
            "122994d3a4aa4168b7a25bf2fcb75f12",
            "363cd7771c6f45d09db0abcc06e31c60",
            "1c4ff9efabf6418cb31ebacafbe886b5",
            "3c27b86759f94786b77a560a32856875",
            "97827c4e0bbc470f8b420c3bce9aa202",
            "fc5894a33a824078b5063769270edea0",
            "b8d15f8a0f8749eab1265e790c71a725",
            "213a8b12e47643228f42bda40a4ffc7b",
            "b4d65b8f4f7c4cddad1fa0ce735b6384",
            "ac08bae15e944971b2332430b60aefee",
            "5401eda2dd92440eb942e4e4ce22ae9a",
            "8d6a9ce521154252b75dcfc8389be09f",
            "e182c0280fc44a5a8e8af5f6ed120e77",
            "0e1cbab441fd44d6b30a6566b65a0629"
          ]
        },
        "id": "hZEoStUoYddB",
        "outputId": "5cc3c12c-34b1-4ba6-999b-ce5f48c7272b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠ No GPU detected, using CPU (training will be slow)\n",
            "Using model: xlm-roberta-base\n",
            "Tokenizing datasets (this may take a moment)...\n",
            "  Using single-process tokenization (Windows compatibility)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 2348/2348 [00:00<00:00, 10002.66 examples/s]\n",
            "Map: 100%|██████████| 1468/1468 [00:00<00:00, 13227.15 examples/s]\n",
            "Map: 100%|██████████| 734/734 [00:00<00:00, 9881.94 examples/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Datasets ready: train=2348, val=1468, test=734\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Model loaded on cpu\n"
          ]
        }
      ],
      "source": [
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import platform\n",
        "\n",
        "# GPU detection and optimization settings\n",
        "USE_GPU = torch.cuda.is_available()\n",
        "if USE_GPU:\n",
        "    print(f\"✓ GPU detected: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"  CUDA Version: {torch.version.cuda}\")\n",
        "    print(f\"  GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    # Windows needs num_workers=0, Linux can use more\n",
        "    NUM_WORKERS = 0 if platform.system() == 'Windows' else 4\n",
        "    PIN_MEMORY = True\n",
        "else:\n",
        "    print(\"⚠ No GPU detected, using CPU (training will be slow)\")\n",
        "    device = torch.device(\"cpu\")\n",
        "    NUM_WORKERS = 0\n",
        "    PIN_MEMORY = False\n",
        "\n",
        "MODEL_CHOICES = {\n",
        "    \"xlmrb\": \"xlm-roberta-base\",\n",
        "    \"roberta-tl\": \"jcblaise/roberta-tagalog-base\",\n",
        "}\n",
        "MODEL_CHOICE = \"xlmrb\"\n",
        "MODEL_NAME = MODEL_CHOICES[MODEL_CHOICE]\n",
        "print(f\"Using model: {MODEL_NAME}\")\n",
        "\n",
        "MAX_LEN = 128\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
        "\n",
        "def tokenize_fn(batch):\n",
        "    return tokenizer(batch[\"review\"], truncation=True, padding=\"max_length\", max_length=MAX_LEN)\n",
        "\n",
        "print(\"Tokenizing datasets (this may take a moment)...\")\n",
        "ds_train = Dataset.from_pandas(df_train[['review','label']].reset_index(drop=True))\n",
        "ds_val   = Dataset.from_pandas(df_val[['review','label']].reset_index(drop=True))\n",
        "ds_test  = Dataset.from_pandas(df_test[['review','label']].reset_index(drop=True))\n",
        "\n",
        "# Windows multiprocessing has issues with tokenizers, so disable parallel processing on Windows\n",
        "# On Linux/Mac, we can use parallel processing if not on CPU\n",
        "if platform.system() == 'Windows':\n",
        "    NUM_PROC_TOKENIZE = None  # Disable parallel processing on Windows\n",
        "    print(\"  Using single-process tokenization (Windows compatibility)\")\n",
        "else:\n",
        "    NUM_PROC_TOKENIZE = 4 if USE_GPU else 2  # Parallel processing on Unix systems\n",
        "    print(f\"  Using {NUM_PROC_TOKENIZE} processes for tokenization\")\n",
        "\n",
        "# Tokenize datasets (batched=True is faster than individual processing)\n",
        "# Only remove 'review' column, keep 'label' column\n",
        "ds_train = ds_train.map(tokenize_fn, batched=True, num_proc=NUM_PROC_TOKENIZE, remove_columns=['review'])\n",
        "ds_val   = ds_val.map(tokenize_fn, batched=True, num_proc=NUM_PROC_TOKENIZE, remove_columns=['review'])\n",
        "ds_test  = ds_test.map(tokenize_fn, batched=True, num_proc=NUM_PROC_TOKENIZE, remove_columns=['review'])\n",
        "\n",
        "cols = ['input_ids','attention_mask','label']\n",
        "ds_train = ds_train.with_format(\"torch\", columns=cols)\n",
        "ds_val   = ds_val.with_format(\"torch\", columns=cols)\n",
        "ds_test  = ds_test.with_format(\"torch\", columns=cols)\n",
        "\n",
        "print(f\"✓ Datasets ready: train={len(ds_train)}, val={len(ds_val)}, test={len(ds_test)}\")\n",
        "\n",
        "num_labels = 3\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=num_labels)\n",
        "model = model.to(device)\n",
        "print(f\"✓ Model loaded on {device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEsbkL2IG9kO"
      },
      "source": [
        "# **Training arguments, metric function, and Trainer construction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBYE28ApDjp7"
      },
      "source": [
        "**`Purpose`**\n",
        "\n",
        "This block defines how progress will be measured and how training will proceed. It establishes a metric function that reports macro-F1 and accuracy, builds a version-safe set of training arguments, and constructs a Trainer object that ties the model, data, tokenizer, arguments, and metrics into a single training interface.\n",
        "\n",
        "**`Input`**\n",
        "\n",
        "Inputs include the tokenized datasets, the initialized model and tokenizer, and hyperparameters such as number of epochs, batch sizes, learning rate, weight decay, and evaluation cadence. The argument builder reads the current library signature to set compatible fields for evaluation and saving strategies.\n",
        "\n",
        "**`Output`**\n",
        "\n",
        "The cell prints a confirmation that the trainer is ready and includes the active model name. Internally, it prepares all objects required for training and evaluation so that the next call can start optimization without additional setup.\n",
        "\n",
        "**`Details`**\n",
        "\n",
        "A compute function converts raw model outputs into predicted labels and compares them with gold labels to obtain macro-F1 and accuracy. A helper builds a dictionary of training arguments and adapts it to the current version of the library so that required keys are set correctly. Optional mixed-precision is enabled when a GPU is available. The finalized arguments, datasets, and tokenizer are passed into Trainer, which centralizes the fit loop, evaluation, and checkpointing steps under a consistent API.\n",
        "\n",
        "\n",
        "**`Line-by-line Description`**\n",
        "\n",
        "`import numpy as np, inspect` pulls in numerical tools and reflection utilities.\n",
        "\n",
        "`from transformers import TrainingArguments, Trainer` imports the high-level training API.\n",
        "\n",
        "`def compute_metrics(eval_pred): ...` defines the scoring routine that returns macro-F1 and accuracy for evaluation and model selection.\n",
        "\n",
        "`sig = inspect.signature(TrainingArguments.__init__)` captures the current constructor signature so keys can be set compatibly.\n",
        "\n",
        "`def make_training_args(**overrides):` creates a helper that merges sensible defaults with any overrides provided later. Inside the helper, the dictionary sets outputs, epochs, batch sizes, learning rate, weight decay, warmup, scheduler, accumulation steps, best-model selection, seed, logging interval, and reporting target.\n",
        "\n",
        "The following `if` blocks map evaluation and saving keys to whatever names the current library expects, and another branch sets `fp16` if a GPU is present.\n",
        "\n",
        "`training_args = make_training_args()` creates a baseline configuration, and `trainer = Trainer(...)` binds the model, arguments, datasets, tokenizer, and metric function together.\n",
        "\n",
        "`print('Trainer ready on', MODEL_NAME)` confirms that the training interface is assembled and names the backbone in use.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TschWlUwZBIo",
        "outputId": "a42cb5b6-d6c1-47bf-fe1b-18acb322f3a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Trainer ready on cpu\n",
            "  Batch size: 8 (train), 16 (eval)\n",
            "  FP16: False, Workers: 0, Pin Memory: False\n",
            "  Early stopping: patience=2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ivanj\\AppData\\Local\\Temp\\ipykernel_38352\\3496499708.py:81: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ],
      "source": [
        "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback\n",
        "import inspect\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    preds = np.argmax(eval_pred.predictions, axis=1)\n",
        "    labels = eval_pred.label_ids\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    f1m = f1_score(labels, preds, average='macro')\n",
        "    return {'accuracy': acc, 'f1_macro': f1m}\n",
        "\n",
        "# GPU-optimized batch sizes\n",
        "if USE_GPU:\n",
        "    # Adjust batch size based on GPU memory (larger = faster training)\n",
        "    TRAIN_BATCH_SIZE = 32  # Increase if you have more GPU memory\n",
        "    EVAL_BATCH_SIZE = 64\n",
        "    USE_FP16 = True\n",
        "    GRADIENT_CHECKPOINTING = False  # Set True if out of memory\n",
        "else:\n",
        "    TRAIN_BATCH_SIZE = 8   # Smaller for CPU\n",
        "    EVAL_BATCH_SIZE = 16\n",
        "    USE_FP16 = False\n",
        "    GRADIENT_CHECKPOINTING = False\n",
        "\n",
        "sig = inspect.signature(TrainingArguments.__init__)\n",
        "argnames = set(sig.parameters.keys())\n",
        "\n",
        "def make_training_args(**overrides):\n",
        "    base_epochs = 2 if FAST_MODE else 3\n",
        "    # Calculate warmup steps (10% of training steps)\n",
        "    total_steps = max(1, (len(ds_train) // max(1, TRAIN_BATCH_SIZE)) * base_epochs)\n",
        "    warmup_steps = max(25, int(total_steps * 0.1))\n",
        "\n",
        "    cfg = dict(\n",
        "        output_dir=f\"./checkpoints/{MODEL_CHOICE}/run1\",\n",
        "        num_train_epochs=base_epochs,\n",
        "        per_device_train_batch_size=TRAIN_BATCH_SIZE,\n",
        "        per_device_eval_batch_size=EVAL_BATCH_SIZE,\n",
        "        learning_rate=3e-5,\n",
        "        weight_decay=0.01,\n",
        "        warmup_ratio=0.05,\n",
        "        lr_scheduler_type=\"linear\",\n",
        "        gradient_accumulation_steps=1,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"f1_macro\",\n",
        "        greater_is_better=True,\n",
        "        seed=42,\n",
        "        logging_steps=50,\n",
        "        eval_steps=100,\n",
        "        save_steps=200,\n",
        "        save_total_limit=2,\n",
        "        report_to=[],\n",
        "        fp16=USE_FP16,\n",
        "        dataloader_num_workers=NUM_WORKERS,\n",
        "        dataloader_pin_memory=PIN_MEMORY,\n",
        "        remove_unused_columns=False,\n",
        "        gradient_checkpointing=GRADIENT_CHECKPOINTING,\n",
        "    )\n",
        "    cfg.update(overrides)\n",
        "\n",
        "    # Handle different versions of transformers\n",
        "    if \"evaluation_strategy\" in argnames:\n",
        "        cfg[\"evaluation_strategy\"] = cfg.get(\"evaluation_strategy\", \"steps\")\n",
        "    elif \"eval_strategy\" in argnames:\n",
        "        cfg[\"eval_strategy\"] = cfg.get(\"eval_strategy\", \"steps\")\n",
        "\n",
        "    if \"save_strategy\" in argnames:\n",
        "        cfg[\"save_strategy\"] = cfg.get(\"save_strategy\", \"steps\")\n",
        "\n",
        "    safe_cfg = {k:v for k,v in cfg.items() if k in argnames}\n",
        "    return TrainingArguments(**safe_cfg)\n",
        "\n",
        "training_args = make_training_args()\n",
        "\n",
        "# Enable gradient checkpointing on model if needed\n",
        "if GRADIENT_CHECKPOINTING and hasattr(model, 'gradient_checkpointing_enable'):\n",
        "    model.gradient_checkpointing_enable()\n",
        "    print(\"✓ Gradient checkpointing enabled (saves memory)\")\n",
        "\n",
        "callbacks = [EarlyStoppingCallback(early_stopping_patience=2, early_stopping_threshold=0.001)]\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=ds_train,\n",
        "    eval_dataset=ds_val,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        "    callbacks=callbacks,\n",
        ")\n",
        "\n",
        "print(f\"✓ Trainer ready on {device}\")\n",
        "print(f\"  Batch size: {TRAIN_BATCH_SIZE} (train), {EVAL_BATCH_SIZE} (eval)\")\n",
        "print(f\"  FP16: {USE_FP16}, Workers: {NUM_WORKERS}, Pin Memory: {PIN_MEMORY}\")\n",
        "print(f\"  Early stopping: patience=2\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Automated Hyperparameter Search (Grid vs Random)\n",
        "\n",
        "Optuna is used to compare a compact grid search with a random search on the reduced training split. The search spaces are intentionally small so a CPU run completes in well under ~30 minutes. Set `AUTO_TUNE_ENABLED = False` to skip this block.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-08 14:13:58,185] A new study created in memory with name: no-name-09aeaa3f-26d4-4b88-bf82-05ca166e8168\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Hyperparameter search: GRID ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ivanj\\AppData\\Local\\Temp\\ipykernel_38352\\2726699751.py:28: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*args, **kwargs)\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[W 2025-11-08 14:14:00,311] Trial 0 failed with parameters: {'learning_rate': 3e-05, 'per_device_train_batch_size': 16, 'weight_decay': 0.0} because of the following error: TypeError(\"WeightedTrainer.compute_loss() got an unexpected keyword argument 'num_items_in_batch'\").\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\ivanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "                      ^^^^^^^^^^^\n",
            "  File \"C:\\Users\\ivanj\\AppData\\Local\\Temp\\ipykernel_38352\\81030449.py\", line 137, in objective\n",
            "    trainer_obj.train()\n",
            "  File \"c:\\Users\\ivanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py\", line 2325, in train\n",
            "    return inner_training_loop(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\ivanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py\", line 2674, in _inner_training_loop\n",
            "    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\ivanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py\", line 4020, in training_step\n",
            "    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "TypeError: WeightedTrainer.compute_loss() got an unexpected keyword argument 'num_items_in_batch'\n",
            "[W 2025-11-08 14:14:00,314] Trial 0 failed with value None.\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "WeightedTrainer.compute_loss() got an unexpected keyword argument 'num_items_in_batch'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 169\u001b[39m\n\u001b[32m    167\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== Hyperparameter search: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstrategy.upper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    168\u001b[39m study = optuna.create_study(direction=\u001b[33m\"\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m\"\u001b[39m, sampler=sampler)\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    171\u001b[39m strategy_records = []\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m tr \u001b[38;5;129;01min\u001b[39;00m study.trials:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ivanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\study.py:490\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    398\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ivanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     76\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ivanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     frozen_trial_id = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ivanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py:258\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    251\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    254\u001b[39m     updated_state == TrialState.FAIL\n\u001b[32m    255\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    256\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    257\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial._trial_id\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ivanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py:201\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    203\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    204\u001b[39m         state = TrialState.PRUNED\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 137\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m    135\u001b[39m trainer_obj, args = build_trainer_for_trial(hparams, run_name)\n\u001b[32m    136\u001b[39m start = time.time()\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m \u001b[43mtrainer_obj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m val_metrics = trainer_obj.evaluate()\n\u001b[32m    139\u001b[39m duration = time.time() - start\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ivanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:2325\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2323\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2324\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2326\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2327\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2328\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2329\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2330\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ivanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:2674\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2667\u001b[39m context = (\n\u001b[32m   2668\u001b[39m     functools.partial(\u001b[38;5;28mself\u001b[39m.accelerator.no_sync, model=model)\n\u001b[32m   2669\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i != \u001b[38;5;28mlen\u001b[39m(batch_samples) - \u001b[32m1\u001b[39m\n\u001b[32m   2670\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type != DistributedType.DEEPSPEED\n\u001b[32m   2671\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m contextlib.nullcontext\n\u001b[32m   2672\u001b[39m )\n\u001b[32m   2673\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m-> \u001b[39m\u001b[32m2674\u001b[39m     tr_loss_step = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2676\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2677\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2678\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m   2679\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch.isinf(tr_loss_step))\n\u001b[32m   2680\u001b[39m ):\n\u001b[32m   2681\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2682\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ivanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:4020\u001b[39m, in \u001b[36mTrainer.training_step\u001b[39m\u001b[34m(self, model, inputs, num_items_in_batch)\u001b[39m\n\u001b[32m   4017\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb.reduce_mean().detach().to(\u001b[38;5;28mself\u001b[39m.args.device)\n\u001b[32m   4019\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compute_loss_context_manager():\n\u001b[32m-> \u001b[39m\u001b[32m4020\u001b[39m     loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4022\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[32m   4023\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   4024\u001b[39m     \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4025\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.global_step % \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps == \u001b[32m0\u001b[39m\n\u001b[32m   4026\u001b[39m ):\n",
            "\u001b[31mTypeError\u001b[39m: WeightedTrainer.compute_loss() got an unexpected keyword argument 'num_items_in_batch'"
          ]
        }
      ],
      "source": [
        "import gc\n",
        "import time\n",
        "from optuna.samplers import GridSampler, RandomSampler\n",
        "\n",
        "AUTO_TUNE_ENABLED = True\n",
        "SEARCH_STRATEGIES = [\"grid\", \"random\"]\n",
        "GRID_SEARCH_SPACE = {\n",
        "    \"learning_rate\": [5e-5, 3e-5],\n",
        "    \"per_device_train_batch_size\": [8, 16],\n",
        "    \"weight_decay\": [0.0, 0.05],\n",
        "}\n",
        "RANDOM_SEARCH_SPACE = {\n",
        "    \"learning_rate\": (\"float_log\", 2e-5, 5e-5),\n",
        "    \"per_device_train_batch_size\": (\"choice\", [8, 16, 24]),\n",
        "    \"weight_decay\": (\"float\", 0.0, 0.1),\n",
        "    \"num_train_epochs\": (\"int\", 2, 3),\n",
        "}\n",
        "RANDOM_TRIALS = 6 if FAST_MODE else 10\n",
        "MAX_AUTOTUNE_EPOCHS = 2\n",
        "AUTO_TUNE_USE_CLASS_WEIGHTS = True\n",
        "\n",
        "TUNING_DIR = Path(\"tuning\")\n",
        "TUNING_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "if AUTO_TUNE_ENABLED:\n",
        "    class WeightedTrainer(Trainer):\n",
        "        def __init__(self, *args, class_weights=None, **kwargs):\n",
        "            super().__init__(*args, **kwargs)\n",
        "            self.class_weights = None\n",
        "            if class_weights is not None:\n",
        "                self.class_weights = torch.tensor(class_weights, dtype=torch.float32)\n",
        "\n",
        "        def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None, **kwargs):\n",
        "            labels = inputs.get('labels')\n",
        "            outputs = model(**{k: v for k, v in inputs.items() if k != 'labels'})\n",
        "            logits = outputs.get('logits')\n",
        "            if self.class_weights is None:\n",
        "                loss_fct = torch.nn.CrossEntropyLoss()\n",
        "            else:\n",
        "                loss_fct = torch.nn.CrossEntropyLoss(weight=self.class_weights.to(logits.device))\n",
        "            loss = loss_fct(logits.view(-1, model.config.num_labels), labels.view(-1))\n",
        "            return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "    globals()['WeightedTrainer'] = WeightedTrainer\n",
        "\n",
        "    cls_counts_auto = df_train['label'].value_counts().sort_index().reindex([0, 1, 2]).fillna(0).values.astype(np.float32)\n",
        "    class_weights_auto = (cls_counts_auto.sum() / (len(cls_counts_auto) * np.maximum(1.0, cls_counts_auto))).astype(np.float32)\n",
        "\n",
        "    def _clean_hp_dict(hp_dict):\n",
        "        cleaned = {}\n",
        "        for key, value in hp_dict.items():\n",
        "            if isinstance(value, (np.floating, float)):\n",
        "                cleaned[key] = float(value)\n",
        "            elif isinstance(value, (np.integer, int)):\n",
        "                cleaned[key] = int(value)\n",
        "            else:\n",
        "                cleaned[key] = value\n",
        "        return cleaned\n",
        "\n",
        "    def build_trainer_for_trial(hparams, run_name):\n",
        "        def model_init():\n",
        "            mdl = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=num_labels)\n",
        "            return mdl.to(device)\n",
        "\n",
        "        num_epochs = float(hparams.get(\"num_train_epochs\", MAX_AUTOTUNE_EPOCHS))\n",
        "        argnames_ta = set(inspect.signature(TrainingArguments.__init__).parameters.keys())\n",
        "        arg_kwargs = {\n",
        "            \"output_dir\": str(TUNING_DIR / run_name),\n",
        "            \"num_train_epochs\": num_epochs,\n",
        "            \"per_device_train_batch_size\": int(hparams[\"per_device_train_batch_size\"]),\n",
        "            \"per_device_eval_batch_size\": max(16, int(hparams[\"per_device_train_batch_size\"])),\n",
        "            \"learning_rate\": float(hparams[\"learning_rate\"]),\n",
        "            \"weight_decay\": float(hparams.get(\"weight_decay\", 0.0)),\n",
        "            \"logging_steps\": 50,\n",
        "            \"report_to\": [],\n",
        "            \"seed\": int(hparams.get(\"seed\", RANDOM_SEED)),\n",
        "            \"gradient_accumulation_steps\": 1,\n",
        "            \"dataloader_num_workers\": NUM_WORKERS,\n",
        "            \"dataloader_pin_memory\": PIN_MEMORY,\n",
        "            \"load_best_model_at_end\": False,\n",
        "        }\n",
        "        if \"warmup_steps\" in argnames_ta:\n",
        "            arg_kwargs[\"warmup_steps\"] = 0\n",
        "        elif \"warmup_ratio\" in argnames_ta:\n",
        "            arg_kwargs[\"warmup_ratio\"] = 0.0\n",
        "        if \"evaluation_strategy\" in argnames_ta:\n",
        "            arg_kwargs[\"evaluation_strategy\"] = \"no\"\n",
        "        elif \"eval_strategy\" in argnames_ta:\n",
        "            arg_kwargs[\"eval_strategy\"] = \"no\"\n",
        "        if \"save_strategy\" in argnames_ta:\n",
        "            arg_kwargs[\"save_strategy\"] = \"no\"\n",
        "        args = TrainingArguments(**{k: v for k, v in arg_kwargs.items() if k in argnames_ta})\n",
        "\n",
        "        callbacks = []\n",
        "        trainer_cls = WeightedTrainer if AUTO_TUNE_USE_CLASS_WEIGHTS else Trainer\n",
        "        trainer_obj = trainer_cls(\n",
        "            model_init=model_init,\n",
        "            args=args,\n",
        "            train_dataset=ds_train,\n",
        "            eval_dataset=ds_val,\n",
        "            compute_metrics=compute_metrics,\n",
        "            tokenizer=tokenizer,\n",
        "            callbacks=callbacks,\n",
        "            class_weights=(class_weights_auto if AUTO_TUNE_USE_CLASS_WEIGHTS else None)\n",
        "        )\n",
        "        return trainer_obj, args\n",
        "\n",
        "    def suggest_params(trial, strategy):\n",
        "        params = {}\n",
        "        if strategy == \"grid\":\n",
        "            for name, values in GRID_SEARCH_SPACE.items():\n",
        "                params[name] = trial.suggest_categorical(name, values)\n",
        "            params[\"num_train_epochs\"] = MAX_AUTOTUNE_EPOCHS\n",
        "        else:\n",
        "            for name, spec in RANDOM_SEARCH_SPACE.items():\n",
        "                kind = spec[0]\n",
        "                if kind == \"choice\":\n",
        "                    params[name] = trial.suggest_categorical(name, spec[1])\n",
        "                elif kind == \"float\":\n",
        "                    params[name] = trial.suggest_float(name, spec[1], spec[2])\n",
        "                elif kind == \"float_log\":\n",
        "                    params[name] = trial.suggest_float(name, spec[1], spec[2], log=True)\n",
        "                elif kind == \"int\":\n",
        "                    params[name] = trial.suggest_int(name, spec[1], spec[2])\n",
        "                else:\n",
        "                    raise ValueError(f\"Unsupported spec kind: {kind}\")\n",
        "        params[\"num_train_epochs\"] = float(params.get(\"num_train_epochs\", MAX_AUTOTUNE_EPOCHS))\n",
        "        params[\"num_train_epochs\"] = min(MAX_AUTOTUNE_EPOCHS, max(1, params[\"num_train_epochs\"]))\n",
        "        return params\n",
        "\n",
        "    summary_rows = []\n",
        "\n",
        "    def objective(trial):\n",
        "        hparams = suggest_params(trial, current_strategy)\n",
        "        run_name = f\"{current_strategy}_trial{trial.number}\"\n",
        "        trainer_obj, args = build_trainer_for_trial(hparams, run_name)\n",
        "        start = time.time()\n",
        "        trainer_obj.train()\n",
        "        val_metrics = trainer_obj.evaluate()\n",
        "        duration = time.time() - start\n",
        "\n",
        "        record = {\n",
        "            \"hyperparameters\": _clean_hp_dict(hparams),\n",
        "            \"val_accuracy\": float(val_metrics.get(\"eval_accuracy\", float(\"nan\"))),\n",
        "            \"val_f1_macro\": float(val_metrics.get(\"eval_f1_macro\", float(\"nan\"))),\n",
        "            \"train_time_sec\": duration,\n",
        "            \"output_dir\": args.output_dir,\n",
        "        }\n",
        "        trial.set_user_attr(\"record\", record)\n",
        "\n",
        "        # Cleanup to free memory\n",
        "        del trainer_obj\n",
        "        gc.collect()\n",
        "        if USE_GPU:\n",
        "            torch.cuda.empty_cache()\n",
        "        return record[\"val_f1_macro\"]\n",
        "\n",
        "    all_records = []\n",
        "    for strategy in SEARCH_STRATEGIES:\n",
        "        current_strategy = strategy\n",
        "        if strategy == \"grid\":\n",
        "            sampler = GridSampler(GRID_SEARCH_SPACE)\n",
        "            n_trials = int(np.prod([len(v) for v in GRID_SEARCH_SPACE.values()]))\n",
        "        else:\n",
        "            sampler = RandomSampler()\n",
        "            n_trials = RANDOM_TRIALS\n",
        "\n",
        "        print(f\"\\n=== Hyperparameter search: {strategy.upper()} ===\")\n",
        "        study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
        "        study.optimize(objective, n_trials=n_trials, show_progress_bar=False)\n",
        "\n",
        "        strategy_records = []\n",
        "        for tr in study.trials:\n",
        "            record = tr.user_attrs.get(\"record\")\n",
        "            if record:\n",
        "                rec = record.copy()\n",
        "                rec.update({\n",
        "                    \"strategy\": strategy,\n",
        "                    \"trial_number\": tr.number,\n",
        "                    \"state\": tr.state.name,\n",
        "                })\n",
        "                strategy_records.append(rec)\n",
        "                all_records.append(rec)\n",
        "\n",
        "        if strategy_records:\n",
        "            df_strategy = pd.DataFrame(strategy_records)\n",
        "            csv_path = TUNING_DIR / f\"{strategy}_trials.csv\"\n",
        "            df_strategy.to_csv(csv_path, index=False)\n",
        "            try:\n",
        "                df_strategy.to_excel(TUNING_DIR / f\"{strategy}_trials.xlsx\", index=False)\n",
        "            except Exception as exc:\n",
        "                print(f\"Excel export for {strategy} trials failed: {exc}\")\n",
        "        else:\n",
        "            print(f\"No successful trials recorded for {strategy}.\")\n",
        "\n",
        "        if study.best_trial is None:\n",
        "            continue\n",
        "\n",
        "        best_record = study.best_trial.user_attrs.get(\"record\")\n",
        "        if best_record is None:\n",
        "            continue\n",
        "\n",
        "        best_params = best_record[\"hyperparameters\"].copy()\n",
        "        best_run_name = f\"{strategy}_best\"\n",
        "        trainer_best, args_best = build_trainer_for_trial(best_params, best_run_name)\n",
        "        start = time.time()\n",
        "        trainer_best.train()\n",
        "        val_best = trainer_best.evaluate()\n",
        "        test_best = trainer_best.evaluate(eval_dataset=ds_test, metric_key_prefix=\"test\")\n",
        "        duration_best = time.time() - start\n",
        "\n",
        "        preds_test = trainer_best.predict(ds_test)\n",
        "        test_preds = np.argmax(preds_test.predictions, axis=1)\n",
        "        pd.DataFrame({\n",
        "            \"review\": df_test[\"review\"].tolist(),\n",
        "            \"gold\": df_test[\"label\"].tolist(),\n",
        "            \"pred\": test_preds,\n",
        "        }).to_csv(TUNING_DIR / f\"{strategy}_best_predictions.csv\", index=False)\n",
        "\n",
        "        row_log = {\n",
        "            \"member\": f\"auto-{strategy}\",\n",
        "            \"model\": MODEL_NAME,\n",
        "            \"num_train_epochs\": float(best_params.get(\"num_train_epochs\", MAX_AUTOTUNE_EPOCHS)),\n",
        "            \"per_device_train_batch_size\": int(best_params[\"per_device_train_batch_size\"]),\n",
        "            \"learning_rate\": float(best_params[\"learning_rate\"]),\n",
        "            \"weight_decay\": float(best_params.get(\"weight_decay\", 0.0)),\n",
        "            \"warmup_steps\": None,\n",
        "            \"lr_scheduler_type\": args_best.lr_scheduler_type,\n",
        "            \"gradient_accumulation_steps\": int(args_best.gradient_accumulation_steps),\n",
        "            \"max_seq_length\": MAX_LEN,\n",
        "            \"seed\": int(args_best.seed),\n",
        "            \"fp16\": bool(args_best.fp16),\n",
        "            \"accuracy\": float(val_best.get(\"eval_accuracy\", float(\"nan\"))),\n",
        "            \"f1_macro\": float(val_best.get(\"eval_f1_macro\", float(\"nan\"))),\n",
        "            \"test_accuracy\": float(test_best.get(\"test_accuracy\", float(\"nan\"))),\n",
        "            \"test_f1_macro\": float(test_best.get(\"test_f1_macro\", float(\"nan\"))),\n",
        "            \"training_time_min\": duration_best / 60.0,\n",
        "            \"notes\": f\"auto-{strategy} search (trials={len(strategy_records)})\",\n",
        "        }\n",
        "        pd.DataFrame([row_log]).to_csv(\n",
        "            \"runs_log.csv\",\n",
        "            mode=\"a\",\n",
        "            index=False,\n",
        "            header=not os.path.exists(\"runs_log.csv\")\n",
        "        )\n",
        "\n",
        "        summary_rows.append({\n",
        "            \"strategy\": strategy,\n",
        "            \"best_val_f1_macro\": study.best_value,\n",
        "            \"best_val_accuracy\": best_record[\"val_accuracy\"],\n",
        "            \"best_test_f1_macro\": test_best.get(\"test_f1_macro\", float(\"nan\")),\n",
        "            \"best_test_accuracy\": test_best.get(\"test_accuracy\", float(\"nan\")),\n",
        "            \"training_time_min\": duration_best / 60.0,\n",
        "            \"hyperparameters\": json.dumps(best_params),\n",
        "        })\n",
        "\n",
        "        del trainer_best\n",
        "        gc.collect()\n",
        "        if USE_GPU:\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    if all_records:\n",
        "        df_all_records = pd.DataFrame(all_records)\n",
        "        df_all_records.to_csv(TUNING_DIR / \"all_trials.csv\", index=False)\n",
        "        try:\n",
        "            df_all_records.to_excel(TUNING_DIR / \"all_trials.xlsx\", index=False)\n",
        "        except Exception as exc:\n",
        "            print(f\"Excel export for combined trials failed: {exc}\")\n",
        "\n",
        "    if summary_rows:\n",
        "        df_summary = pd.DataFrame(summary_rows)\n",
        "        summary_csv = TUNING_DIR / \"strategy_summary.csv\"\n",
        "        df_summary.to_csv(summary_csv, index=False)\n",
        "        try:\n",
        "            df_summary.to_excel(TUNING_DIR / \"strategy_summary.xlsx\", index=False)\n",
        "        except Exception as exc:\n",
        "            print(f\"Excel export for summary failed: {exc}\")\n",
        "        display(df_summary)\n",
        "    else:\n",
        "        print(\"Automated search finished, but no successful trials were completed.\")\n",
        "    # Prevent the legacy block further below from executing twice.\n",
        "    AUTO_TUNE_ENABLED = False\n",
        "else:\n",
        "    print(\"AUTO_TUNE_ENABLED is False; skipping automated hyperparameter search.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- Deprecated: superseded by the automated hyperparameter search block above. -->\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# (Legacy helper functions removed in favour of the new automated search block.)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- Legacy search block removed. -->\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tuning_records: list[dict] = []\n",
        "best_summaries: list[dict] = []\n",
        "\n",
        "\n",
        "def _sample_grid_params(trial: optuna.trial.Trial) -> dict:\n",
        "    params = {}\n",
        "    for name, values in GRID_SEARCH_SPACE.items():\n",
        "        params[name] = trial.suggest_categorical(name, values)\n",
        "    params.setdefault(\"per_device_eval_batch_size\", params[\"per_device_train_batch_size\"])\n",
        "    return params\n",
        "\n",
        "\n",
        "def _sample_random_params(trial: optuna.trial.Trial) -> dict:\n",
        "    params = {}\n",
        "    for name, spec in RANDOM_SEARCH_SPACE.items():\n",
        "        mode = spec[0]\n",
        "        if mode == \"choice\":\n",
        "            params[name] = trial.suggest_categorical(name, spec[1])\n",
        "        elif mode == \"uniform\":\n",
        "            params[name] = trial.suggest_float(name, spec[1], spec[2])\n",
        "        elif mode == \"log_uniform\":\n",
        "            params[name] = trial.suggest_float(name, spec[1], spec[2], log=True)\n",
        "        elif mode == \"int\":\n",
        "            params[name] = trial.suggest_int(name, spec[1], spec[2])\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported search spec '{mode}' for {name}\")\n",
        "    params.setdefault(\"per_device_eval_batch_size\", params[\"per_device_train_batch_size\"])\n",
        "    return params\n",
        "\n",
        "\n",
        "def _ensure_defaults(params: dict) -> dict:\n",
        "    \"\"\"Fill optional hyperparameters with sensible defaults.\"\"\"\n",
        "    params = params.copy()\n",
        "    params.setdefault(\"per_device_eval_batch_size\", params.get(\"per_device_train_batch_size\", EVAL_BATCH_SIZE))\n",
        "    params.setdefault(\"weight_decay\", 0.01)\n",
        "    params.setdefault(\"learning_rate\", 3e-5)\n",
        "    params.setdefault(\"num_train_epochs\", 3)\n",
        "    params.setdefault(\"warmup_ratio\", 0.1)\n",
        "    params.setdefault(\"gradient_accumulation_steps\", 1)\n",
        "    params.setdefault(\"logging_steps\", 50)\n",
        "    params.setdefault(\"lr_scheduler_type\", \"linear\")\n",
        "    params.setdefault(\"seed\", 42)\n",
        "    return params\n",
        "\n",
        "\n",
        "def _record_trial(strategy: str, trial: optuna.trial.Trial, params: dict, eval_metrics: dict, duration_min: float):\n",
        "    record = {\n",
        "        \"strategy\": strategy,\n",
        "        \"trial\": trial.number,\n",
        "        \"learning_rate\": params.get(\"learning_rate\"),\n",
        "        \"per_device_train_batch_size\": int(params.get(\"per_device_train_batch_size\", TRAIN_BATCH_SIZE)),\n",
        "        \"weight_decay\": params.get(\"weight_decay\"),\n",
        "        \"num_train_epochs\": int(params.get(\"num_train_epochs\", training_args.num_train_epochs)),\n",
        "        \"warmup_ratio\": params.get(\"warmup_ratio\", 0.1),\n",
        "        \"gradient_accumulation_steps\": int(params.get(\"gradient_accumulation_steps\", 1)),\n",
        "        \"val_accuracy\": eval_metrics.get(\"eval_accuracy\"),\n",
        "        \"val_f1_macro\": eval_metrics.get(\"eval_f1_macro\"),\n",
        "        \"val_loss\": eval_metrics.get(\"eval_loss\"),\n",
        "        \"train_time_min\": duration_min,\n",
        "    }\n",
        "    tuning_records.append(record)\n",
        "\n",
        "\n",
        "def _save_trial_history(strategy: str):\n",
        "    if not tuning_records:\n",
        "        return\n",
        "    strategy_df = pd.DataFrame([r for r in tuning_records if r[\"strategy\"] == strategy])\n",
        "    if strategy_df.empty:\n",
        "        return\n",
        "    out_dir = Path(\"exports\")\n",
        "    out_dir.mkdir(exist_ok=True)\n",
        "    csv_path = out_dir / f\"hparam_trials_{strategy}.csv\"\n",
        "    xlsx_path = out_dir / f\"hparam_trials_{strategy}.xlsx\"\n",
        "    strategy_df.to_csv(csv_path, index=False)\n",
        "    try:\n",
        "        strategy_df.to_excel(xlsx_path, index=False)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "\n",
        "def _append_runs_log(row: dict):\n",
        "    runs_path = Path(\"runs_log.csv\")\n",
        "    df_out = pd.DataFrame([row])\n",
        "    if runs_path.exists():\n",
        "        df_out.to_csv(runs_path, mode=\"a\", header=False, index=False)\n",
        "    else:\n",
        "        df_out.to_csv(runs_path, index=False)\n",
        "\n",
        "\n",
        "if AUTO_TUNE_ENABLED:\n",
        "    strategies = []\n",
        "    if GRID_SEARCH_SPACE:\n",
        "        strategies.append(\"grid\")\n",
        "    if RANDOM_SEARCH_SPACE and RANDOM_TRIALS > 0:\n",
        "        strategies.append(\"random\")\n",
        "\n",
        "    for strategy in strategies:\n",
        "        sampler = None\n",
        "        n_trials = None\n",
        "        if strategy == \"grid\":\n",
        "            sampler = optuna.samplers.GridSampler(GRID_SEARCH_SPACE)\n",
        "            n_trials = grid_search_size(GRID_SEARCH_SPACE)\n",
        "            sample_params = _sample_grid_params\n",
        "        else:\n",
        "            sampler = optuna.samplers.RandomSampler()\n",
        "            n_trials = RANDOM_TRIALS\n",
        "            sample_params = _sample_random_params\n",
        "\n",
        "        study = optuna.create_study(direction=\"maximize\", sampler=sampler, study_name=f\"{strategy}_search\")\n",
        "\n",
        "        def objective(trial: optuna.trial.Trial) -> float:\n",
        "            params = _ensure_defaults(sample_params(trial))\n",
        "            run_dir = tuning_root / strategy / f\"trial_{trial.number}\"\n",
        "            run_dir.mkdir(parents=True, exist_ok=True)\n",
        "            trainer = build_trainer_for_hparams(params, run_dir)\n",
        "            start = time.time()\n",
        "            trainer.train()\n",
        "            duration_min = (time.time() - start) / 60.0\n",
        "            eval_metrics = trainer.evaluate()\n",
        "            _record_trial(strategy, trial, params, eval_metrics, duration_min)\n",
        "            trial.set_user_attr(\"train_time_min\", duration_min)\n",
        "            trial.set_user_attr(\"eval_metrics\", eval_metrics)\n",
        "            # Explicitly release resources between trials\n",
        "            del trainer\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "            return eval_metrics.get(\"eval_f1_macro\", 0.0)\n",
        "\n",
        "        study.optimize(objective, n_trials=n_trials, show_progress_bar=False)\n",
        "        _save_trial_history(strategy)\n",
        "\n",
        "        best_params = _ensure_defaults(study.best_trial.params)\n",
        "        best_run_dir = tuning_root / strategy / \"best\"\n",
        "        best_run_dir.mkdir(parents=True, exist_ok=True)\n",
        "        best_trainer = build_trainer_for_hparams(best_params, best_run_dir)\n",
        "        best_start = time.time()\n",
        "        best_trainer.train()\n",
        "        best_duration_min = (time.time() - best_start) / 60.0\n",
        "        val_metrics = best_trainer.evaluate()\n",
        "        test_metrics = best_trainer.evaluate(eval_dataset=ds_test, metric_key_prefix=\"test\")\n",
        "\n",
        "        preds = best_trainer.predict(ds_test)\n",
        "        pred_labels = preds.predictions.argmax(axis=1)\n",
        "        prob_tensor = torch.softmax(torch.tensor(preds.predictions), dim=1).numpy()\n",
        "        predictions_df = pd.DataFrame({\n",
        "            \"review\": df_test['review'].tolist(),\n",
        "            \"gold\": df_test['label'].tolist(),\n",
        "            \"pred\": pred_labels.tolist(),\n",
        "            \"prob_neg\": prob_tensor[:, 0],\n",
        "            \"prob_neu\": prob_tensor[:, 1],\n",
        "            \"prob_pos\": prob_tensor[:, 2],\n",
        "        })\n",
        "        pred_path = Path(\"exports\") / f\"{strategy}_tuning_predictions_test.csv\"\n",
        "        predictions_df.to_csv(pred_path, index=False)\n",
        "\n",
        "        del best_trainer\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        best_summary = {\n",
        "            \"strategy\": strategy,\n",
        "            \"learning_rate\": best_params.get(\"learning_rate\"),\n",
        "            \"per_device_train_batch_size\": int(best_params.get(\"per_device_train_batch_size\", TRAIN_BATCH_SIZE)),\n",
        "            \"weight_decay\": best_params.get(\"weight_decay\"),\n",
        "            \"num_train_epochs\": int(best_params.get(\"num_train_epochs\", training_args.num_train_epochs)),\n",
        "            \"val_accuracy\": val_metrics.get(\"eval_accuracy\"),\n",
        "            \"val_f1_macro\": val_metrics.get(\"eval_f1_macro\"),\n",
        "            \"test_accuracy\": test_metrics.get(\"test_accuracy\"),\n",
        "            \"test_f1_macro\": test_metrics.get(\"test_f1_macro\"),\n",
        "            \"train_time_min\": best_duration_min,\n",
        "        }\n",
        "        best_summaries.append(best_summary)\n",
        "\n",
        "        log_row = {\n",
        "            \"member\": f\"auto-{strategy}\",\n",
        "            \"model\": MODEL_NAME,\n",
        "            \"num_train_epochs\": best_summary[\"num_train_epochs\"],\n",
        "            \"per_device_train_batch_size\": best_summary[\"per_device_train_batch_size\"],\n",
        "            \"learning_rate\": best_summary[\"learning_rate\"],\n",
        "            \"weight_decay\": best_summary[\"weight_decay\"],\n",
        "            \"warmup_steps\": None,\n",
        "            \"lr_scheduler_type\": \"linear\",\n",
        "            \"gradient_accumulation_steps\": 1,\n",
        "            \"max_seq_length\": MAX_LEN,\n",
        "            \"seed\": 42,\n",
        "            \"fp16\": USE_FP16,\n",
        "            \"accuracy\": best_summary[\"val_accuracy\"],\n",
        "            \"f1_macro\": best_summary[\"val_f1_macro\"],\n",
        "            \"notes\": f\"Automated {strategy} search (best)\"\n",
        "        }\n",
        "        _append_runs_log(log_row)\n",
        "\n",
        "    # Persist combined trial history and summaries\n",
        "    if tuning_records:\n",
        "        all_trials_df = pd.DataFrame(tuning_records)\n",
        "        out_dir = Path(\"exports\")\n",
        "        out_dir.mkdir(exist_ok=True)\n",
        "        all_trials_df.to_csv(out_dir / \"hparam_trials_all.csv\", index=False)\n",
        "        try:\n",
        "            all_trials_df.to_excel(out_dir / \"hparam_trials_all.xlsx\", index=False)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    if best_summaries:\n",
        "        summary_df = pd.DataFrame(best_summaries)\n",
        "        out_dir = Path(\"exports\")\n",
        "        out_dir.mkdir(exist_ok=True)\n",
        "        summary_df.to_csv(out_dir / \"Hyperparameter_Strategy_Comparison.csv\", index=False)\n",
        "        try:\n",
        "            summary_df.to_excel(out_dir / \"Hyperparameter_Strategy_Comparison.xlsx\", index=False)\n",
        "        except Exception:\n",
        "            pass\n",
        "        display(summary_df)\n",
        "else:\n",
        "    print(\"AUTO_TUNE_ENABLED is False - skipping automated searches\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzQvyLLRG6KH"
      },
      "source": [
        "# **Fast-mode bootstrap for quick sweeps**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thTkK_iBDqrM"
      },
      "source": [
        "**`Purpose`**\n",
        "\n",
        "This block prepares a quick sweep mode that reduces run time while preserving the validation set. It defines default values for epochs, batch size, and evaluation steps if they are missing, creates a smaller training subset, and optionally attaches early stopping. The intent is to identify promising settings rapidly before running a full configuration.\n",
        "\n",
        "**`Input`**\n",
        "\n",
        "Inputs are the full tokenized training and validation datasets along with optional global variables for the number of epochs, batch size, and evaluation interval. No changes are made to the validation set so that results remain comparable.\n",
        "\n",
        "**`Output`**\n",
        "\n",
        "The block prints a short summary line that shows the chosen values for epochs, batch size, evaluation steps, and the size of the reduced training subset. These values explain why later training progress appears shorter and help distinguish a sweep run from a full run.\n",
        "\n",
        "**`Details`**\n",
        "\n",
        "A fraction of the training set is selected to form a smaller dataset while leaving the validation set intact. A callback for early stopping is attached when available so the loop can halt once improvement stalls. The printed message confirms the configuration and the subset size so that log viewers can interpret run time and scores in context.\n",
        "\n",
        "\n",
        "**`Line-by-line Description`**\n",
        "\n",
        "`from transformers import EarlyStoppingCallback` is imported when available to stop training when validation does not improve.\n",
        "\n",
        "`FAST_TRAIN = False` sets the default to full training unless quick sweeps are desired.\n",
        "\n",
        "`TRAIN_FRACTION`, `NEW_MAX_LEN`, `EPOCHS`, `BATCH`, and `EVAL_STEPS` define compact settings that shorten training and evaluation cycles.\n",
        "\n",
        "The `if FAST_TRAIN:` branch selects a prefix of the training dataset with `ds_train.select(range(n))`, leaving the validation data untouched.\n",
        "\n",
        "`overrides = dict(...)` sets fewer epochs, a larger batch, zero warmup, evaluation every fixed number of steps, and a shorter logging interval so progress is visible without heavy overhead.\n",
        "\n",
        "`fast_args = make_training_args(**overrides)` rebuilds the training arguments specifically for fast mode.\n",
        "\n",
        "`callbacks = [EarlyStoppingCallback(...)] if HAVE_ES else None` attaches a simple stopping rule when supported.\n",
        "\n",
        "`trainer = Trainer(model=model, args=fast_args, train_dataset=ds_train_fast, ...)` re-instantiates the trainer to use the fast subsets.\n",
        "\n",
        "The final `print` statement reports the reduced training size so the reader knows this run is a sweep.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-z3wCGgYW7k",
        "outputId": "b067db1e-b49d-427a-9ff9-0e5fcd196116"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[BOOTSTRAP] EPOCHS=1, BATCH=32, EVAL_STEPS=200, train_fast=939 / 2348\n"
          ]
        }
      ],
      "source": [
        "import math, numpy as np\n",
        "from transformers import Trainer\n",
        "\n",
        "EPOCHS = globals().get('EPOCHS', 1)\n",
        "BATCH = globals().get('BATCH', 32)\n",
        "EVAL_STEPS = globals().get('EVAL_STEPS', 200)\n",
        "TRAIN_FRACTION = globals().get('TRAIN_FRACTION', 0.20)\n",
        "\n",
        "if 'ds_train_fast' not in globals():\n",
        "    assert 'ds_train' in globals() and 'ds_val' in globals(), \"Need ds_train/ds_val first.\"\n",
        "    n_fast = max(8, int(len(ds_train) * TRAIN_FRACTION))\n",
        "    ds_train_fast = ds_train.select(range(n_fast))\n",
        "    ds_val_fast = ds_val\n",
        "\n",
        "callbacks = globals().get('callbacks', None)\n",
        "if callbacks is None:\n",
        "    try:\n",
        "        from transformers import EarlyStoppingCallback\n",
        "        callbacks = [EarlyStoppingCallback(early_stopping_patience=1)]\n",
        "    except Exception:\n",
        "        callbacks = None\n",
        "\n",
        "print(f\"[BOOTSTRAP] EPOCHS={EPOCHS}, BATCH={BATCH}, EVAL_STEPS={EVAL_STEPS}, \"\n",
        "      f\"train_fast={len(ds_train_fast)} / {len(ds_train)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dzl1-YjqG1Vs"
      },
      "source": [
        "# **Train, evaluate, save, and append to the run log**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TasFTWZhDwf-"
      },
      "source": [
        "**`Purpose`**\n",
        "\n",
        "This block performs the actual fine-tuning, evaluates on the validation split, saves the trained checkpoint and tokenizer for later use, and writes a structured record of the run to the experiment log. It captures both on-screen feedback and durable artifacts needed for reporting and replication.\n",
        "\n",
        "**`Input`**\n",
        "\n",
        "Inputs include the Trainer instance, which encapsulates the model, datasets, and arguments. The training arguments determine the number of epochs, batch sizes, learning rate, and scheduling behavior. No additional inputs are required once the trainer has been built.\n",
        "\n",
        "**`Output`**\n",
        "\n",
        "The cell prints the evaluation dictionary containing accuracy and macro-F1, writes the model and tokenizer to a versioned folder named after the backbone, and appends a new row to runs_log.csv that contains the hyperparameters, scores, and a note string. These outputs provide both a human-readable summary and a machine-readable record.\n",
        "\n",
        "**`Details`**\n",
        "\n",
        "The call to train() runs the optimization loop and tracks progress according to the evaluation strategy. The call to evaluate() computes metrics on the fixed validation set using the same metric function defined earlier. The model and tokenizer are saved together so that future inference uses the exact same text processing. A dictionary is assembled with the run configuration and evaluation scores, then written as a new log row with consistent column names to support later aggregation and sorting.\n",
        "\n",
        "**`Line-by-line Description`**\n",
        "\n",
        "`train_out = trainer.train()` runs the optimization loop and shows progress updates and evaluation checkpoints as configured.\n",
        "\n",
        "`eval_results = trainer.evaluate()` computes macro-F1 and accuracy on the validation set using the shared metric function.\n",
        "\n",
        "`print('Eval:', eval_results)` surfaces the summary in the notebook output for quick inspection.\n",
        "\n",
        "`save_dir = f\\\"./finetuned_{MODEL_NAME.replace('/','_')}_best\\\"` constructs a folder name that is safe for filesystems.\n",
        "\n",
        "`trainer.save_model(save_dir)` and `tokenizer.save_pretrained(save_dir)` write the necessary artifacts for future use.\n",
        "\n",
        "The `row = {...}` dictionary collects hyperparameters and scores, and the `with open('runs_log.csv','a',...)` block appends the record, adding headers if the file is new.\n",
        "\n",
        "`print('Logged:', row['model'])` confirms that the run has been recorded.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "GvP-1u1sZMv1",
        "outputId": "a4db4a13-d6f7-409c-af20-fbaa98acb821"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "Starting training...\n",
            "============================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='58' max='882' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 58/882 11:40 < 2:51:43, 0.08 it/s, Epoch 0.19/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import time\n",
        "print(\"=\" * 60)\n",
        "print(\"Starting training...\")\n",
        "if USE_GPU:\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Memory before training: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "start_time = time.time()\n",
        "train_out = trainer.train()\n",
        "training_time = time.time() - start_time\n",
        "\n",
        "print(f\"\\n✓ Training completed in {training_time/60:.2f} minutes\")\n",
        "\n",
        "# Evaluate on validation\n",
        "eval_results = trainer.evaluate()\n",
        "print(\"\\nValidation Results:\")\n",
        "print(f\"  Accuracy: {eval_results.get('eval_accuracy', 0):.4f}\")\n",
        "print(f\"  F1 Macro: {eval_results.get('eval_f1_macro', 0):.4f}\")\n",
        "\n",
        "# Evaluate on test set\n",
        "if 'ds_test' in globals() and len(ds_test) > 0:\n",
        "    print(\"\\nEvaluating on test set...\")\n",
        "    test_results = trainer.evaluate(eval_dataset=ds_test, metric_key_prefix=\"test\")\n",
        "    print(\"Test Results:\")\n",
        "    print(f\"  Accuracy: {test_results.get('test_accuracy', 0):.4f}\")\n",
        "    print(f\"  F1 Macro: {test_results.get('test_f1_macro', 0):.4f}\")\n",
        "else:\n",
        "    test_results = {}\n",
        "\n",
        "if USE_GPU:\n",
        "    print(f\"\\nGPU Memory after training: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n",
        "\n",
        "# Save best model\n",
        "save_dir = f\"./checkpoints/{MODEL_CHOICE}/best\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "trainer.save_model(save_dir)\n",
        "tokenizer.save_pretrained(save_dir)\n",
        "print(f\"\\n✓ Model saved to: {save_dir}\")\n",
        "\n",
        "# Log results\n",
        "row = {\n",
        "    \"member\": \"team\",\n",
        "    \"model\": MODEL_NAME,\n",
        "    \"num_train_epochs\": float(getattr(training_args, \"num_train_epochs\", np.nan)),\n",
        "    \"per_device_train_batch_size\": int(getattr(training_args, \"per_device_train_batch_size\", np.nan)),\n",
        "    \"learning_rate\": float(getattr(training_args, \"learning_rate\", np.nan)),\n",
        "    \"weight_decay\": float(getattr(training_args, \"weight_decay\", np.nan)),\n",
        "    \"warmup_steps\": None,\n",
        "    \"warmup_ratio\": float(getattr(training_args, \"warmup_ratio\", np.nan)),\n",
        "    \"lr_scheduler_type\": str(getattr(training_args, \"lr_scheduler_type\", \"\")),\n",
        "    \"gradient_accumulation_steps\": int(getattr(training_args, \"gradient_accumulation_steps\", np.nan)),\n",
        "    \"max_seq_length\": MAX_LEN,\n",
        "    \"seed\": int(getattr(training_args, \"seed\", 42)),\n",
        "    \"fp16\": USE_FP16,\n",
        "    \"accuracy\": float(eval_results.get(\"eval_accuracy\", np.nan)),\n",
        "    \"f1_macro\": float(eval_results.get(\"eval_f1_macro\", np.nan)),\n",
        "    \"test_accuracy\": float(test_results.get(\"test_accuracy\", np.nan)) if test_results else np.nan,\n",
        "    \"test_f1_macro\": float(test_results.get(\"test_f1_macro\", np.nan)) if test_results else np.nan,\n",
        "    \"training_time_min\": training_time / 60,\n",
        "    \"notes\": f\"GPU-optimized; batch_size={TRAIN_BATCH_SIZE}; early_stop=2\"\n",
        "}\n",
        "pd.DataFrame([row]).to_csv(\"runs_log.csv\", mode=\"a\",\n",
        "                           index=False, header=not os.path.exists(\"runs_log.csv\"))\n",
        "print(\"✓ Results logged to runs_log.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'model': 'tfidf-logreg', 'accuracy': 0.803133514986376, 'f1_macro': 0.8057244174688569}\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using model: xlm-roberta-base\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7eaaec20b70143ac9f4e868c38f38868",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/5872 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2263361c4ee24175bb5b358b499e02ba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1468 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trainer ready on: xlm-roberta-base\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-139214311.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[BOOTSTRAP] EPOCHS=1, BATCH=32, EVAL_STEPS=200, train_fast=1174 / 5872\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='368' max='1101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 368/1101 2:27:45 < 4:55:56, 0.04 it/s, Epoch 1/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='32' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [32/46 06:51 < 03:05, 0.08 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ang bilis ng delivery, pero sira yung box.\n",
            " -> {'label': 'LABEL_0', 'score': 0.4898853600025177}\n",
            "\n",
            "solid yung quality, sakto ang size. sulit!\n",
            " -> {'label': 'LABEL_2', 'score': 0.7228704690933228}\n",
            "\n",
            "medyo pangit yung tela, tapos delay pa courier :(\n",
            " -> {'label': 'LABEL_0', 'score': 0.5115751624107361}\n",
            "\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_report\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05678303789950534,\n        \"min\": 0.48598130841121495,\n        \"max\": 0.6584564860426929,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.5348837209302325,\n          0.48598130841121495,\n          0.5584680822377985\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.21251741358066809,\n        \"min\": 0.20392156862745098,\n        \"max\": 0.8319502074688797,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.20392156862745098,\n          0.5868872306875724,\n          0.8319502074688797\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1-score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14731852235496515,\n        \"min\": 0.287292817679558,\n        \"max\": 0.7351054078826764,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.6155218554861731,\n          0.287292817679558,\n          0.5407551408906287\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"support\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 599.2766104873285,\n        \"min\": 0.5790190735694822,\n        \"max\": 1468.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          510.0,\n          1468.0,\n          482.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_report"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-f34d6eb0-9c78-4fe7-bfaa-67d34ea39d6a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>support</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>negative</th>\n",
              "      <td>0.534884</td>\n",
              "      <td>0.724790</td>\n",
              "      <td>0.615522</td>\n",
              "      <td>476.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>0.485981</td>\n",
              "      <td>0.203922</td>\n",
              "      <td>0.287293</td>\n",
              "      <td>510.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>0.658456</td>\n",
              "      <td>0.831950</td>\n",
              "      <td>0.735105</td>\n",
              "      <td>482.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>accuracy</th>\n",
              "      <td>0.579019</td>\n",
              "      <td>0.579019</td>\n",
              "      <td>0.579019</td>\n",
              "      <td>0.579019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>macro avg</th>\n",
              "      <td>0.559774</td>\n",
              "      <td>0.586887</td>\n",
              "      <td>0.545973</td>\n",
              "      <td>1468.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weighted avg</th>\n",
              "      <td>0.558468</td>\n",
              "      <td>0.579019</td>\n",
              "      <td>0.540755</td>\n",
              "      <td>1468.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f34d6eb0-9c78-4fe7-bfaa-67d34ea39d6a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f34d6eb0-9c78-4fe7-bfaa-67d34ea39d6a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f34d6eb0-9c78-4fe7-bfaa-67d34ea39d6a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d2c3046f-9af6-4aac-868c-175f3ce36f54\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d2c3046f-9af6-4aac-868c-175f3ce36f54')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d2c3046f-9af6-4aac-868c-175f3ce36f54 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_d24ed1c1-eebd-468f-90e2-94334b82b883\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_report')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d24ed1c1-eebd-468f-90e2-94334b82b883 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_report');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "              precision    recall  f1-score      support\n",
              "negative       0.534884  0.724790  0.615522   476.000000\n",
              "neutral        0.485981  0.203922  0.287293   510.000000\n",
              "positive       0.658456  0.831950  0.735105   482.000000\n",
              "accuracy       0.579019  0.579019  0.579019     0.579019\n",
              "macro avg      0.559774  0.586887  0.545973  1468.000000\n",
              "weighted avg   0.558468  0.579019  0.540755  1468.000000"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exported logs to exports/.\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOYlxuQqGxnp"
      },
      "source": [
        "# **Inference sanity check with a small pipeline**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGmm4xUyD4oF"
      },
      "source": [
        "**`Purpose`**\n",
        "\n",
        "This block performs a quick, human-readable check that the saved model can process fresh text and return reasonable labels. It creates a simple text-classification pipeline and runs a few short sentences through it to confirm label behavior. This step helps validate that training produced a usable artifact.\n",
        "\n",
        "**`Input`**\n",
        "\n",
        "The inputs are the saved model and tokenizer from the previous step and a small list of short review sentences that represent common positive, neutral, and negative tones. The device is chosen automatically based on GPU availability to keep the call simple.\n",
        "\n",
        "**`Output`**\n",
        "\n",
        "The code prints each input sentence followed by the predicted label and a confidence score. These lines provide a quick visual confirmation that positive lines map to positive labels and complaint-style text maps to negative labels, with neutral sitting in between.\n",
        "\n",
        "**`Details`**\n",
        "\n",
        "A pipeline wrapper loads the classification head and tokenizer and applies them to each sample string. The outputs are dictionaries containing the predicted label index and score. The format is concise and easy to read, which makes it suitable for inclusion in a report as a small qualitative check beside the quantitative metrics.\n",
        "\n",
        "**`Line-by-line Description`**\n",
        "\n",
        "`from transformers import pipeline` imports the high-level inference interface.\n",
        "\n",
        "`clf = pipeline('text-classification', model=save_dir, tokenizer=tokenizer, device=0 if torch.cuda.is_available() else -1)` loads the saved classifier and sets the device index for GPU or CPU.\n",
        "\n",
        "`samples = [...]` prepares a short list of example sentences that cover different sentiments.\n",
        "\n",
        "`for t, p in zip(samples, clf(samples)):` iterates over inputs and predictions together to print a clean pairing.\n",
        "\n",
        "`print(t, '->', p)` produces human-readable lines that show the predicted label and score for each sample."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ed6AdjXcilJO",
        "outputId": "b0d50c82-87c3-4393-90b3-80a473a5609a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ang bilis ng delivery, pero sira yung box.\n",
            " -> {'label': 'LABEL_0', 'score': 0.4898853600025177}\n",
            "\n",
            "solid yung quality, sakto ang size. sulit!\n",
            " -> {'label': 'LABEL_2', 'score': 0.7228704690933228}\n",
            "\n",
            "medyo pangit yung tela, tapos delay pa courier :(\n",
            " -> {'label': 'LABEL_0', 'score': 0.5115751624107361}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "sentiment_analyzer = pipeline(\n",
        "    \"text-classification\", model=model, tokenizer=tokenizer, device=0 if torch.cuda.is_available() else -1\n",
        ")\n",
        "\n",
        "samples = [\n",
        "    \"Ang bilis ng delivery, pero sira yung box.\",\n",
        "    \"solid yung quality, sakto ang size. sulit!\",\n",
        "    \"medyo pangit yung tela, tapos delay pa courier :(\"\n",
        "]\n",
        "preds = sentiment_analyzer(samples)\n",
        "for t, r in zip(samples, preds):\n",
        "    print(f\"{t}\\n -> {r}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xx7vWRVrGsDF"
      },
      "source": [
        "# **Confusion matrix and per-class report**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jSu0hb3D-6f"
      },
      "source": [
        "**`Purpose`**\n",
        "\n",
        "This block explains where the model succeeds and where it struggles by producing a confusion matrix and a per-class table. It complements the single macro-F1 score with a breakdown across negative, neutral, and positive classes, which supports targeted analysis of errors.\n",
        "\n",
        "**`Input`**\n",
        "\n",
        "The inputs are the validation dataset and the trained model encapsulated by the trainer. Predictions are obtained as raw scores, which are converted to class labels before building the matrix and the report.\n",
        "\n",
        "**`Output`**\n",
        "\n",
        "The block displays a color-mapped confusion matrix with counts for each true–predicted pair and prints a classification report that includes precision, recall, and F1 per class, plus macro and weighted averages. These outputs make it easy to identify common confusions, such as neutral being mistaken for positive or negative.\n",
        "\n",
        "**`Details`**\n",
        "\n",
        "The trainer produces predictions and gold labels, which are turned into a confusion matrix using a fixed label order so the axes are stable across runs. The figure is annotated with counts for clarity. The classification report quantifies performance for each class, and the macro averages summarize balance across classes. The combination of figure and table supports discussion of error sources and improvements from hyperparameter changes.\n",
        "\n",
        "**`Line-by-line Description`**\n",
        "\n",
        "`import matplotlib.pyplot as plt` brings in plotting functions for the confusion matrix.\n",
        "\n",
        "`from sklearn.metrics import confusion_matrix, classification_report` imports evaluation tools for structured summaries.\n",
        "\n",
        "`pred = trainer.predict(ds_val)` gathers raw predictions and gold labels in one call.\n",
        "\n",
        "`y_true = pred.label_ids` extracts the ground truth, and `y_pred = np.argmax(pred.predictions, axis=1)` converts scores to label indices.\n",
        "\n",
        "`cm = confusion_matrix(y_true, y_pred, labels=[0,1,2])` builds the matrix with a stable label order.\n",
        "\n",
        "The next group of lines creates a figure, renders the matrix, sets axis titles and tick names, and writes counts into each cell for clarity.\n",
        "\n",
        "`report = classification_report(..., output_dict=True)` computes per-class precision, recall, and F1 plus macro and weighted averages.\n",
        "\n",
        "`pd.DataFrame(report).transpose()` presents the report as a table that can be sorted or exported if needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762
        },
        "id": "YndcMJ2Bio64",
        "outputId": "b05592a1-b82a-402e-fc4a-1f889f9eb88f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcsAAAHWCAYAAAAYSqICAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAPUxJREFUeJzt3Xd4VGXexvF7UmbSC0kgCYQAAjGhilgwCkGanbKi2CgrKoqKIoq8ylIEeWVVZHEV1F2JiKwdWUWliaAgVYqAdKQEDCW9l+f9g5fRMYETJMkE8v1cF9fFeZ7nnPM7M5m557QZmzHGCAAAnJaHuwsAAKCmIywBALBAWAIAYIGwBADAAmEJAIAFwhIAAAuEJQAAFghLAAAsEJYAAFggLIEz2Llzp7p3767g4GDZbDbNnTu3Upe/b98+2Ww2zZw5s1KXez5LSkpSUlJSpS7zwIED8vHx0ffff1+py/29mTNnymazad++fc62K6+8Uk899VSVrRPVh7BEjbd792498MADatKkiXx8fBQUFKTExERNnTpVeXl5VbruAQMGaPPmzZo4caJmzZql9u3bV+n6qtPAgQNls9kUFBRU7uO4c+dO2Ww22Ww2vfjii2e9/JSUFI0dO1YbNmyohGrPzfjx43XFFVcoMTFRRUVFCg8P19VXX33a8cYYxcTEqF27due03pEjR+qf//ynjhw5ck7Lgft5ubsA4Ey++OIL9e3bVw6HQ/3791fLli1VWFio7777Tk8++aS2bNmiN954o0rWnZeXp5UrV+qZZ57Rww8/XCXriI2NVV5enry9vatk+Va8vLyUm5ur//73v7rttttc+mbPni0fHx/l5+f/qWWnpKRo3LhxatSokdq2bVvh+RYsWPCn1nc6R48eVXJyspKTkyVJ3t7e6tu3r2bMmKFffvlFsbGxZeZZtmyZDh48qMcff/yc1t2zZ08FBQXptdde0/jx489pWXAv9ixRY+3du1f9+vVTbGystm7dqqlTp+q+++7T0KFDNWfOHG3dulUtWrSosvUfPXpUkhQSElJl67DZbPLx8ZGnp2eVreNMHA6HunTpojlz5pTpe++993TjjTdWWy25ubmSJLvdLrvdXmnLfffdd+Xl5aWbb77Z2XbXXXfJGFPudksnt93Dw0P9+vU7p3V7eHjo1ltv1TvvvCN+s+I8Z4AaasiQIUaS+f777ys0vqioyIwfP940adLE2O12Exsba0aNGmXy8/NdxsXGxpobb7zRLF++3Fx22WXG4XCYxo0bm+TkZOeYMWPGGEku/2JjY40xxgwYMMD5/987Nc/vLViwwCQmJprg4GDj7+9vmjdvbkaNGuXs37t3r5Fk3n77bZf5Fi9ebK6++mrj5+dngoODzS233GK2bt1a7vp27txpBgwYYIKDg01QUJAZOHCgycnJsXy8BgwYYPz9/c3MmTONw+EwaWlpzr7Vq1cbSebjjz82kszf//53Z9/x48fNE088YVq2bGn8/f1NYGCgue6668yGDRucY7755psyj9/vt7NTp06mRYsWZu3ateaaa64xvr6+ZtiwYc6+Tp06OZfVv39/43A4ymx/9+7dTUhIiDl06NAZt7Njx44mKSnJpa20tNQ0atTItGrVqsz4wsJCU6dOHdOlSxdjjDEbN240AwYMMI0bNzYOh8PUq1fPDBo0yBw7dsxlvrfffttIMnv37nVp/+yzz4wks379+jPWiZqNPUvUWP/973/VpEkTXXXVVRUaP3jwYP3tb39Tu3btNGXKFHXq1EmTJk0qd+9g165duvXWW9WtWze99NJLCg0N1cCBA7VlyxZJUp8+fTRlyhRJ0h133KFZs2bplVdeOav6t2zZoptuukkFBQUaP368XnrpJd1yyy2WF5ksWrRIPXr0UGpqqsaOHavhw4drxYoVSkxMdLl45JTbbrtNWVlZmjRpkm677TbNnDlT48aNq3Cdffr0kc1m0yeffOJse++993TxxReXe85uz549mjt3rm666Sa9/PLLevLJJ7V582Z16tRJKSkpkqT4+HjnYcf7779fs2bN0qxZs9SxY0fnco4fP67rr79ebdu21SuvvKLOnTuXW9/UqVMVERGhAQMGqKSkRJI0Y8YMLViwQNOmTVN0dPRpt62oqEhr1qwpsx02m0133nmnNm/e7HzOT/nqq6904sQJ3XXXXZKkhQsXas+ePRo0aJCmTZumfv366T//+Y9uuOGGCu0tXnrppZJUpRcXoRq4O62B8mRkZBhJpmfPnhUav2HDBiPJDB482KV9xIgRRpJZsmSJsy02NtZIMsuWLXO2paamGofDYZ544gln26m9vt/vVRlT8T3LKVOmGEnm6NGjp627vD3Ltm3bmrp165rjx4872zZu3Gg8PDxM//79y6zvr3/9q8sye/fubcLCwk67zt9vh7+/vzHGmFtvvdW5J1VSUmIiIyPNuHHjyn0M8vPzTUlJSZntcDgcZvz48c62NWvWlLvXbMzJvUdJZvr06eX2/X7P0hhjvv76ayPJTJgwwezZs8cEBASYXr16WW7jrl27jCQzbdq0Mn1btmwxklz29I0xpl+/fsbHx8dkZGQYY4zJzc0tM++cOXPK/A2dbs/SGGPsdrt58MEHLetFzcWeJWqkzMxMSVJgYGCFxs+fP1+SNHz4cJf2J554QtLJC4V+LyEhQddcc41zOiIiQnFxcdqzZ8+frvmPTp3r/Oyzz1RaWlqheQ4fPqwNGzZo4MCBqlOnjrO9devW6tatm3M7f2/IkCEu09dcc42OHz/ufAwr4s4779TSpUt15MgRLVmyREeOHNGdd95Z7liHwyEPj5NvHSUlJTp+/LgCAgIUFxen9evXV3idDodDgwYNqtDY7t2764EHHtD48ePVp08f+fj4aMaMGZbzHT9+XJIUGhpapi8hIUGXXHKJ/vOf/zjbcnJyNG/ePN10000KCgqSJPn6+jr78/PzdezYMV155ZWSVOHtDQ0N1bFjxyo0FjUTYYka6dQbVVZWVoXG//LLL/Lw8FDTpk1d2iMjIxUSEqJffvnFpb1hw4ZllhEaGqq0tLQ/WXFZt99+uxITEzV48GDVq1dP/fr10wcffHDG4DxVZ1xcXJm++Ph4HTt2TDk5OS7tf9yWU8FwNttyww03KDAwUO+//75mz56tyy67rMxjeUppaammTJmiZs2ayeFwKDw8XBEREdq0aZMyMjIqvM769euf1YU8L774ourUqaMNGzboH//4h+rWrVvhec1pDpfedddd2rt3r1asWCFJmjt3rnJzc52HYCXpxIkTGjZsmOrVqydfX19FRESocePGklTh7TXGyGazVbhe1DyEJWqkoKAgRUdH66effjqr+Sr6hnS6q09P96ZakXWcOp92iq+vr5YtW6ZFixbpnnvu0aZNm3T77berW7duZcaei3PZllMcDof69Omj5ORkffrpp6fdq5Sk559/XsOHD1fHjh317rvv6uuvv9bChQvVokWLCu9BS657bBXx448/KjU1VZK0efPmCs0TFhYm6fQfHO644w55eHjovffek3TyXG1oaKhuuOEG55jbbrtNb775poYMGaJPPvlECxYs0FdffSVJFd7e9PR0hYeHV2gsaibCEjXWTTfdpN27d2vlypWWY2NjY1VaWqqdO3e6tP/6669KT08v9166Pys0NFTp6ell2v+49yqdvHWgS5cuevnll7V161ZNnDhRS5Ys0TfffFPusk/VuX379jJ9P//8s8LDw+Xv739uG3Aad955p3788UdlZWWd8ZaJjz76SJ07d9a//vUv9evXT927d1fXrl3LPCaVuSeVk5OjQYMGKSEhQffff78mT56sNWvWWM7XsGFD+fr6au/eveX2R0dHq3Pnzvrwww/166+/auHChbr11lude7xpaWlavHixnn76aY0bN069e/dWt27d1KRJkwrXfujQIRUWFio+Pr7C86DmISxRYz311FPy9/fX4MGD9euvv5bp3717t6ZOnSpJzj2BP16x+vLLL0tSpd4veNFFFykjI0ObNm1yth0+fFiffvqpy7gTJ06UmffUzfkFBQXlLjsqKkpt27ZVcnKyS/j89NNPWrBggcseT2Xr3LmznnvuOb366quKjIw87ThPT88ye60ffvihDh065NJ2KtTL+2BxtkaOHKn9+/crOTlZL7/8sho1aqQBAwac9nE8xdvbW+3bt9fatWtPO+auu+5SamqqHnjgARUVFbkcgj211/7H7T2bK6PXrVsnSRW+qhs1E9/ggxrroosu0nvvvafbb79d8fHxLt/gs2LFCn344YcaOHCgJKlNmzYaMGCA3njjDaWnp6tTp05avXq1kpOT1atXr9PelvBn9OvXTyNHjlTv3r316KOPKjc3V6+//rqaN2/ucsHH+PHjtWzZMt14442KjY1VamqqXnvtNTVo0OCMX7X297//Xddff706dOige++9V3l5eZo2bZqCg4M1duzYStuOP/Lw8NCzzz5rOe6mm27S+PHjNWjQIF111VXavHmzZs+eXWZv66KLLlJISIimT5+uwMBA+fv764orrnCe76uoJUuW6LXXXtOYMWOct4C8/fbbSkpK0ujRozV58uQzzt+zZ08988wzyszMdJ4L/72//OUveuihh/TZZ58pJibG5faWoKAgdezYUZMnT1ZRUZHq16+vBQsWnHZPtTwLFy5Uw4YNdckll1R4HtRA7rwUF6iIHTt2mPvuu880atTI2O12ExgYaBITE820adNcvnCgqKjIjBs3zjRu3Nh4e3ubmJiYM34pwR/98ZaF0906YszJLxto2bKlsdvtJi4uzrz77rtlbh1ZvHix6dmzp4mOjjZ2u91ER0ebO+64w+zYsaPMOv54e8WiRYtMYmKi8fX1NUFBQebmm28+7ZcS/PHWlDPdwvB7v7915HROd+vIE088YaKiooyvr69JTEw0K1euLPeWj88++8wkJCQYLy+vcr+UoDy/X05mZqaJjY017dq1M0VFRS7jHn/8cePh4WFWrlx5xm349ddfjZeXl5k1a9Zpx/Tt29dIMk899VSZvoMHD5revXubkJAQExwcbPr27WtSUlKMJDNmzBjnuPIe95KSEhMVFWWeffbZM9aIms9mDN/BBODCdu+992rHjh1avnx5ta537ty5uvPOO7V7925FRUVV67pRuQhLABe8/fv3q3nz5lq8eLESExOrbb0dOnTQNddcY3moGDUfYQkAgAWuhgUAwAJhCQCABcISAAALhCUAABZq/ZcSlJaWKiUlRYGBgXzRMQDUMsYYZWVlKTo62vlrOuWp9WGZkpKimJgYd5cBAHCjAwcOqEGDBqftr/Vheer3El9Y2l4+AbX+4aiV5j5QeV+Fh/OPx74j7i4BblRcWqhv02Zb/nZurU+HU4defQK85EtY1kpenj7uLgFu5OFR8d/UxIXL6jQcF/gAAGCBsAQAwAJhCQCABcISAAALhCUAABYISwAALBCWAABYICwBALBAWAIAYIGwBADAAmEJAIAFwhIAAAuEJQAAFghLAAAsEJYAAFggLAEAsEBYAgBggbAEAMACYQkAgAXCEgAAC4QlAAAWCEsAACwQlgAAWCAsAQCwQFgCAGCBsAQAwAJhCQCABcISAAALhCUAABYISwAALBCWAABYICwBALBAWAIAYIGwBADAAmEJAIAFwhIAAAuEJQAAFghLAAAsEJYAAFggLAEAsEBYAgBggbAEAMACYQkAgAXCEgAAC4QlAAAWCEsAACwQlgAAWCAsAQCwQFgCAGCBsAQAwAJhCQCABcISAAALhCUAABYISwAALBCWAABY8HJ3Aah8S+cc1rdzDuv4oQJJUnRTP904NEatOtZxGWeM0T/u36oty9P04KvxuqRrmLPv/ou/K7PcwS/F6fIbI6q2eFQJY0q1+9A3OnxskwqLsuWwByo6vK0aR3eSzWaTJP2051MdPrbBZb6w4KZqF3ePGypGVdqT+6N25qxWQ9+Wig9IdLanFx3Rzpw1yihKlWw2BXmF6dLgG+VpIyp4BC5AofXs6vNEI9WN9ZWMtGLur3pt6DaN/qStopv5O8ctSk7R/79Plmvg883U4ppQ57RfEH8u56t9h7/TwdS1atGktwJ8I5SZk6Ite+bKy9NHDSOvdI4LC26qFo17Oac9PHjOLzQZRak6mLdNAZ6uH57Ti45oXcaXauzXVvEBibLJQ1nFx2XTGd4kahFeCRegNteGuUz3fryRvv3PEe3ZmOUMywPbsrXw7UN65qO2evKa1eUuxzfIS8ER9iqvF1UvPeuAIkLiFBHSXJLk6wjVkeOblZFzyGWch81LDnugO0pENSg2RdqUtUQtAjtqd+56l76fs1eqoW9LNfG7xNnm7xVSzRXWXITlBa60xGjtV8dUmFuiJm2DJEkFeSV6a8R23fm3i84YhnPG79Y7z+5URIyPOvaLVGKfes5Ddji/hATG6GDqOuXkHZO/b7iyco8oPWu/mje8zmVcWtY+LV0/Wd5ePqoT1FgX1e8iu7efm6pGZduW9Z0i7A0VZm/gEpYFpXnKKE5VlE8zrUqbq9ySTPl7haiZ/2UK9Y5yY8U1h1vDMikpSa1bt5aPj4/eeust2e12DRkyRGPHjpUkpaena8SIEfrss89UUFCg9u3ba8qUKWrTpo1zGRMmTNA//vEP5eXl6fbbb1d4eLi++uorbdiwwT0bVUMc3J6jF+7YqKKCUjn8PPXgq/GKbnryTe+DSXt10SVBatsl7LTz3/JoQ118ZYjsPh7a+n263hu3WwU5perSP7q6NgGVqFHU1SouKdCKza/KZrPJGKOmDa5VVHhr55jw4KaqGxovX0eo8gpOaNeBxfox511dnjBYNhvXAp7vDufvUmbxMV0Z2rtMX15JpiRpd85axQVcqUDPcKUU7NCa9M+VGHqb/L2Cq7vcGsfte5bJyckaPny4Vq1apZUrV2rgwIFKTExUt27d1LdvX/n6+urLL79UcHCwZsyYoS5dumjHjh2qU6eOZs+erYkTJ+q1115TYmKi/vOf/+ill15S48aNT7u+goICFRQUOKczMzOrYzOrXWRjX43+9BLlZZVo3dfH9PbTOzRiVmul7s/T9lXpevaTS844/00PNXT+v2FCgArySrTg3wcJy/PUrye26PDxTWp10V/k71tXWblHtOOXL+XwDlJ0RFtJUmRYK+f4QL96CvCtp+83TdWJzH0KC27ipspRGfJKsvVz9gq1Dyn/Yh0jI0lq4BOv+j4XS5KCvMN1vPCQDuX/rOYBV1RrvTWR28OydevWGjNmjCSpWbNmevXVV7V48WL5+vpq9erVSk1NlcPhkCS9+OKLmjt3rj766CPdf//9mjZtmu69914NGjRIkvS3v/1NCxYsUHZ29mnXN2nSJI0bN67qN8zNvOweJy/wkRTbMkD7fsrS4ndSZPfx0NH9+Xrs8pUu46c/uk3NLg3SiFmty1ucGrcO1BevHVBRYam87exlnG92HFigxlFXOwMx0K+e8gvStffwcmdY/pGfTx15e/kpr+C4JMLyfJZZfFSFJk8r0z52thkZpRUd1oG8Lbq6zu2SpACvUJf5ArxClF96+vfT2qRGhOXvRUVFKTU1VRs3blR2drbCwlwPFebl5Wn37t2SpO3bt+uhhx5y6b/88su1ZMmS065v1KhRGj58uHM6MzNTMTEx57oZNZ4plYoLS3XLIw119a31XPrG3fKjbnu6idpcW+c0c0sHfs6RX7AXQXmeKi0pkv5wVaPNZpOMOe08+YUZKirOk92bC37Od2He9XVVaF+Xtp+ylsrfM0SN/drK1yNIDg8/5ZRkuIzJKclQuPeF//5YEW4PS29vb5dpm82m0tJSZWdnKyoqSkuXLi0zT0hIyJ9en8PhcO6pXqg+eWmfWnYMVZ0oh/JzSrT686PasTpDw95qoeAIe7kX9dSJdii8gY8kaeOS48o8XqQmbQLl7fDQ1hXp+nLGAXUfVL+6NwWVJDw0TntTlsvHEaIA3whl5RzRL0dWqn7EycPxxSUF2nNoqerWSZDDO0C5+WnaeWCB/Bx1FB7c1M3V41x5edgV6OH6YdjT5iVvD4cCvU62N/Jto9256xToFaZArzCl5O9QTnG62gZ1c0fJNY7bw/J02rVrpyNHjsjLy0uNGjUqd0xcXJzWrFmj/v37O9vWrFlTTRXWXFknivT2yB3KOFoo30Av1Y/z07C3WighMdR6Zkme3h5a+t5hfTBprySjiIa+6juysa65LbJqC0eVuTj2Bu0+uEQ/7/tchUU5ctgD1aBuezWJ7iRJstk8lJ37q1KObVRxSb4c3oEKC75IFzW4lnsta4lGfq1VqhJtz16hotICBXqFqX3IjfLz5OIeqQaHZdeuXdWhQwf16tVLkydPVvPmzZWSkqIvvvhCvXv3Vvv27fXII4/ovvvuU/v27XXVVVfp/fff16ZNm9SkSe0+vzJgYrOzGv/Gz1e7TLe8JlQtr6lYsOL84OXpUFzs9YqLvb7cfk8Pb7W7uH+5fbgwXR5yS5m2Jn6XuNxnid/U2LC02WyaP3++nnnmGQ0aNEhHjx5VZGSkOnbsqHr1Tp5zu+uuu7Rnzx6NGDFC+fn5uu222zRw4ECtXl3+TfYAAPwZNmPOcIb/PNStWzdFRkZq1qxZFRqfmZmp4OBgTV17pXwDauxnB1ShD/tzTqY289ib4u4S4EbFpYVafPxtZWRkKCgo6LTjzut0yM3N1fTp09WjRw95enpqzpw5WrRokRYuXOju0gAAF5DzOixPHaqdOHGi8vPzFRcXp48//lhdu3Z1d2kAgAvIeR2Wvr6+WrRokbvLAABc4LjDHAAAC4QlAAAWCEsAACwQlgAAWCAsAQCwQFgCAGCBsAQAwAJhCQCABcISAAALhCUAABYISwAALBCWAABYICwBALBAWAIAYIGwBADAAmEJAIAFwhIAAAuEJQAAFghLAAAsEJYAAFggLAEAsEBYAgBggbAEAMACYQkAgAXCEgAAC4QlAAAWCEsAACwQlgAAWCAsAQCwQFgCAGCBsAQAwAJhCQCABcISAAALhCUAABYISwAALBCWAABYICwBALBAWAIAYIGwBADAAmEJAIAFwhIAAAuEJQAAFghLAAAsEJYAAFggLAEAsEBYAgBggbAEAMACYQkAgAXCEgAAC4QlAAAWCEsAACwQlgAAWCAsAQCwQFgCAGDBy90F1BQvre8mDz8fd5cBN4gN5jNjbXbizjh3lwA3KinIl6Zbj+NdAgAAC4QlAAAWCEsAACwQlgAAWCAsAQCwQFgCAGCBsAQAwAJhCQCABcISAAALhCUAABYISwAALBCWAABYICwBALBAWAIAYIGwBADAAmEJAIAFwhIAAAuEJQAAFghLAAAsEJYAAFggLAEAsEBYAgBggbAEAMACYQkAgAXCEgAAC4QlAAAWCEsAACwQlgAAWCAsAQCwQFgCAGCBsAQAwAJhCQCABcISAAALhCUAABYISwAALBCWAABYICwBALBAWAIAYIGwBADAAmEJAIAFwhIAAAuEJQAAFghLAAAsEJYAAFggLAEAsEBYAgBggbAEAMACYQkAgAXCEgAAC4QlAAAW/lRYLl++XHfffbc6dOigQ4cOSZJmzZql7777rlKLAwCgJjjrsPz444/Vo0cP+fr66scff1RBQYEkKSMjQ88//3ylFwgAgLuddVhOmDBB06dP15tvvilvb29ne2JiotavX1+pxQEAUBOcdVhu375dHTt2LNMeHBys9PT0yqgJAIAa5azDMjIyUrt27SrT/t1336lJkyaVUhQAADXJWYflfffdp2HDhmnVqlWy2WxKSUnR7NmzNWLECD344INVUSMAAG7ldbYzPP300yotLVWXLl2Um5urjh07yuFwaMSIEXrkkUeqokYAANzqrMPSZrPpmWee0ZNPPqldu3YpOztbCQkJCggIqIr6AABwu7MOy1PsdrsSEhIqsxZUkvR53yp3zRYVHT4qm91bjmYNVef2HvKOjigz1hij1L8nK2/TTkU8dpf825d9TkuycpXyP9NUkpapmBnPytPftzo2A+cgPW2vDuxbpuzMQyoszFKLNncrvG4LZ78xRvt2L9KRQ2tUXJynoJBYNbu4l/z8w8ssq7S0WOtXvaac7MO69MpHFBAYXZ2bgj8h59BuHV33jfJSD6o4J1MNbxqk4ItauYzJP/Grjnz3uXIO7ZYpLZVPnXpqeONA2YNCVZyfo9QfvlbWL9tVlJUmL98ABV3UUvU6XC9PR+18/Z91WHbu3Fk2m+20/UuWLDmngnDu8rftVWC3K+VoUl8qKVXaBwt05IWZqv/CMHn42F3GZn61QjrD8ylJx976RPaGkcpLy6zKslGJSkoKFRAYpaj67bVl47tl+g/sW6ZDB1bo4hZ95eMbqn27F2rzj//WZR0el4ent8vYPTu+lMMRqJzsw9VVPs5RaVGhfMKjFZpwufZ/MbNMf0H6Me35cJpCW1yhelf2kIfdRwUnjsjD62QkFGdnqig7Q1HX3CJHnXoqykrToSUfqSgnU7E3DqzejakhzvoCn7Zt26pNmzbOfwkJCSosLNT69evVqlUr6wWgykWOHKjAju1kb1BP9tgohT9wq0qOp6tw3yGXcQW/pChz/ncKu6/PaZeVuWiVSnPyFXTD1VVdNipRWHicGjft7rI3eYoxRof2f6/Yxp0VXjdBAYFRurjFbSooyNKxo1tdxh4/tl1pJ3aqSfMbqqt0VILARvGKvOoGBTdtXW7/ryvnK7BRvKKuvlm+dRvIERKuoCYt5eUXKEnyCY9S7E2DFNSkhRwh4QqIaabIq65X1t4tMqUl1bkpNcZZ71lOmTKl3PaxY8cqOzv7rJaVlJSk1q1by8fHR2+99ZbsdruGDBmisWPHSpLS09M1YsQIffbZZyooKFD79u01ZcoUtWnTRpI0cOBApaena+7cuc5lPvbYY9qwYYOWLl16tpt2wSrNzZckefj7/dZWUKhj//xAYQNvlldIYLnzFR5KVcanSxQ17kEVpZ6ollpR9fLz0lRYmKXQsKbONi9vHwUFxSgzfb/qRp58fRUWZGnH1k/Uss098vS0n25xOM8YU6qsvdsUfmln7f10hvKOHpI9qI4iLutS5lDt75UU5MvD7iObh2c1VltzVNoXqd99993697//fdbzJScny9/fX6tWrdLkyZM1fvx4LVy4UJLUt29fpaam6ssvv9S6devUrl07denSRSdO8MZdUaa0VCfe/UKO5rGyx9Rztp94d74czRrK79LyzzubomId/ef7Cr3jenmFh1RTtagOhYVZkiRvu+tFeXZHgLPPGKOft3yk6AZXKDC4QbXXiKpTnJut0qICHV27RIGxF6tx7wcUdFEr7f98prIPlr2HXpKK87KVunqh6rTsUM3V1hx/+gKfP1q5cqV8fHzOer7WrVtrzJgxkqRmzZrp1Vdf1eLFi+Xr66vVq1crNTVVDodDkvTiiy9q7ty5+uijj3T//ff/qToLCgqc32crSZmZF/Z5uBPJ/1XhwV8VNfq3xyt33Tblb92j6IlDTztf2vsL5B0doYCr21ZDlahpDh1YoZKSAjVsnOTuUlDZjJEkBTVpofB2nSRJvhH1lXt4n05sXqmABk1dhpcU5GvfZ2/JUaee6l3Ro9rLrSnOOiz79HE9v2WM0eHDh7V27VqNHj36rAto3dr1mHpUVJRSU1O1ceNGZWdnKywszKU/Ly9Pu3fvPuv1nDJp0iSNGzfuT89/PjmePE+5P25X5LOD5RUW7GzP27pHxakntP/+CS7jj059T5lxjRT17GDlbd2togO/at/q/39O//8FduDB5xXcs5NC/9K12rYDlctuP3nYvagwWw5HkLO9sCBbAYFRkqT0E3uUmb5fyxa7vqbXrfqn6kW20cUtb6u+glGpPH39JQ8P+YRFurQ76tRVbspel7aSwnzt++wNedgdir1pkGyetfMQrPQnwjI4ONhl2sPDQ3FxcRo/fry6d+9+1gX8/svYpZP3cZaWlio7O1tRUVHlnnsMCQlxrtv8/5v4KUVFRWdc36hRozR8+HDndGZmpmJiYs667prMGKMT7/xXuWu3KvKZwfKuW8elP/jmjgpMau/SljLqH6pz9w3yveRiSVLdYXfKFBY7+wv2HNTxNz9R5Oj7yiwP5xcf31DZ7YFKO77beRtIcXG+MjMPKDrmCklS07ib1bhpN+c8BQWZ2rz+bSW0ukNBwRfW66W28fD0kl+9hipIS3VpL0w/Ku/AUOd0SUG+9s6dIQ9PLzW6+V55eHn/cVG1ylmFZUlJiQYNGqRWrVopNDTUeoZz0K5dOx05ckReXl5q1KhRuWMiIiL0008/ubRt2LChTAD/nsPhcB7WvVCdmDlP2Ss3qd7jd8vm41Bx+snzUB5+PvKwe5+8oKeci3o8w0KcQehdz3WPviQr52R7dAT3WZ4HSooLlJd33Dmdn5em7KwUeXn5ycc3RPUbJmr/3iXy9QuTj28d7du9UA5HoMIjTp7D9vENcVmep+fJ14yvXx05fFw/MKPmKSksUGHGMed0UcYJ5R09JE+Hn+xBoQpvl6QDX86Sf/0m8m/QVFm//KzMPVvV5C8PnZy/IF97506XKSpS/R53qaQwXyWFJy8U9PINkM2j0i53OW+cVVh6enqqe/fu2rZtW5WHZdeuXdWhQwf16tVLkydPVvPmzZWSkqIvvvhCvXv3Vvv27XXttdfq73//u9555x116NBB7777rn766SddcsklVVpbTZe1eLUk6cjEt1zaw+7/iwI7tnNHSahmWZmHtHHdm87p3Tu+kCTVi2qni1v2VUyjjiopKdSObZ+quDhfwSGxanXJoDL3WOL8lJd6QHs/fs05fXj5Z5KkkPjLFNP9DgU3ba2Sa2/V0TWLlbL0UzlC6yr2xoHyr3/yxzDyjh5U3pH9kqQdya6/Uxw36FnZg2rf0SWb+eNxTAvt27fXCy+8oC5dupzzypOSktS2bVu98sorzrZevXopJCREM2fOVFZWlp555hl9/PHHOnr0qCIjI9WxY0dNmjTJeeh0zJgxmjFjhvLz8/XXv/5VRUVF2rx5c4VvHcnMzFRwcLAavjFaHn5nf4ESzn+xybXvUzJ+cyLhwj7ShDMrKcjX1un/o4yMDAUFBZ123FmH5VdffaVRo0bpueee06WXXip/f3+X/jOtrCYiLEFY1m6EZe1W0bCs8GHY8ePH64knntANN5z8Jo9bbrnF5WvvjDGy2WwqKamd3+4AALhwVTgsx40bpyFDhuibb76pynoAAKhxKhyWp47WdurUqcqKAQCgJjqrkzVn+rURAAAuVGd160jz5s0tA5PvbQUAXGjOKizHjRtX5ht8AAC40J1VWPbr109169atqloAAKiRKnzOkvOVAIDaqsJheZbfXQAAwAWjwodhS0tLq7IOAABqLL7nCwAAC4QlAAAWCEsAACwQlgAAWCAsAQCwQFgCAGCBsAQAwAJhCQCABcISAAALhCUAABYISwAALBCWAABYICwBALBAWAIAYIGwBADAAmEJAIAFwhIAAAuEJQAAFghLAAAsEJYAAFggLAEAsEBYAgBggbAEAMACYQkAgAXCEgAAC4QlAAAWCEsAACwQlgAAWCAsAQCwQFgCAGCBsAQAwAJhCQCABcISAAALhCUAABYISwAALBCWAABYICwBALBAWAIAYIGwBADAAmEJAIAFwhIAAAuEJQAAFghLAAAsEJYAAFggLAEAsEBYAgBggbAEAMCCl7sLqCmajz8mLw+Hu8uAGxQfOOjuEuBGG97Z4O4S4EaZWaUKnW49jj1LAAAsEJYAAFggLAEAsEBYAgBggbAEAMACYQkAgAXCEgAAC4QlAAAWCEsAACwQlgAAWCAsAQCwQFgCAGCBsAQAwAJhCQCABcISAAALhCUAABYISwAALBCWAABYICwBALBAWAIAYIGwBADAAmEJAIAFwhIAAAuEJQAAFghLAAAsEJYAAFggLAEAsEBYAgBggbAEAMACYQkAgAXCEgAAC4QlAAAWCEsAACwQlgAAWCAsAQCwQFgCAGCBsAQAwAJhCQCABcISAAALhCUAABYISwAALBCWAABYICwBALBAWAIAYIGwBADAAmEJAIAFwhIAAAuEJQAAFghLAAAsEJYAAFggLAEAsEBYAgBggbAEAMACYQkAgAXCEgAAC4QlAAAWCEsAACwQlgAAWPBydwGoHjvTV2p35iqXNn+vUF0TPcA5nVaQop3pK5RReESSh4LsEWof0VueHvyZnO/2mp91VIeUoyx5yFMhClNTtZK/LdA5Zq1ZqnQdc5mvvpoo3tauustFJXphWpr+5/njenRwsKY8FyFJys8v1Yhxx/X+Z1kqKDDqnuSnf/5vhOpF/PZaH/bsUa1Yna+fthcovpld6xc1dNcm1Ai8C9YiAd5huqxuH+e07XcHFtIKUrQuda6aBF2m+NDOstlsyio8JpvNHZWisqXrqBroIgUpVEZGu/STftRydTDd5Wn77W2gvhqriVo4pz3l6Y5yUUnWbMjXG7My1DrB7tI+fMwxzV+Uq/ffiFRwoIcefeaobr33iJbPa+AybtAdgVq13q7N2wqqs+waibCsRWyyyeHpX27fz2nLFBvYVk2CL3O2BXjXqa7SUMUusV3jMt3CXKZl+q8ylaZQRTjbPeQph82nustDFcjOKdU9Q3/VjBfr6vlXTjjbMzJL9O85mXr3tUhde7WfJOlfU+qpRcf9+mFdvq689OTzP3XCyb+Lo8ePE5aqAecsk5KS9PDDD+vhhx9WcHCwwsPDNXr0aBljJElpaWnq37+/QkND5efnp+uvv147d+50zv/LL7/o5ptvVmhoqPz9/dWiRQvNnz/fXZtTo+UWp+ubQ2/q20P/1sZjXyqvOFOSVFCSq4zCI7J7+umHI+9rycE3tOrXD5WWf8jNFaOqFKtIkuQt1z2OI9qvb808rTQLtMtsVokpdkd5qAQPjzqqG7r4qWtHP5f2dZsKVFQkdb3G19l2cTO7Gtb30g9r86u7zPOG28NSkpKTk+Xl5aXVq1dr6tSpevnll/XWW29JkgYOHKi1a9dq3rx5WrlypYwxuuGGG1RUdPLFPnToUBUUFGjZsmXavHmzXnjhBQUEBLhzc2qkEEekWoV1V/uIXkqoc63yijO16tcPVVxaqLziDEnSrowf1CCgpdrX7aUge12tTv1EOUVpbq4clc0Yox3aoGCFKcAW7GyPVEO11OW6VJ3USBfrsPbrJ612Y6X4s/4zN0s/bi7Q8/8TVqbvSGqJ7HYpJNj1EHu9CE8dOcqHo9OpEYdhY2JiNGXKFNlsNsXFxWnz5s2aMmWKkpKSNG/ePH3//fe66qqrJEmzZ89WTEyM5s6dq759+2r//v36y1/+olatWkmSmjRpcsZ1FRQUqKDgt0MKmZmZVbdhNUiEb2Pn/wMVoRBHpL499G8dyd0h//8/3BoT0EoNAk6erwqy19Xx/AM6mLNFcSFXu6VmVI2f9aOylan2SnJpb2D77bUToGA5jI/Wa5lyTbb8bHwAPV8cOFSkx0cf09fvR8vHp0bsD10QasQjeeWVV8r2uytJOnTooJ07d2rr1q3y8vLSFVdc4ewLCwtTXFyctm3bJkl69NFHNWHCBCUmJmrMmDHatGnTGdc1adIkBQcHO//FxMRUzUbVcN4ePvLzDlVOcbrzPOYfz1EGeIcqvzjLHeWhivxsftQxHdal6iQfm98Zxwbr5N9DnrKrozRUknWbCpR6rETtux+QvcEu2Rvs0rcr8zXtXxmyN9ilehGeKiyU0jNKXOb79WiJIiNqxP5TjVQjwvJcDB48WHv27NE999yjzZs3q3379po2bdppx48aNUoZGRnOfwcOHKjGamuOk4dfTwalr2eQHJ7+ZQ655hSly9cryE0VojIZY/Sz+VFHdUiXqqN8beVf6PV7WUqXJNnFBT/nky7X+GnjNzFav+i3f+3bOHRnn0Dn/729pcXL85zzbN9VqP2HinVle57r06kRHyNWrXK9/++HH35Qs2bNlJCQoOLiYq1atcp5GPb48ePavn27EhISnONjYmI0ZMgQDRkyRKNGjdKbb76pRx55pNx1ORwOORyOqtuYGurntGWq69tEPl6BKijJ0a6MHyR5KNovTjabTY0DL9WujB8UaI9QoHeEUnK2Kqf4hC7xv9HdpaMSbNePOqIDaqOr5ClvFZiTF3J4yVueNk/lmmwd0X6FK0resitbGdqhjQpRuAJtIe4tHmclMMBDLS92fY/z97MpLPS39r/eEaQRY4+pTqiHggI8NOzZY+rQ3sd5Jawk7dpbqOwcoyOpJcrLN9rw08nTVwnN7bLba989ZTUiLPfv36/hw4frgQce0Pr16zVt2jS99NJLatasmXr27Kn77rtPM2bMUGBgoJ5++mnVr19fPXv2lCQ99thjuv7669W8eXOlpaXpm2++UXx8vJu3qObJL8nWxuNfqrAkX3ZPX4U6otWh3u2ye548FNcoqJ1KTYl+TvtWRaX5CvSO0GURfeTnHeLewlEpDmqPJGmdvnVpT1B7RauRPOShE0rVAe1SiYrlkJ/qqr4ai9fShejlceHy8DiuvoOPuHwpwe/d/0Sqvl3529Wxl3Y7eRRu9+pYNYrxrtZ6awKbOXWPhpskJSWpRYsWKi0t1XvvvSdPT089+OCDmjBhgmw2m9LS0jRs2DDNmzdPhYWF6tixo6ZNm6ZmzZpJkh555BF9+eWXOnjwoIKCgnTddddpypQpCgsrexVYeTIzMxUcHKyuDR6Ul0ft2+OEVHzgoLtLgBt9nbLB3SXAjTKzShXafI8yMjIUFHT60041Ys/S29tbr7zyil5//fUyfaGhoXrnnXdOO++Zzk8CAFAZzvsLfAAAqGqEJQAAFtx+GHbp0qXuLgEAgDNizxIAAAuEJQAAFghLAAAsEJYAAFggLAEAsEBYAgBggbAEAMACYQkAgAXCEgAAC4QlAAAWCEsAACwQlgAAWCAsAQCwQFgCAGCBsAQAwAJhCQCABcISAAALhCUAABYISwAALBCWAABYICwBALBAWAIAYIGwBADAAmEJAIAFwhIAAAuEJQAAFghLAAAsEJYAAFggLAEAsEBYAgBggbAEAMACYQkAgAXCEgAAC4QlAAAWCEsAACwQlgAAWCAsAQCwQFgCAGCBsAQAwAJhCQCABcISAAALhCUAABYISwAALBCWAABYICwBALBAWAIAYIGwBADAAmEJAIAFwhIAAAuEJQAAFghLAAAsEJYAAFggLAEAsEBYAgBgwcvdBbibMUaSVFxa6OZK4C7FpsjdJcCNMrNK3V0C3Cgz++TzfyoLTsdmrEZc4A4ePKiYmBh3lwEAcKMDBw6oQYMGp+2v9WFZWlqqlJQUBQYGymazubucapeZmamYmBgdOHBAQUFB7i4HbsDfQO1W259/Y4yysrIUHR0tD4/Tn5ms9YdhPTw8zvhporYICgqqlS8U/Ia/gdqtNj//wcHBlmO4wAcAAAuEJQAAFgjLWs7hcGjMmDFyOBzuLgVuwt9A7cbzXzG1/gIfAACssGcJAIAFwhIAAAuEJQAAFghLAAAsEJYAAFggLC9QSUlJevTRR/XUU0+pTp06ioyM1NixY5396enpGjx4sCIiIhQUFKRrr71WGzdudFnGhAkTVLduXQUGBmrw4MF6+umn1bZt2+rdEPwp5/r8Dxw4UL169XJZ5mOPPaakpKTq2QCcs6SkJD388MN6+OGHFRwcrPDwcI0ePdr5heFpaWnq37+/QkND5efnp+uvv147d+50zv/LL7/o5ptvVmhoqPz9/dWiRQvNnz/fXZvjdoTlBSw5OVn+/v5atWqVJk+erPHjx2vhwoWSpL59+yo1NVVffvml1q1bp3bt2qlLly46ceKEJGn27NmaOHGiXnjhBa1bt04NGzbU66+/7s7NwVk6l+cfF4bk5GR5eXlp9erVmjp1ql5++WW99dZbkk5+IFq7dq3mzZunlStXyhijG264QUVFJ3+FZ+jQoSooKNCyZcu0efNmvfDCCwoICHDn5riXwQWpU6dO5uqrr3Zpu+yyy8zIkSPN8uXLTVBQkMnPz3fpv+iii8yMGTOMMcZcccUVZujQoS79iYmJpk2bNlVaNyrHuT7/AwYMMD179nTpHzZsmOnUqVNVlo1K1KlTJxMfH29KS0udbSNHjjTx8fFmx44dRpL5/vvvnX3Hjh0zvr6+5oMPPjDGGNOqVSszduzYaq+7pmLP8gLWunVrl+moqCilpqZq48aNys7OVlhYmAICApz/9u7dq927d0uStm/frssvv9xl/j9Oo2Y7l+cfF4Yrr7zS5deUOnTooJ07d2rr1q3y8vLSFVdc4ewLCwtTXFyctm3bJkl69NFHNWHCBCUmJmrMmDHatGlTtddfk9T6Xx25kHl7e7tM22w2lZaWKjs7W1FRUVq6dGmZeUJCQqqnOFS5c3n+PTw8yvwY7qnDc6gdBg8erB49euiLL77QggULNGnSJL300kt65JFH3F2aW7BnWQu1a9dOR44ckZeXl5o2beryLzw8XJIUFxenNWvWuMz3x2mcnyry/EdEROjw4cMu823YsMEN1eJcrFq1ymX6hx9+ULNmzZSQkKDi4mKX/uPHj2v79u1KSEhwtsXExGjIkCH65JNP9MQTT+jNN9+sttprGsKyFuratas6dOigXr16acGCBdq3b59WrFihZ555RmvXrpUkPfLII/rXv/6l5ORk7dy5UxMmTNCmTZtq5Q9kX2gq8vxfe+21Wrt2rd555x3t3LlTY8aM0U8//eTmynG29u/fr+HDh2v79u2aM2eOpk2bpmHDhqlZs2bq2bOn7rvvPn333XfauHGj7r77btWvX189e/aUdPLq56+//lp79+7V+vXr9c033yg+Pt7NW+Q+hGUtZLPZNH/+fHXs2FGDBg1S8+bN1a9fP/3yyy+qV6+eJOmuu+7SqFGjNGLECLVr10579+7VwIED5ePj4+bqca4q8vz36NFDo0eP1lNPPaXLLrtMWVlZ6t+/v5srx9nq37+/8vLydPnll2vo0KEaNmyY7r//fknS22+/rUsvvVQ33XSTOnToIGOM5s+f7zx8X1JSoqFDhyo+Pl7XXXedmjdvrtdee82dm+NW/OoIKqxbt26KjIzUrFmz3F0KAAtJSUlq27atXnnlFXeXckHgAh+UKzc3V9OnT1ePHj3k6empOXPmaNGiRc779ACgNiEsUa5Th+omTpyo/Px8xcXF6eOPP1bXrl3dXRoAVDsOwwIAYIELfAAAsEBYAgBggbAEAMACYQkAgAXCEgAAC4QlUIv88Uedk5KS9Nhjj1V7HUuXLpXNZlN6enq1rxv4MwhLoAYYOHCgbDabbDab7Ha7mjZtqvHjx6u4uLhK1/vJJ5/oueeeq9BYAg61GV9KANQQ1113nd5++20VFBRo/vz5Gjp0qLy9vTVq1CiXcYWFhbLb7ZWyzjp16lTKcoALHXuWQA3hcDgUGRmp2NhYPfjgg+ratavmzZvnPHQ6ceJERUdHKy4uTpJ04MAB3XbbbQoJCVGdOnXUs2dP7du3z7m8kpISDR8+XCEhIQoLC9NTTz1V5jcq/3gYtqCgQCNHjlRMTIwcDoeaNm2qf/3rX9q3b586d+4sSQoNDZXNZtPAgQMlSaWlpZo0aZIaN24sX19ftWnTRh999JHLeubPn6/mzZvL19dXnTt3dqkTOB8QlkAN5evrq8LCQknS4sWLtX37di1cuFCff/65ioqK1KNHDwUGBmr58uX6/vvvFRAQoOuuu845z0svvaSZM2fq3//+t7777judOHFCn3766RnX2b9/f82ZM0f/+Mc/tG3bNs2YMUMBAQGKiYnRxx9/LEnavn27Dh8+rKlTp0qSJk2apHfeeUfTp0/Xli1b9Pjjj+vuu+/Wt99+K+lkqPfp00c333yzNmzYoMGDB+vpp5+uqocNqBoGgNsNGDDA9OzZ0xhjTGlpqVm4cKFxOBxmxIgRZsCAAaZevXqmoKDAOX7WrFkmLi7OlJaWOtsKCgqMr6+v+frrr40xxkRFRZnJkyc7+4uKikyDBg2c6zHGmE6dOplhw4YZY4zZvn27kWQWLlxYbo3ffPONkWTS0tKcbfn5+cbPz8+sWLHCZey9995r7rjjDmOMMaNGjTIJCQku/SNHjiyzLKAm45wlUEN8/vnnCggIUFFRkUpLS3XnnXdq7NixGjp0qFq1auVynnLjxo3atWuXAgMDXZaRn5+v3bt3KyMjQ4cPH9YVV1zh7PPy8lL79u3LHIo9ZcOGDfL09FSnTp0qXPOuXbuUm5urbt26ubQXFhbqkksukSRt27bNpQ5J6tChQ4XXAdQEhCVQQ3Tu3Fmvv/667Ha7oqOj5eX128vT39/fZWx2drYuvfRSzZ49u8xyIiIi/tT6fX19z3qe7OxsSdIXX3yh+vXru/Q5HI4/VQdQExGWQA3h7++vpk2bVmhsu3bt9P7776tu3boKCgoqd0xUVJRWrVqljh07SpKKi4u1bt06tWvXrtzxrVq1Umlpqb799ttyf4rt1J5tSUmJsy0hIUEOh0P79+8/7R5pfHy85s2b59L2ww8/WG8kUINwgQ9wHrrrrrsUHh6unj17avny5dq7d6+WLl2qRx99VAcPHpQkDRs2TP/7v/+ruXPn6ueff9ZDDz10xnskGzVqpAEDBuivf/2r5s6d61zmBx98IEmKjY2VzWbT559/rqNHjyo7O1uBgYEaMWKEHn/8cSUnJ2v37t1av369pk2bpuTkZEnSkCFDtHPnTj355JPavn273nvvPc2cObOqHyKgUhGWwHnIz89Py5YtU8OGDdWnTx/Fx8fr3nvvVX5+vnNP84knntA999yjAQMGqEOHDgoMDFTv3r3PuNzXX39dt956qx566CFdfPHFuu+++5STkyNJql+/vsaNG6enn35a9erV08MPPyxJeu655zR69GhNmjRJ8fHxuu666/TFF1+ocePGkqSGDRvq448/1ty5c9WmTRtNnz5dzz//fBU+OkDl48efAQCwwJ4lAAAWCEsAACwQlgAAWCAsAQCwQFgCAGCBsAQAwAJhCQCABcISAAALhCUAABYISwAALBCWAABYICwBALDwfxA2ngpAGglKAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_report\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05678303789950534,\n        \"min\": 0.48598130841121495,\n        \"max\": 0.6584564860426929,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.5348837209302325,\n          0.48598130841121495,\n          0.5584680822377985\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.21251741358066809,\n        \"min\": 0.20392156862745098,\n        \"max\": 0.8319502074688797,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.20392156862745098,\n          0.5868872306875724,\n          0.8319502074688797\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1-score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14731852235496515,\n        \"min\": 0.287292817679558,\n        \"max\": 0.7351054078826764,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.6155218554861731,\n          0.287292817679558,\n          0.5407551408906287\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"support\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 599.2766104873285,\n        \"min\": 0.5790190735694822,\n        \"max\": 1468.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          510.0,\n          1468.0,\n          482.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_report"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-f34d6eb0-9c78-4fe7-bfaa-67d34ea39d6a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>support</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>negative</th>\n",
              "      <td>0.534884</td>\n",
              "      <td>0.724790</td>\n",
              "      <td>0.615522</td>\n",
              "      <td>476.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>0.485981</td>\n",
              "      <td>0.203922</td>\n",
              "      <td>0.287293</td>\n",
              "      <td>510.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>0.658456</td>\n",
              "      <td>0.831950</td>\n",
              "      <td>0.735105</td>\n",
              "      <td>482.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>accuracy</th>\n",
              "      <td>0.579019</td>\n",
              "      <td>0.579019</td>\n",
              "      <td>0.579019</td>\n",
              "      <td>0.579019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>macro avg</th>\n",
              "      <td>0.559774</td>\n",
              "      <td>0.586887</td>\n",
              "      <td>0.545973</td>\n",
              "      <td>1468.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weighted avg</th>\n",
              "      <td>0.558468</td>\n",
              "      <td>0.579019</td>\n",
              "      <td>0.540755</td>\n",
              "      <td>1468.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f34d6eb0-9c78-4fe7-bfaa-67d34ea39d6a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f34d6eb0-9c78-4fe7-bfaa-67d34ea39d6a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f34d6eb0-9c78-4fe7-bfaa-67d34ea39d6a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d2c3046f-9af6-4aac-868c-175f3ce36f54\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d2c3046f-9af6-4aac-868c-175f3ce36f54')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d2c3046f-9af6-4aac-868c-175f3ce36f54 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_d24ed1c1-eebd-468f-90e2-94334b82b883\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_report')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d24ed1c1-eebd-468f-90e2-94334b82b883 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_report');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "              precision    recall  f1-score      support\n",
              "negative       0.534884  0.724790  0.615522   476.000000\n",
              "neutral        0.485981  0.203922  0.287293   510.000000\n",
              "positive       0.658456  0.831950  0.735105   482.000000\n",
              "accuracy       0.579019  0.579019  0.579019     0.579019\n",
              "macro avg      0.559774  0.586887  0.545973  1468.000000\n",
              "weighted avg   0.558468  0.579019  0.540755  1468.000000"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np, matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "pred = trainer.predict(ds_val)\n",
        "y_true = pred.label_ids\n",
        "y_pred = np.argmax(pred.predictions, axis=1)\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred, labels=[0,1,2])\n",
        "plt.figure()\n",
        "plt.imshow(cm, interpolation='nearest')\n",
        "plt.title('Confusion Matrix (Val)')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.xticks([0,1,2], ['neg','neu','pos'])\n",
        "plt.yticks([0,1,2], ['neg','neu','pos'])\n",
        "for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        plt.text(j, i, cm[i, j], ha='center', va='center')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "report = classification_report(y_true, y_pred, labels=[0,1,2],\n",
        "                               target_names=['negative','neutral','positive'],\n",
        "                               output_dict=True)\n",
        "df_report = pd.DataFrame(report).transpose()\n",
        "df_report\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hufxTwCGmOE"
      },
      "source": [
        "# **Export of consolidated logs and model summaries**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0T3L9mdTsIuI"
      },
      "source": [
        "# Upgraded transformer training (early stopping, class weights, test evaluation)\n",
        "\n",
        "This section adds optional class weighting, early stopping, a small sweep over configs, and a proper evaluation on the held‑out test set with predictions export and run logging.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UN2EKZ4QsIuI"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, EarlyStoppingCallback, set_seed\n",
        "import torch, numpy as np, os\n",
        "from datasets import Dataset\n",
        "import platform\n",
        "\n",
        "# GPU-optimized settings for sweep\n",
        "USE_GPU_SWEEP = torch.cuda.is_available()\n",
        "NUM_WORKERS_SWEEP = 0 if platform.system() == 'Windows' else 4\n",
        "PIN_MEMORY_SWEEP = USE_GPU_SWEEP\n",
        "\n",
        "# Build tokenized datasets for a given max length (with GPU optimizations)\n",
        "def build_datasets_for_len(max_len: int):\n",
        "    tok = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
        "    def _tok(batch):\n",
        "        return tok(batch['review'], truncation=True, padding='max_length', max_length=max_len)\n",
        "    dtr = Dataset.from_pandas(df_train[['review','label']].reset_index(drop=True))\n",
        "    dva = Dataset.from_pandas(df_val[['review','label']].reset_index(drop=True))\n",
        "    dte = Dataset.from_pandas(df_test[['review','label']].reset_index(drop=True))\n",
        "\n",
        "    # Windows multiprocessing has issues with tokenizers\n",
        "    if platform.system() == 'Windows':\n",
        "        num_proc_tok = None  # Disable parallel processing on Windows\n",
        "    else:\n",
        "        num_proc_tok = 4 if USE_GPU_SWEEP else 2  # Parallel on Unix systems\n",
        "\n",
        "    # Tokenize (batched=True is faster)\n",
        "    # Only remove 'review' column, keep 'label' column\n",
        "    dtr = dtr.map(_tok, batched=True, num_proc=num_proc_tok, remove_columns=['review'])\n",
        "    dva = dva.map(_tok, batched=True, num_proc=num_proc_tok, remove_columns=['review'])\n",
        "    dte = dte.map(_tok, batched=True, num_proc=num_proc_tok, remove_columns=['review'])\n",
        "\n",
        "    cols = ['input_ids','attention_mask','label']\n",
        "    dtr = dtr.with_format('torch', columns=cols)\n",
        "    dva = dva.with_format('torch', columns=cols)\n",
        "    dte = dte.with_format('torch', columns=cols)\n",
        "    return tok, dtr, dva, dte\n",
        "\n",
        "# GPU-optimized batch sizes for sweep\n",
        "if USE_GPU_SWEEP:\n",
        "    DEFAULT_BS = 32  # Larger batch for GPU\n",
        "    DEFAULT_EVAL_BS = 64\n",
        "else:\n",
        "    DEFAULT_BS = 8\n",
        "    DEFAULT_EVAL_BS = 16\n",
        "\n",
        "# Small sweep configurations (GPU-optimized)\n",
        "SWEEP = [\n",
        "    {'max_len': 128, 'seed': 42, 'lr': 2e-5, 'epochs': 3, 'bs': DEFAULT_BS},\n",
        "    {'max_len': 256, 'seed': 42, 'lr': 3e-5, 'epochs': 3, 'bs': DEFAULT_BS},\n",
        "]\n",
        "\n",
        "print(f\"Starting sweep with {len(SWEEP)} configurations\")\n",
        "print(f\"GPU: {USE_GPU_SWEEP}, Batch size: {DEFAULT_BS}\")\n",
        "\n",
        "best_run = None\n",
        "for i, cfg in enumerate(SWEEP, 1):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Run {i}/{len(SWEEP)}: max_len={cfg['max_len']}, lr={cfg['lr']}, bs={cfg['bs']}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    set_seed(cfg['seed'])\n",
        "    tokenizer_s, ds_tr_s, ds_va_s, ds_te_s = build_datasets_for_len(cfg['max_len'])\n",
        "    model_s = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=3)\n",
        "    model_s = model_s.to(device if 'device' in globals() else torch.device('cuda' if USE_GPU_SWEEP else 'cpu'))\n",
        "\n",
        "    args = TrainingArguments(\n",
        "        output_dir=f\"checkpoints/{MODEL_CHOICE}/sweep_len{cfg['max_len']}_seed{cfg['seed']}\",\n",
        "        evaluation_strategy='steps',\n",
        "        eval_steps=200,\n",
        "        save_strategy='steps',\n",
        "        save_steps=200,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model='f1_macro',\n",
        "        greater_is_better=True,\n",
        "        num_train_epochs=cfg['epochs'],\n",
        "        per_device_train_batch_size=cfg['bs'],\n",
        "        per_device_eval_batch_size=DEFAULT_EVAL_BS,\n",
        "        learning_rate=cfg['lr'],\n",
        "        weight_decay=0.01,\n",
        "        warmup_ratio=0.1,\n",
        "        lr_scheduler_type='linear',\n",
        "        seed=cfg['seed'],\n",
        "        logging_steps=50,\n",
        "        fp16=USE_GPU_SWEEP,\n",
        "        dataloader_num_workers=NUM_WORKERS_SWEEP,\n",
        "        dataloader_pin_memory=PIN_MEMORY_SWEEP,\n",
        "        save_total_limit=2,\n",
        "        report_to=[],\n",
        "        remove_unused_columns=False,\n",
        "    )\n",
        "\n",
        "    callbacks = [EarlyStoppingCallback(early_stopping_patience=2, early_stopping_threshold=0.001)]\n",
        "    trainer_s = WeightedTrainer(\n",
        "        model=model_s,\n",
        "        args=args,\n",
        "        train_dataset=ds_tr_s,\n",
        "        eval_dataset=ds_va_s,\n",
        "        compute_metrics=compute_metrics,\n",
        "        tokenizer=tokenizer_s,\n",
        "        callbacks=callbacks,\n",
        "        class_weights=(CLASS_WEIGHTS_TENSOR if USE_CLASS_WEIGHTS else None)\n",
        "    )\n",
        "\n",
        "    import time\n",
        "    start = time.time()\n",
        "    trainer_s.train()\n",
        "    train_time = time.time() - start\n",
        "\n",
        "    eval_s = trainer_s.evaluate()\n",
        "    print(f'\\n✓ Run {i} completed in {train_time/60:.2f} min')\n",
        "    print(f'  Val Accuracy: {eval_s.get(\"eval_accuracy\", 0):.4f}')\n",
        "    print(f'  Val F1 Macro: {eval_s.get(\"eval_f1_macro\", 0):.4f}')\n",
        "\n",
        "    if USE_GPU_SWEEP:\n",
        "        print(f'  GPU Memory: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB')\n",
        "\n",
        "    if best_run is None or eval_s.get('eval_f1_macro', -1) > best_run['val_f1']:\n",
        "        best_run = {\n",
        "            'cfg': cfg,\n",
        "            'val_f1': float(eval_s.get('eval_f1_macro', -1)),\n",
        "            'val_acc': float(eval_s.get('eval_accuracy', -1)),\n",
        "            'tokenizer': tokenizer_s,\n",
        "            'trainer': trainer_s,\n",
        "            'ds_test': ds_te_s,\n",
        "            'save_dir': f\"checkpoints/{MODEL_CHOICE}/best\"\n",
        "        }\n",
        "        # save current best\n",
        "        os.makedirs(best_run['save_dir'], exist_ok=True)\n",
        "        trainer_s.save_model(best_run['save_dir'])\n",
        "        tokenizer_s.save_pretrained(best_run['save_dir'])\n",
        "\n",
        "# Evaluate best on test and export predictions\n",
        "if best_run is not None:\n",
        "    preds = best_run['trainer'].predict(best_run['ds_test'])\n",
        "    y_true = preds.label_ids\n",
        "    y_pred = np.argmax(preds.predictions, axis=1)\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    f1m = f1_score(y_true, y_pred, average='macro')\n",
        "    print({'transformer_best_test_acc': acc, 'transformer_best_test_f1_macro': f1m, 'cfg': best_run['cfg']})\n",
        "\n",
        "    # Save predictions\n",
        "    pd.DataFrame({\n",
        "        'review': df_test['review'].tolist(), 'gold': df_test['label'].tolist(), 'pred': y_pred\n",
        "    }).to_csv('transformer_predictions_test.csv', index=False)\n",
        "\n",
        "    # Log\n",
        "    row = {\n",
        "        'member': 'transformer',\n",
        "        'model': MODEL_NAME,\n",
        "        'num_train_epochs': best_run['cfg']['epochs'],\n",
        "        'per_device_train_batch_size': best_run['cfg']['bs'],\n",
        "        'learning_rate': best_run['cfg']['lr'],\n",
        "        'weight_decay': 0.01,\n",
        "        'warmup_steps': None,\n",
        "        'lr_scheduler_type': 'linear',\n",
        "        'gradient_accumulation_steps': 1,\n",
        "        'max_seq_length': best_run['cfg']['max_len'],\n",
        "        'seed': best_run['cfg']['seed'],\n",
        "        'fp16': bool(torch.cuda.is_available()),\n",
        "        'accuracy': acc,\n",
        "        'f1_macro': f1m,\n",
        "        'notes': f\"early_stop=2; class_weights={USE_CLASS_WEIGHTS}\"\n",
        "    }\n",
        "    pd.DataFrame([row]).to_csv('runs_log.csv', mode='a', index=False, header=not os.path.exists('runs_log.csv'))\n",
        "\n",
        "BEST_CKPT_DIR = best_run['save_dir'] if best_run is not None else None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nX6m1vlsIuJ"
      },
      "source": [
        "# Export: ONNX and dynamic quantized PyTorch\n",
        "\n",
        "Exports the best checkpoint for fast CPU inference. Produces `model.onnx` and a `pytorch_model_quantized.bin` alongside the checkpoint.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugzJQ2xdsIuJ"
      },
      "outputs": [],
      "source": [
        "import torch, os\n",
        "from pathlib import Path\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "ckpt_dir = BEST_CKPT_DIR if 'BEST_CKPT_DIR' in globals() and BEST_CKPT_DIR else f\"./finetuned_{MODEL_NAME.replace('/','_')}_best\"\n",
        "print('Exporting from:', ckpt_dir)\n",
        "\n",
        "tokenizer_exp = AutoTokenizer.from_pretrained(ckpt_dir, use_fast=True)\n",
        "model_exp = AutoModelForSequenceClassification.from_pretrained(ckpt_dir).cpu().eval()\n",
        "\n",
        "# ONNX export\n",
        "onnx_path = Path(ckpt_dir)/'model.onnx'\n",
        "dummy = tokenizer_exp(\"ok lang\", return_tensors='pt', padding='max_length', truncation=True, max_length=128)\n",
        "with torch.no_grad():\n",
        "    torch.onnx.export(\n",
        "        model_exp,\n",
        "        (dummy['input_ids'], dummy['attention_mask']),\n",
        "        str(onnx_path),\n",
        "        input_names=['input_ids','attention_mask'],\n",
        "        output_names=['logits'],\n",
        "        dynamic_axes={'input_ids': {0: 'batch', 1:'seq'},\n",
        "                      'attention_mask': {0: 'batch', 1:'seq'},\n",
        "                      'logits': {0: 'batch'}},\n",
        "        opset_version=13\n",
        "    )\n",
        "print('ONNX saved to', onnx_path)\n",
        "\n",
        "# Dynamic quantization (PyTorch)\n",
        "quantized = torch.quantization.quantize_dynamic(model_exp, {torch.nn.Linear}, dtype=torch.qint8)\n",
        "q_path = Path(ckpt_dir)/'pytorch_model_quantized.bin'\n",
        "torch.save(quantized.state_dict(), q_path)\n",
        "print('Quantized state_dict saved to', q_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKFlT6EAsIuJ"
      },
      "source": [
        "# Inference helpers and batch scoring\n",
        "\n",
        "Utilities to load a checkpoint, score a list of texts, or annotate an input CSV and write predictions to disk.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCrsw8R0sIuR"
      },
      "outputs": [],
      "source": [
        "from typing import List, Tuple\n",
        "import torch, numpy as np, pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "\n",
        "def predict_texts(texts: List[str], ckpt_dir: str, batch_size: int = 32) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    device_local = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    tok = AutoTokenizer.from_pretrained(ckpt_dir, use_fast=True)\n",
        "    mdl = AutoModelForSequenceClassification.from_pretrained(ckpt_dir).to(device_local).eval()\n",
        "    preds_all, probs_all = [], []\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, len(texts), batch_size):\n",
        "            batch = texts[i:i+batch_size]\n",
        "            enc = tok(batch, padding=True, truncation=True, max_length=256, return_tensors='pt').to(device_local)\n",
        "            out = mdl(**enc)\n",
        "            logits = out.logits.detach().cpu().numpy()\n",
        "            probs = torch.softmax(out.logits, dim=-1).detach().cpu().numpy()\n",
        "            preds = logits.argmax(axis=1)\n",
        "            preds_all.append(preds)\n",
        "            probs_all.append(probs)\n",
        "    return np.concatenate(preds_all), np.concatenate(probs_all)\n",
        "\n",
        "\n",
        "def score_csv(input_csv: str, text_col: str = 'review', ckpt_dir: str | None = None, out_csv: str = 'scored.csv') -> str:\n",
        "    if ckpt_dir is None:\n",
        "        ckpt_dir = BEST_CKPT_DIR if 'BEST_CKPT_DIR' in globals() and BEST_CKPT_DIR else f\"./finetuned_{MODEL_NAME.replace('/','_')}_best\"\n",
        "    df_in = pd.read_csv(input_csv)\n",
        "    assert text_col in df_in.columns, f\"Missing column {text_col} in {input_csv}\"\n",
        "    preds, probs = predict_texts(df_in[text_col].astype(str).tolist(), ckpt_dir)\n",
        "    out = df_in.copy()\n",
        "    out['pred'] = preds\n",
        "    out['prob_neg'] = probs[:,0]\n",
        "    out['prob_neu'] = probs[:,1]\n",
        "    out['prob_pos'] = probs[:,2]\n",
        "    out.to_csv(out_csv, index=False)\n",
        "    print('Wrote', out_csv)\n",
        "    return out_csv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aFku-HosIuR"
      },
      "source": [
        "# Reporting: test confusion matrices and comparison table\n",
        "\n",
        "Generates confusion matrices for the baseline and transformer best models on the test split, and writes a compact comparison CSV.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-JMMuBWCsIuR"
      },
      "outputs": [],
      "source": [
        "import os, pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, f1_score, classification_report\n",
        "from pathlib import Path\n",
        "\n",
        "outdir = Path('exports'); outdir.mkdir(exist_ok=True)\n",
        "\n",
        "rows = []\n",
        "# Baseline\n",
        "if os.path.exists('baseline_predictions_test.csv'):\n",
        "    dfb = pd.read_csv('baseline_predictions_test.csv')\n",
        "    y_true = dfb['gold'].values; y_pred = dfb['pred'].values\n",
        "    acc = accuracy_score(y_true, y_pred); f1m = f1_score(y_true, y_pred, average='macro')\n",
        "    rows.append({'model':'baseline_best', 'accuracy':acc, 'f1_macro':f1m})\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[0,1,2])\n",
        "    ConfusionMatrixDisplay(cm, display_labels=['neg','neu','pos']).plot(colorbar=False)\n",
        "    plt.title('Baseline (test)'); plt.tight_layout(); plt.savefig(outdir/'CM_baseline_test.png', dpi=150); plt.close()\n",
        "\n",
        "# Transformer\n",
        "if os.path.exists('transformer_predictions_test.csv'):\n",
        "    dft = pd.read_csv('transformer_predictions_test.csv')\n",
        "    y_true = dft['gold'].values; y_pred = dft['pred'].values\n",
        "    acc = accuracy_score(y_true, y_pred); f1m = f1_score(y_true, y_pred, average='macro')\n",
        "    rows.append({'model':'transformer_best', 'accuracy':acc, 'f1_macro':f1m})\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[0,1,2])\n",
        "    ConfusionMatrixDisplay(cm, display_labels=['neg','neu','pos']).plot(colorbar=False)\n",
        "    plt.title('Transformer (test)'); plt.tight_layout(); plt.savefig(outdir/'CM_transformer_test.png', dpi=150); plt.close()\n",
        "\n",
        "if rows:\n",
        "    cmp = pd.DataFrame(rows).sort_values('f1_macro', ascending=False)\n",
        "    cmp.to_csv(outdir/'Sentiment_Comparison.csv', index=False)\n",
        "    try: cmp.to_excel(outdir/'Sentiment_Comparison.xlsx', index=False)\n",
        "    except Exception: pass\n",
        "    display(cmp)\n",
        "else:\n",
        "    print('No predictions found yet. Run cells above first.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMIh-NzUEEdZ"
      },
      "source": [
        "**`Purpose`**\n",
        "\n",
        "This block consolidates the experiment ledger into export files that support grading and documentation. It merges local runs with any team template, sorts them by macro-F1, and writes CSV and spreadsheet versions, along with summary tables for “best by model,” “runs per model,” and the “top ten by macro-F1.”\n",
        "\n",
        "**`Input`**\n",
        "\n",
        "The inputs are runs_log.csv produced by previous training cells and an optional Experiment_Log_Template.xlsx if a group sheet is in use. The code aligns column names and merges tables so that both personal and team entries appear together.\n",
        "\n",
        "**`Output`**\n",
        "\n",
        "The block writes exports/Experiment_Runs_All.csv and .xlsx, as well as Best_by_Model, Runs_per_Model, and Top10_by_F1 files in both CSV and Excel formats when possible. A short message confirms export success. These files are suitable for inclusion as appendix tables and as sources for figures.\n",
        "\n",
        "**`Details`**\n",
        "\n",
        "The merged table is sorted by macro-F1 to surface the strongest runs first. A “best by model” table keeps only the top row per backbone to support quick comparisons in the Results section. A “runs per model” count shows coverage across backbones. A “top ten by F1” slice provides a quick list of leading configurations for screenshots. The exports follow stable column names so that downstream formatting or conditional coloring in spreadsheets is straightforward.\n",
        "\n",
        "**`Line-by-line Description`**\n",
        "\n",
        "`from pathlib import Path` prepares folder handling, and `outdir = Path('exports'); outdir.mkdir(exist_ok=True)` ensures the output directory exists.\n",
        "\n",
        "`df_runs = pd.read_csv('runs_log.csv') if os.path.exists('runs_log.csv') else pd.DataFrame()` loads the personal ledger or falls back to an empty table.\n",
        "\n",
        "The branch that checks `Experiment_Log_Template.xlsx` merges a team sheet when available, aligns columns, and creates a unified table.\n",
        "\n",
        "`if not df_all.empty:` guards the export steps so that the code only writes files when there is data to save.\n",
        "\n",
        "`df_all = df_all.sort_values('f1_macro', ascending=False)` places the highest macro-F1 at the top.\n",
        "\n",
        "`df_all.to_csv(...)` and `df_all.to_excel(...)` write consolidated logs for easy sharing.\n",
        "\n",
        "The next group builds `best_by_model` by keeping the top row per backbone, writes it out, and creates a `rpm` count of runs per model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrk3KgeMiroD",
        "outputId": "043bd056-1e2b-4f25-fc8a-537d68367395"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exported logs to exports/.\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "outdir = Path('exports'); outdir.mkdir(exist_ok=True)\n",
        "\n",
        "df_runs = pd.read_csv('runs_log.csv') if os.path.exists('runs_log.csv') else pd.DataFrame()\n",
        "if os.path.exists('Experiment_Log_Template.xlsx'):\n",
        "    df_team = pd.read_excel('Experiment_Log_Template.xlsx')\n",
        "    for d in (df_runs, df_team):\n",
        "        d.columns = [str(c).strip().lower() for c in d.columns]\n",
        "    all_cols = sorted(set(df_runs.columns) | set(df_team.columns))\n",
        "    df_runs = df_runs.reindex(columns=all_cols)\n",
        "    df_team = df_team.reindex(columns=all_cols)\n",
        "    df_all = pd.concat([df_team, df_runs], ignore_index=True).drop_duplicates()\n",
        "else:\n",
        "    df_all = df_runs\n",
        "\n",
        "if not df_all.empty:\n",
        "    if 'f1_macro' in df_all.columns:\n",
        "        df_all = df_all.sort_values(by='f1_macro', ascending=False)\n",
        "    df_all.to_csv(outdir/'Experiment_Runs_All.csv', index=False)\n",
        "    try:\n",
        "        df_all.to_excel(outdir/'Experiment_Runs_All.xlsx', index=False)\n",
        "    except Exception as e:\n",
        "        print(\"Excel export error:\", e)\n",
        "\n",
        "    if 'model' in df_all.columns and 'f1_macro' in df_all.columns:\n",
        "        best_by_model = df_all.sort_values('f1_macro', ascending=False).drop_duplicates(subset=['model'])\n",
        "        best_by_model.to_csv(outdir/'Best_by_Model.csv', index=False)\n",
        "        best_by_model.to_excel(outdir/'Best_by_Model.xlsx', index=False)\n",
        "\n",
        "        rpm = df_all['model'].value_counts().rename_axis('model').reset_index(name='runs')\n",
        "        rpm.to_csv(outdir/'Runs_per_Model.csv', index=False)\n",
        "        rpm.to_excel(outdir/'Runs_per_Model.xlsx', index=False)\n",
        "\n",
        "    if 'f1_macro' in df_all.columns:\n",
        "        top10 = df_all.head(10)\n",
        "        top10.to_csv(outdir/'Top10_by_F1.csv', index=False)\n",
        "        top10.to_excel(outdir/'Top10_by_F1.xlsx', index=False)\n",
        "    print(\"Exported logs to exports/.\")\n",
        "else:\n",
        "    print(\"No logs found yet.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0a4ea765a86c4f4bb359ea799b6a14bc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e1cbab441fd44d6b30a6566b65a0629": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f08a2cde1a943b7b7bbc6700bb81a7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "122994d3a4aa4168b7a25bf2fcb75f12": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1245c9f4b94044f89da706b7ad6e1e15": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b1eac066cf34176853032a4cc2bccd0",
            "max": 1468,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_122994d3a4aa4168b7a25bf2fcb75f12",
            "value": 1468
          }
        },
        "1b1eac066cf34176853032a4cc2bccd0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c4ff9efabf6418cb31ebacafbe886b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "213a8b12e47643228f42bda40a4ffc7b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25a9b69db84d4019bfcf4468de0230f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35ee990f87ff4e08875f67b39634a733": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "363cd7771c6f45d09db0abcc06e31c60": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c27b86759f94786b77a560a32856875": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_97827c4e0bbc470f8b420c3bce9aa202",
              "IPY_MODEL_fc5894a33a824078b5063769270edea0",
              "IPY_MODEL_b8d15f8a0f8749eab1265e790c71a725"
            ],
            "layout": "IPY_MODEL_213a8b12e47643228f42bda40a4ffc7b"
          }
        },
        "404cb20929ae449bbfdcec1c1120e492": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4216e6ed3fb24da18e99fe0c717db045": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5401eda2dd92440eb942e4e4ce22ae9a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54ce2cbf872e4a1bace9d357224af54f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f86573a9431e45ac90ebebc4fefaa637",
              "IPY_MODEL_5a98a9565c80437eb5fbff7959f641af",
              "IPY_MODEL_de4e6cb32d1c4cb1a144d45cfdd69716"
            ],
            "layout": "IPY_MODEL_404cb20929ae449bbfdcec1c1120e492"
          }
        },
        "5a3eb5c3ddb64655b8e50bff64be19d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a98a9565c80437eb5fbff7959f641af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35ee990f87ff4e08875f67b39634a733",
            "max": 2348,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a62adb4544da44c08eb9e0b2490a1dbe",
            "value": 2348
          }
        },
        "7998ea6b1b6746ee9b0b646d86515b55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_885427d083a14807a16138dbc4578041",
              "IPY_MODEL_1245c9f4b94044f89da706b7ad6e1e15",
              "IPY_MODEL_7a1c7c195a8a4f308edef2de43b3fcae"
            ],
            "layout": "IPY_MODEL_4216e6ed3fb24da18e99fe0c717db045"
          }
        },
        "7a1c7c195a8a4f308edef2de43b3fcae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_363cd7771c6f45d09db0abcc06e31c60",
            "placeholder": "​",
            "style": "IPY_MODEL_1c4ff9efabf6418cb31ebacafbe886b5",
            "value": " 1468/1468 [00:01&lt;00:00, 1159.22 examples/s]"
          }
        },
        "885427d083a14807a16138dbc4578041": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a4ea765a86c4f4bb359ea799b6a14bc",
            "placeholder": "​",
            "style": "IPY_MODEL_5a3eb5c3ddb64655b8e50bff64be19d3",
            "value": "Map (num_proc=2): 100%"
          }
        },
        "8d6a9ce521154252b75dcfc8389be09f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "97827c4e0bbc470f8b420c3bce9aa202": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4d65b8f4f7c4cddad1fa0ce735b6384",
            "placeholder": "​",
            "style": "IPY_MODEL_ac08bae15e944971b2332430b60aefee",
            "value": "Map (num_proc=2): 100%"
          }
        },
        "9fd7900968bb4fcc933209f91c2a6d13": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a62adb4544da44c08eb9e0b2490a1dbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ac08bae15e944971b2332430b60aefee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4d65b8f4f7c4cddad1fa0ce735b6384": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8d15f8a0f8749eab1265e790c71a725": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e182c0280fc44a5a8e8af5f6ed120e77",
            "placeholder": "​",
            "style": "IPY_MODEL_0e1cbab441fd44d6b30a6566b65a0629",
            "value": " 734/734 [00:00&lt;00:00, 1158.59 examples/s]"
          }
        },
        "cd8c033f142e4cfa8ada243107fb6d9e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de4e6cb32d1c4cb1a144d45cfdd69716": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9fd7900968bb4fcc933209f91c2a6d13",
            "placeholder": "​",
            "style": "IPY_MODEL_0f08a2cde1a943b7b7bbc6700bb81a7c",
            "value": " 2348/2348 [00:02&lt;00:00, 1729.37 examples/s]"
          }
        },
        "e182c0280fc44a5a8e8af5f6ed120e77": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f86573a9431e45ac90ebebc4fefaa637": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd8c033f142e4cfa8ada243107fb6d9e",
            "placeholder": "​",
            "style": "IPY_MODEL_25a9b69db84d4019bfcf4468de0230f0",
            "value": "Map (num_proc=2): 100%"
          }
        },
        "fc5894a33a824078b5063769270edea0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5401eda2dd92440eb942e4e4ce22ae9a",
            "max": 734,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8d6a9ce521154252b75dcfc8389be09f",
            "value": 734
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
