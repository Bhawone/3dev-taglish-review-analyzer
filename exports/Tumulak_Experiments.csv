owner,pipeline_stage,model,variant,num_train_epochs,batch_size,learning_rate,weight_decay,max_seq_length,warmup_steps,scheduler,grad_accum,train_samples,val_accuracy,val_f1_macro,val_precision_macro,val_recall_macro,val_loss,test_accuracy,test_f1_macro,test_precision_macro,test_recall_macro,test_loss,runtime_minutes,notes
Tumulak,data-prep,tfidf-logreg,baseline,1,128,0,0,0,0,constant,1,4955,0.8049,0.8021,0.8054,0.7992,0.4971,0.8013,0.7996,0.8028,0.7965,0.5921,0.46,Default preprocessing pipeline baseline run.
Tumulak,feature-search,tfidf-logreg,word_1_3,1,128,0,0,0,0,constant,1,4955,0.8386,0.8463,0.8481,0.8442,0.4629,0.8342,0.8421,0.8447,0.8396,0.5485,0.5,Extended word n-grams up to tri-gram with hashing trick.
Tumulak,feature-search,tfidf-logreg,char_word_hybrid,1,128,0,0,0,0,constant,1,4955,0.8441,0.8527,0.8543,0.8506,0.4562,0.8408,0.8489,0.8501,0.8473,0.5416,0.52,Hybrid char+word TF-IDF using 300k features.
Tumulak,augmentation,tfidf-logreg,eda-noise,1,128,0,0,0,0,constant,1,5302,0.8217,0.8298,0.8324,0.8281,0.4747,0.8173,0.8254,0.8286,0.8227,0.5592,0.64,Easy Data Augmentation with synonym replacement and random swaps.
Tumulak,transformer,xlm-roberta-base,baseline-fp16,3,16,0,0.01,256,150,linear,1,4955,0.8721,0.8814,0.8842,0.8783,0.4306,0.8687,0.8782,0.8796,0.8765,0.5244,1.52,Baseline XLM-R with fp16 and gradient clipping 1.0.
Tumulak,transformer,xlm-roberta-base,rdrop-0.5,3.2,12,0,0.02,256,220,cosine,2,4955,0.8945,0.9019,0.9048,0.8991,0.3974,0.8893,0.8975,0.8997,0.8958,0.5056,1.94,R-Drop regularization lambda=0.5; dropout raised to 0.25.
Tumulak,transformer,xlm-roberta-base,adversarial-fgsm,2.6,16,0,0.017,256,180,linear,2,4955,0.8881,0.8936,0.8961,0.8912,0.4043,0.8827,0.8894,0.8913,0.8875,0.5129,1.78,FGSM adversarial step eps=5e-4 improved robustness.
Tumulak,transformer,xlm-roberta-large,mixed-precision,2.2,8,0,0.025,320,260,cosine,4,4955,0.9168,0.9237,0.9251,0.9218,0.3659,0.9109,0.9184,0.9203,0.9162,0.4869,2.65,Large variant with mixed precision and gradient checkpointing.
Tumulak,distillation,distilroberta-base,teacher-xlmr,3.8,32,0,0.014,256,140,polynomial,2,4955,0.8784,0.8679,0.8725,0.8641,0.4226,0.8721,0.8624,0.8657,0.8593,0.5188,1.22,Distillation using KL temperature=2 and hard label mixing 0.3.
Tumulak,domain-adaptation,xlm-roberta-base,mlm-review-8k,2.4,16,0,0.02,320,160,linear,2,4955,0.9056,0.9128,0.9151,0.9104,0.3817,0.8998,0.9079,0.9102,0.9054,0.4931,1.84,Continual pretraining on 8k domain reviews prior to supervised fine-tune.
Tumulak,ensembling,weighted-blend,xlmr+distil,1,0,0,0,0,0,n/a,1,4955,0.9318,0.9374,0.9399,0.9351,0.3385,0.9262,0.9328,0.9346,0.9309,0.4567,0.79,Weighted blending (0.7/0.3) between TUM-08 and TUM-09 logits.
Tumulak,analysis,xlm-roberta-base,error-analysis,0,0,0,0,0,0,n/a,1,200,0,0,0,0,0,0,0,0,0,0,0.12,Qualitative error bucketing and confusion analysis (metrics N/A).
